
\chapter{Untermannigfaltigkeiten des Koordinatenraums}

\section{Vorbereitungen}

Wir wollen in diesem Abschnitt später benötigte Ergebnisse der
linearen Algebra rekapitulieren und für unsere Zwecke anpassen.

\subsection{Orthogonalität}

Sei $V$ ein endlichdimensionaler reeller Vektorraum und
$B\colon V^2\to\R$ eine nicht ausgeartete symmetrische Bilinearform.
Weil $B$ nicht ausgartet ist, ist die lineare Abbildung%
\begin{equation}
\Phi\colon V\to V^*,\quad \Phi(v)(w):=B(v,w)
\end{equation}
ein Isomorphismus. Man bezeichnet $\Phi$ als
\emph{kanonischen Isomorphimus}\index{kanonischer Isomorphismus}
bezüglich $B$ und spricht in den Schreibweisen $v^\flat:=\Phi(v)$
und $\omega^\sharp:=\Phi^{-1}(\omega)$ von den \emph{musikalischen
Isomorphismen}\index{musikalische Isomorphismen}.

Sei nun $(g_k)$ eine Basis von $V$. Man bzeichnet die Matrix
$g=(g_{ij})$ mit $g_{ij}:=B(g_i,g_j)$ dann als
\emph{gramsche Matrix}\index{gramsche Matrix}
der Bilinearform $B$ bezüglich der gewählten Basis. Man bezeichnet
$g$ außerdem als Darstellungsmatrix von $B$ bezüglich $(g_k)$,
weil $B$ durch $g$ dargestellt wird. Es ist nun aber so, dass
$g$ auch Darstellungsmatrix von $\Phi$ ist. Weil $\Phi$ bijektiv
ist, muss $g$ invertierbar sein, bzw. $\det g\ne 0$.

Weil $g$ eine reelle symmetrische Matrix ist, besitzt $g$ nur reelle
Eigenwerte, algebraische und geometrische Vielfachheit jedes
Eigenwerts stimmen überein, somit ist $g$ diagonalisierbar.
Nach dem Trägheitssatz von Sylvester gibt es eine Basis, so
dass $g$ diagonal wird. Eine solche Basis bezeichnen wir als
\emph{Orthogonalbasis} bezüglich $B$. Der Trägheitssatz macht auch
noch die schärfere Aussage, dass man eine Basis finden kann, bei der
die Diagonale von $g$ nur aus $+1$, $-1$, $0$ besteht. Wegen
$\det g\ne 0$ kann $0$ bei uns nicht auftreten, der Trägheitsindex von
$B$ ist also $(p,q,0)$.

Zwei Vektoren $v,w$ nennen wir genau dann \emph{orthonormal},
wenn $B(v,w)$ verschwindet:%
\begin{equation}
v\perp w \defiff B(v,w)=0.
\end{equation}

\subsection{Orthogonale Projektion}

Sei $V$ ein Vektorraum und $U$ ein Untervektorraum. Sei
$B\colon V^2\to\R$ eine symmetrische Bilinearform. Dann definert
man das orthogonale Komplement\index{orthogonales Komplement}
von $U$ bezüglich $B$ als
\begin{equation}
U^\perp := \{v\in V\mid \forall u\in U\colon B(u,v)=0\}.
\end{equation}
\begin{theorem}
Sei $B$ sowohl auf $V$ als auch auf $U$ nicht ausgeartet.
Dann gibt es eine Zerlegung $V=U\oplus U^\perp$. Demnach
existiert auch die orthogonale Projektion $P(v):=u$
für $v=u+u_n$ mit $u\in U$ und $u_n\in U^\perp$.
\end{theorem}
\strong{Beweis.} Zu zeigen ist zunächst $U\cap U^\perp=\{0\}$.
Weil die Einschränkung von $B$ auf $U$ nicht ausgeartet ist, ist
$\Phi_U(v)(w):=B_{|U}(v,w)$ injektiv, das bedeutet
$\Kern\Phi_U=\{0\}$. Man kann nun rechnen:
\begin{align}
U\cap U^\perp &= U\cap\{v\in V\mid \forall u\in U\colon B(u,v)=0\}\\
&= \{v\in U\mid\forall u\in U\colon\Phi_U(v)(u)=0\}\\
&= \{v\in U\mid \Phi_U(v)=0\} = \Kern\Phi_U = \{0\}.
\end{align}
Nun muss man noch $V=U+U^\perp$ zeigen. Das kann man tun, indem
zu jedem $v\in V$ ein $u\in U$ und $v_n\in U^\perp$ konstruiert
wird, so dass $v=u+u_n$. Haben wir die Projektion $P$ bei Hand,
kann diese Konstruktion sofort als $u:=P(v)$ und $u_n:=v-P(v)$
herbeigeschafft werden. Nun muss man aber die Projektion
konstruieren. Diese soll eine lineare Abbildung sein, die%
\begin{align}
&\forall v\in V\colon\; P(v)\in U,\\
&\forall v\in V, u\in U\colon\; B(v-P(v),u) = 0
\end{align}
erfüllt. Die zweite Bedingung lässt sich zu $B(P(v),u)=B(v,u)$
umformen. Sei nun $(g_k)$ eine Basis von $U$, dann muss sich
$P(v)$ als Linearkombination aus der Basis darstellen lassen,
also $P(v)=\sum_{i=1}^n a_i g_i$. Aufgrund der Bilinearität von $B$
genügt es, wenn die zweite Bedingung für die Basisvektoren
$u\in\{g_k\}$ erfüllt ist, anstelle für alle $u\in U$. Einsetzen
ergibt nun
\begin{equation}
B(v,g_j) = B(P(v),g_j) = B(\sum_{i=1}^n a_i g_i,g_j)
= \sum_{i=1}^n a_i B(g_i,g_j) = \sum_{i=1}^n a_i g_{ij}.
\end{equation}
Das ist ein lineares Gleichungssystem mit der System"=Matrix
$g:=(g_{ij})$ mit $g_{ij}:=B(g_i,g_j)$. Weil $g$ aber auch
Darstellungsmatrix des Isomorphismus $\Phi_U$ ist, muss $\det g\ne 0$
sein. Das System besitzt also eine eindeutige Lösung $(a_k)$. Diese
legt die Projektion eindeutig fest.\;\qedsymbol



\section{Grundlagen}
\subsection{Definition}

\begin{definition}[Topologische Untermannigfaltigkeit]%
\index{Mannigfaltigkeit}\index{Untermannigfaltigkeit}\mbox{}\\*
Eine Menge $M\subseteq\R^m$ heißt
Untermannigfaltigkeit des $\R^m$, wenn es zu jedem Punkt $p\in M$ einen
Homöomorphismus $\varphi\colon U\to V$ mit%
\begin{equation}
M\cap V = \varphi(U\cap(\R^n\times\{0\})),\quad 0\in\R^{m-n}
\end{equation}
gibt, wobei $U,V\subseteq\R^m$ offen in $\R^m$ sind und $p\in V$ ist.
\end{definition}
Wenn nämlich $U$ offen in $\R^m$ ist, muss der Schnitt von $U$
mit einem Untervektorraum auch offen in diesem Untervektorraum
sein. Demnach ist $\tilde U:=U\cap(\R^n\times\{0\})$ offen in
$\R^n\times\{0\}$. Der Homöomorphismus $\varphi$ kann nun zur
Übertragung der Topologie genutzt werden. 

\begin{theorem}[Lokale Topologie einer Untermannigfaltigkeit]\mbox{}\\*
Eine Menge $B\subseteq\varphi(\tilde U)$
sei offen in $\varphi(\tilde U)$, wenn eine Menge $A$ mit
$B=\varphi(A)$ existiert, wobei
$A\subseteq\tilde U$ offen ist.
Hierdurch wird $\varphi(\tilde U)$
zu einem topologischen Raum.
\end{theorem}

\noindent\strong{Beweis.}
Die Menge $B=\emptyset$ ist trivialerweise das Bild von
$A=\emptyset$. Die Menge $B=\varphi(\tilde U)$ ist
trivialerweise das Bild der offenen Menge $\tilde U$.

Nun muss gezeigt werden, dass $B_1\cap B_2$ offen ist,
wenn $B_1,B_2$ offen sind. Es gibt also $A_1,A_2$ mit $B_1=\varphi(A_1)$
und $B_2=\varphi(A_2)$. Gesucht ist also eine offene Menge $X$,
welche die Gleichung
\begin{equation}
\varphi(X) = B_1\cap B_2 = \varphi(A_1)\cap\varphi(A_2)
\end{equation}
erfüllt. Für eine beliebige Abbildung $f$ gilt
$f(B_1\cap B_2) \subseteq f(B_1)\cap f(B_2)$ und falls $f$
bijektiv ist, auch $f(B_1\cap B_2)=f(B_1)\cap f(B_2)$. Demnach
ergibt sich
\begin{equation}
X = \varphi^{-1}(B_1\cap B_2) = \varphi^{-1}(B_1)\cap\varphi^{-1}(B_2)
= A_1\cap A_2.
\end{equation}
Die Vereinigung von beliebig vielen offenen Mengen $B_k=\varphi(A_k)$
soll wieder offen sein. Das ist die Gleichung
\begin{equation}
\varphi(X) = \bigcup_{k\in K} B_k = \bigcup_{k\in K} \varphi(A_k)
= \varphi(\bigcup_{k\in K} A_k)
\implies X=\bigcup_{k\in K} A_k.
\end{equation}
Dabei wurde beachtet, dass $f(\bigcup_k B_k) = \bigcup_k f(B_k)$
für eine beliebige Abbildung $f$ gilt.\;\qedsymbol

\begin{theorem}[Topologie einer Untermannigfaltigkeit]\mbox{}\\*
Eine Menge $B\subseteq M$ sei offen, wenn Paare $(\varphi_k,A_k)$
mit $B=\bigcup_k\varphi_k(A_k)$ existieren, wobei die
$A_k\subseteq\tilde U_k$ offen sind.
Hierdurch wird $M$ zu einem topologischen Raum.
\end{theorem}

\noindent\strong{Beweis.}
Die Offenheit der leeren Menge ist wieder geschenkt.
Beliebige Vereinigungen sind offen, da die Vereinigung von
Vereinigungen wieder eine Vereinigung ist. Dann muss auch
$M$ offen sein.

Seien nun $B_1,B_2$ offen. Demnach ist $B_1=\bigcup_i B_i$
und $B_2=\bigcup_j B_j$, wobei $B_k=\varphi_k(A_k)$.
Daraus ergibt sich nun
\begin{equation}
B_1\cap B_2 = \Big(\bigcup\nolimits_i B_i\Big)
\cap\Big(\bigcup\nolimits_j B_j\Big)
= \bigcup\nolimits_i \bigcup\nolimits_j (B_i\cap B_j).
\end{equation}
Es bleibt lediglich zu zeigen, dass $B_i\cap B_j$ offen ist.
Wegen $B_i\cap B_j\subseteq B_i$ muss es ganz sicher eine Menge
$X\subseteq\tilde U_i$ geben, so dass
\begin{equation}
\varphi_i(X) = B_i\cap B_j = \varphi_i(A_i)\cap\varphi_j(A_j).
\end{equation}
Es ergibt sich nun
\begin{equation}
X = \varphi_i^{-1}(B_i\cap B_j)
= \varphi_i^{-1}(B_i)\cap\varphi_i^{-1}(B_j)
= A_i\cap (\varphi_i^{-1}{\circ}\varphi_j)(A_j).
\end{equation}
Folglich muss $X$ offen sein, da es die Schnittmenge von offenen
Mengen im flachen Raum ist. Demnach besitzt auch $B_1\cap B_2$
eine Darstellung als Vereinigung von offenen Mengen.\;\qedsymbol

Es gibt aufgrund der unterschiedlichen topologischen Strukturen
viele Mannigfaltigkeiten, die nicht über eine einzige Karte
angegeben werden können. Die Angabe geschieht somit im
Allgemeinen über einen Atlas von Karten.

\begin{definition}[Atlas]\index{Atlas}\mbox{}\\*
Eine Menge von Karten $\varphi_k\colon U_k\to V_k$ für eine
Mannigfaltigkeit $M$ wird \emph{Atlas} genannt, wenn die
$V_k$ die Mannigfaltigkeit überdecken, d.\,h. $M=\bigcup_k V_k$.
\end{definition}

\noindent
Angenommen, auf einer Mannigfaltigkeit $M$ ist nun ein Skalarfeld
$f\colon V\to\R$ mit offenem $V\subseteq M$ definiert. Dieses
Skalarfeld sei gegeben durch eine lokale Darstellung
$\tilde f\colon U\to\R$ mit $U\subseteq\R^n$, wobei
$f=\tilde f\circ\psi$ und $\psi\colon V\to U$.
Die Berechnung der Ableitung muss nun über die Kettenregel
geschehen:
\begin{equation}
\mathrm df_p = \mathrm d(\tilde f\circ\psi)_p
= \mathrm d\tilde f_u\circ\mathrm d\psi_p,
\quad u = \psi(p).
\end{equation}
Dann muss die Karte $\psi$ differenzierbar sein.

Wenn auf einer Mannigfaltigkeit Differentialrechnung benutzt
werden soll usw. usf., dann müssen also auch die Karten hinreichend oft
differenzierbar sein. Wir fordern demnach dass die Karten
$C^k$-Diffeomorphismen sein sollen.


\subsection{Lokale Karten}

Sei $\varphi\colon U\to\R^m$ mit $U\subseteq\R^n$ eine lokale Karte.
Man definiert die Richtungsableitung von $\varphi$ als
\begin{equation}
\mathrm d\varphi_u(v) = (\mathrm d\varphi)(u)(v)
:= \lim_{h\to 0}\frac{\varphi(u+hv)-\varphi(u)}{h}.
\end{equation}
Im Folgenden wird der Begriff der totalen Differenzierbarkeit
aus der mehrdimensionalen Analysis als bekannt vorausgesetzt.
Ist $\varphi$ total differenzierbar, dann lässt sich
$\mathrm d\varphi_u$ als lineare Abbildung aus $\hom(\R^n,\R^m)$
darstellen. Aufgrund der kanonischen Isomorphie zwischen
$\hom(\R^n,\R^m)$ und dem Matrizenraum $\R^{m\times n}$ gibt
es für jede lineare Abbildung genau eine Darstellungsmatrix,
wobei für $\R^n$ und $\R^m$ die kanonische Basis zu wählen ist.
Dieser Zusammenhang ist so eindrücklich, dass wir die lineare
Abbildung zwischen Koordinatenräumen mit ihrer Darstellungsmatrix
identifizieren könnten.

Die kanonische Darstellungsmatrix von $\mathrm d\varphi_u$ ist die
Jacobi"=Matrix $J=D\varphi_u$. Für einen Vektor $v\in\R^n$ mit
$v=\sum_{j=1}^n v_j \mathbf e_j$ gilt dann
\begin{equation}
\mathrm d\varphi_u(v) = Jv
= \sum_{j=1}^n \frac{\partial\varphi}{\partial u^j}(u) v^j
= \sum_{i=1}^m\sum_{j=1}^n \frac{\partial\varphi^i}{\partial u^j}(u) v^j\mathbf e_i
= \sum_{i=1}^m\sum_{j=1}^n J_{ij} v^j\mathbf e_i.
\end{equation}

\subsection{Tangentialräume}

Sei $M$ eine Untermannigfaltigkeit, $p\in M$ ein Punkt und
$c\colon (-\varepsilon,\varepsilon)\to M$ eine differenzierbare Kurve
mit $p=c(0)$. Da $c'(0)$ der Tangentialvektor der Kurve am Punkt $p$
ist und die Kurve in $M$ liegt, muss $c'(0)$ auch ein Tangentialvektor
von $M$ sein. Die Menge aller Tangentialvektoren, die sich auf
diese Art am Punkt $p$ bilden lassen, nennt man
Tangentialraum\index{Tangentialraum} $T_p M$.

\begin{theorem}
Sei $M$ eine $n$"=dimensionale Untermannigfaltigkeit des $\R^m$.
Der Tangentialraum $T_p M$ ist ein $n$"=dimensionaler Untervektorraum
des $\R^m$. Sei $\varphi\colon U\to V$ mit $U\subseteq\R^n$ und
$V\subseteq M$ eine lokale Karte von $M$.  Es gilt
$T_p M = \Bild(\mathrm d\varphi_u)$, wobei $p=\varphi(u)$. 
\end{theorem}

\noindent\strong{Beweis.}
Zur Kurve $c$ in $M$ gehört genau die Kurve $\tilde c$ im $\R^n$, so
dass $c=\varphi\circ\tilde c$. Sei $u=\tilde c(0)$. Nach der
Kettenregel gilt%
\begin{equation}
c'(0) = (\varphi\circ\tilde c)'(0) = \mathrm d\varphi_u\tilde c'(0),
\end{equation}
Zu jedem Vektor $v\in\R^n$ lässt sich eine Kurve $\tilde c$
mit $u=\tilde c(0)$ und $v=\tilde c'(0)$ finden. Demnach gilt
\begin{equation}
T_p M = \mathrm d\varphi_u(\R^n) = \Bild(\mathrm d\varphi_u).
\end{equation}
Weil $\mathrm d\varphi_u$ eine injektive lineare Abbildung ist,
gilt nach dem Dimensionssatz%
\begin{equation}
\dim\Bild(d\varphi_u) = \dim(\R^n) = n.\;\qedsymbol
\end{equation}
Da $\mathrm d\varphi_u$ injektiv ist, wird einer Basis wieder eine
Basis zugeordnet. Nimmt man die Standardbasis
$(\mathbf e_k)=(\mathbf e_1,\ldots,\mathbf e_n)$, dann ergibt
sich für $T_p M$ die Basis $(g_k)$ mit
\begin{equation}
g_k(u) = \mathrm d\varphi_u(\mathbf e_k)
= \frac{\partial\varphi}{\partial u^k}(u),\quad\text{wobei}\; p=\varphi(u).
\end{equation}


\section{Skalarfelder}

\subsection{Die Richtungsableitung}

Sei $U\subseteq\R^n$ eine offene Menge. Sei außerdem $p\in U$ 
eine Stelle und $v\in\R^n$ ein Vektor. Man betrachte die Gerade
\begin{equation}\label{eq:Gerade-zum-Vektor}
G := \{p+tv\mid t\in\R\}.
\end{equation}
Das Skalarfeld $f$ wollen wir nun auf den Streifen $U\cap G$
einschränken. Parametrisiert man diesen Streifen um $p$ herum durch
$t$, dann ergibt sich die Funktion%
\begin{equation}
g\colon (-\varepsilon,\varepsilon)\to\R,\quad g(t):=f(p+tv).
\end{equation}
Für $g$ ist die gewöhnliche Ableitung definiert, da $g$
eine reelle Funktion in einer Variablen ist. Wir nennen $g'(0)$ die
\emph{Richtungsableitung} von $f$ an der Stelle $p$ in Richtung $v$.
Es ergibt sich%
\begin{equation}\label{eq:Richtungsableitung-flach}
\mathrm df_p(v) = (\mathrm df)(p)(v) := g'(0)
= \lim_{h\to 0}\frac{g(h)-g(0)}{h}
= \lim_{h\to 0}\frac{f(p+hv)-f(p)}{h}.
\end{equation}
Wir betrachten nun ein Skalarfeld $f\colon M\to\R$, welches
auf einer Untermannigfaltigkeit $M$ definiert ist.
Die Richtungsableitung lässt sich nun aber nicht mehr gemäß
\eqref{eq:Richtungsableitung-flach} bestimmen, weil die Gerade
\eqref{eq:Gerade-zum-Vektor} nicht innerhalb von $M$ liegen muss.
Außerhalb von $M$ ist das Skalarfeld nicht definiert, der Ausdruck
\eqref{eq:Richtungsableitung-flach} setzt dies aber voraus.

Dieses Problem lässt sich wie folgt lösen. Sei $p\in M$ ein Punkt
auf $M$. Sei $c\colon (-\varepsilon,\varepsilon)\to M$ eine Kurve
in $M$ mit $p=c(0)$ und $v=c'(0)$. Damit das überhaupt möglich ist, muss
der Vektor $v\in T_p M$, d.\,h. im Punkt $p$ tangential an $M$ sein.
Nun wird ähnlich wie zuvor die Funktion
$g\colon (-\varepsilon,\varepsilon)\to\R$ mit $g:=f\circ c$ betrachtet.
Für $g$ ist die gewöhnliche Ableitung definiert. Die Richtungsableitung
lässt sich also gemäß $g'(0)=(f\circ c)'(0)$ bestimmen.

\begin{definition}[Richtungsableitung]%
\index{Richtungsableitung}\mbox{}\\*
Sei $M$ eine Untermannigfaltigkeit und $f\colon M\to\R$ ein Skalarfeld.
Sei $p\in M$ ein Punkt und $v$ ein Vektor, welcher am Punkt $p$
tangential an $M$ ist. Sei $c\colon (-\varepsilon,\varepsilon)\to M$
eine glatte Kurve mit $p=c(0)$ und $v=c'(0)$. Unter der
\emdef{Richtungsableitung} von $f$ am Punkt $p$ in Richtung $v$
versteht man die reelle Zahl
\begin{equation}
\mathrm df_p(v) = (\mathrm df)(p)(v) := (f\circ c)'(0)
= \lim_{h\to 0}\frac{f(c(h))-f(p)}{h}.
\end{equation}
\end{definition}
Sei $\varphi\colon U\to V$ mit $U\subseteq\R^m$ und $V\subseteq M$
eine lokale Karte. Sei $(g_k)$ der durch
$g_k=\frac{\partial\varphi}{\partial u^k}$ induzierte lokale
Rahmen. Demnach ist $(g_k)$ am Punkt $p$ eine
Basis von $T_p M$. Sei $(\mathrm dx^k)$ die zu $(g_k)$ eindeutig
bestimmte duale Basis. Diese spannt den Kotangentialraum $T_p^* M$ auf.

Die partiellen Ableitungen von $f$ lassen sich wie bei Skalarfeldern
auf dem $\R^n$ als die Richtungsableitungen in Richtung der
Basisvektoren sehen. Beim $\R^n$ war es die Standardbasis, hier ist
es $(g_k)$.
\begin{definition}[Partielle Ableitungen]\mbox{}\\*
Die \emdef{partielle Ableitung} von $f$ nach der $k$-ten Koordinate
ist definiert als
\begin{equation}\label{eq:partial}
(\partial_k f)(p) = \frac{\partial f}{\partial x^k}(p)
= \frac{\partial f(x)}{\partial x^k}\Big|_{x=p} :=
\mathrm df_p(g_k).
\end{equation}
\end{definition}
Wenn $f$ als total differenzierbar vorausgesetzt wird, dann ist
$\mathrm df_p$ eine Linearform, also ein Element des
Kotangentialraums. Es ergibt sich
\begin{equation}
\mathrm df_p = \sum_{k=1}^n \frac{\partial f}{\partial x^k}(p)\mathrm dx^k.
\end{equation}
Für einen Vektor $v=\sum_{k=1}^n v^k g_k$ ergibt
sich dann die duale Paarung
\begin{equation}
\mathrm df_p(v) = \sum_{k=1}^n \frac{\partial f}{\partial x^k}(p)v^k.
\end{equation}
Mit der lokalen Karte $\varphi$ ist eigentlich die lokale
Darstellung $\tilde f=f\circ\varphi$ gegeben. Zwischen
$f$ und $\tilde f$ gibt es aber einen besonders einfachen Zusammenhang.
\begin{corollary}
Sei $f$ ein Skalarfeld, $\varphi$ eine lokale Karte und
$\tilde f=f\circ\varphi$. Es gilt%
\begin{equation}
\frac{\partial f}{\partial x^k}(p) = \frac{\partial\tilde f}{\partial u^k}(u),
\end{equation}
wobei $p=\varphi(u)$.
\end{corollary}
\strong{Beweis.} Sei dazu $c(t)$ eine Kurve mit $p=c(0)$ und
$g_k(u)=c'(0)$. Sei außerdem $\tilde c$ eine Kurve im $\R^m$, so dass
$c=\varphi\circ \tilde c$. Nach der Kettenregel gilt
\begin{equation}
g_k(u) = c'(0) = (\varphi\circ\tilde c)'(0) = \mathrm d\varphi_u(\tilde c'(0)).
\end{equation}
Es gilt aber auch $g_k(u) = (\partial_k\varphi)(u) =
\mathrm d\varphi_u(\mathbf e_k)$. Daraus folgt
$\mathrm d\varphi_u(\tilde c'(0)) = \mathrm d\varphi_u(\mathbf e_k)$.
Da $\mathrm d\varphi_u$ eine injektive Abbildung ist, ergibt sich
$\tilde c'(0) = \mathbf e_k$.\;\qedsymbol

Für die Richtungsableitung ergibt sich
\begin{equation}\label{eq:Richtungsableitung-lokal}
\mathrm df_p(v) = \mathrm d\tilde f_u((v^k)) =
\langle(\nabla \tilde f)(u),(v^k)\rangle.
\end{equation}
Auf der rechten Seite steht das Standardskalarprodukt, weil die
duale Paarung mit dem totalen Differential im Koordinatenraum einfach
das Standardskalarprodukt mit dem Gradient ist. Das ist ein rein
technischer Formalismus, diese Formel setzt keinesfalls eine
Metrik oder ähnlich voraus.

Eine Bermerkung noch: Die Notation
$\partial_k$ bzw. $\frac{\partial}{\partial x^k}$ in \eqref{eq:partial}
ist ausgesprochen ungünstig, weil sie sich mit der Notation für die
Ableitung im Koordinatenraum überschneidet, die häufig bei der
Umrechnung von kartesischen in krummlinigen Koordinaten auftritt.
In \eqref{eq:partial} ist $x^k$ keine kartesische Koordinate,
sondern eine abstrakte entlang der Koordiantenlinie.


\section{Vektorfelder}

\subsection{Die kovariante Ableitung}

Sei $M$ eine Untermannigfaltigkeit des $\R^m$ und $X\colon M\to TM$
ein Vektorfeld. Nun kann doch wie bei einem Skalarfeld die
Richtungsableitung von $X$ in Richtung
eines Vektors $v\in T_p M$ definiert werden. Sei dazu
$c\colon (-\varepsilon,\varepsilon)\to M$ eine Kurve
mit $p=c(0)$ und $v=c'(0)$. Dann definiert man%
\begin{equation}
\mathrm dX_p(v) := (X\circ c)'(0).
\end{equation}
Nun taucht das Problem auf, dass die Ableitung an der Stelle $p$
ein Vektor ist, welcher nicht unbedingt tangential an $M$ sein muss.
Ein Ziel der Differentialgeometrie ist es aber, eine Theorie aufzubauen,
welche nur auf Tangentialräumen beruht. Aus diesem Grund projizieren
wir den Vektor $w=\mathrm dX_p(v)$ orthogonal auf den Tangentialraum
$T_p M$. Der zum Tangentialraum orthogonale Anteil entfällt dabei.

Die orthogonale Projektion auf $T_p M$ nennen wir $\Pi_p$. Es handelt
sich um eine lineare Abbildung.

\begin{definition}[Kovariante Ableitung]%
\index{kovariante Ableitung}\mbox{}\\*
Die \emdef{kovariante Ableitung} eines Vektorfeldes $X\colon M\to TM$
an der Stelle $p\in M$ in Richtung $v\in T_p M$ ist definiert als
\begin{equation}
(\nabla_v X)(p) := \Pi_p((X\circ c)'(0)),
\end{equation}
wobei $c\colon (-\varepsilon,\varepsilon)\to M$ eine glatte Kurve
mit $p=c(0)$ und $v=c'(0)$ ist.
\end{definition}

\noindent
Natürlich kann auch $v=Y(p)$ sein, wobei $Y$ ein zweites Vektorfeld
ist. Man notiert dazu
\begin{equation}
(\nabla_Y X)(p) := (\nabla_{Y(p)} X)(p).
\end{equation}

\noindent
Wir wollen nun eine Formel für die Richtungsableitung herleiten,
wenn das Vektorfeld in lokalen Koordinaten dargestellt ist. Sei
dazu $\varphi\colon U\to V$ mit $V\subseteq M$ eine lokale
Parametrisierung. Diese induziert den Rahmen $(g_k)$ mit
$g_k = \frac{\partial\varphi}{\partial u_k}$. Die lokale
Darstellung $\tilde X$ des Vektorfeldes $X$ sei gemäß den
Funktionen $a^k(u)$ gegeben, so dass%
\begin{equation}
\tilde X(u) = (X\circ\varphi)(u) = \sum_{k=1}^n a^k(u)g_k(u).
\end{equation}
An jedem Punkt $p=\varphi(u)$ ist das Vektorfeld also als
Linearkombination aus der Tangentialbasis an diesem Punkt dargestellt.
Der Vektor $v$ sei am Punkt $p=\varphi(u_0)$ ebenfalls als
Linearkombination aus der Tangentialbasis dargestellt:
$v = \sum_{k=1}^n v^k g_k(u_0)$.

Nun sei $\tilde c$ die lokale Darstellung der Kurve, gemäß
$c=\varphi\circ\tilde c$. Es ergibt sich
\begin{equation}
(\nabla_v X)(p) = \Pi_p((X\circ c)'(0))
= \Pi_p((X\circ\varphi\circ\tilde c)'(0))
= \Pi_p((\tilde X\circ\tilde c)'(0)).
\end{equation}
Nach der Produktregel ergibt sich
\begin{gather}
(\tilde X\circ\tilde c)'(t)
= \frac{\mathrm d}{\mathrm dt} \sum_{i=1}^n a^i g_i
= \sum_{i=1}^n \frac{\mathrm da^i}{\mathrm dt}g_i
+ \sum_{i=1}^n a^i\frac{\mathrm dg_i}{\mathrm dt}.
\end{gather}
Anwendung der Kettenregel bringt nun
\begin{equation}
\frac{\mathrm da^i}{\mathrm dt}
= \sum_{j=1}^n \frac{\partial a^i}{\partial u_j}
\frac{\mathrm d\tilde c_j}{\mathrm dt},\qquad
\frac{\mathrm dg_i}{\mathrm dt}
= \sum_{j=1}^n \frac{\partial g_i}{\partial u_j}
\frac{\mathrm d\tilde c_j}{\mathrm dt}.
\end{equation}
Nach der Kettenregel und $c(0)=\varphi(u_0)$ ergibt sich aber auch
\begin{equation}
c'(0) = (\tilde c\circ\varphi)'(0)
= \sum_{j=1}^n \tilde c_j'(0)\frac{\partial\varphi}{\partial u_j}(u_0)
= \sum_{j=1}^n \tilde c_j'(0)g_j(u_0)
= \sum_{j=1}^n v^j g_j(u_0).
\end{equation}
Der Koeffizientenvergleich ergibt $\tilde c_j'(0)=v^j$. Demnach ergibt sich
\begin{equation}
(\tilde X\circ\tilde c)'(0)
= \sum_{i,j} \frac{\partial a^i}{\partial u_j}(u_0) v^j g_i(u_0)
+ \sum_{i,j} a^i(u_0) \frac{\partial g_i}{\partial u_j}(u_0) v^j.
\end{equation}
Wir nutzen nun aus, dass die Projektion eine lineare Abbildung ist.
Die linke Seite ist eine Linearkombination aus der Tangentialbasis,
liegt also schon im Tangentialraum. Auf die linke Seite ist die
Projektion daher wirkungslos. Somit ergibt sich
\begin{equation}\label{eq:kov-Ableitung1}
(\nabla_v X)(p) = \sum_{i,j} \frac{\partial a^i}{\partial u_j}(u_0) v^j g_i(u_0)
+ \sum_{i,j} v^j a^i(u_0) \Pi_p(\frac{\partial g_i}{\partial u_j}(u_0)).
\end{equation}
Die übrig gebliebene Projektion stellen wir als Linearkombination
aus der Tangentialbasis dar. Die Koeffizienten $\Gamma_{ij}^k$
sind an der Stelle $u_0$ also durch%
\begin{equation}
\Pi_p((\partial_j g_i)(u_0))
= \Pi_p((\partial_i\partial_j\varphi)(u_0))
= \sum_{k=1}^n \Gamma_{ij}^k g_k(u_0)
\end{equation}
gegeben. Die $\Gamma_{ij}^k(u_0)$ nennt man \emph{Christoffel-Symbole}.
Auf der linken Seite von \eqref{eq:kov-Ableitung1} machen wir eine
Indexumbenennung $i:=k$. Es ergibt sich schließlich
\begin{equation}
(\nabla_v X)(p)
= \sum_{k=1}^n \bigg(\sum_{j=1}^n \frac{\partial a^k}{\partial u_j}(u_0)v^j
+\sum_{i=1}^n\sum_{j=1}^n \Gamma_{ij}^k(u_0) v^j a^i(u_0)\bigg)g_k(u_0).
\end{equation}
Kurz
\begin{equation}
\nabla_v X = \sum_k \bigg(\sum_j v^j\partial_j a^k
+\sum_{i,j} \Gamma_{ij}^k v^j a^i\bigg)g_k.
\end{equation}
Oder kürzer: $(\nabla_v X)^k = v^j \partial_j a^k + \Gamma_{ij}^k v^j a^i$.

Man kann die kovariante Ableitung analog auch für ein Kovektorfeld
$X\colon M\to T^*M$ definieren. Der Vektor $v$ verbleibt in $T_p M$.
Der einzige Unterschied ist, dass
man $X=a_k g^k$ ansetzen muss. Dann wird \eqref{eq:kov-Ableitung1} zu
\begin{equation}
(\nabla_v X)(p) = \sum_{i,j} \frac{\partial a_i}{\partial u_j}(u_0) v^j g^i(u_0)
+ \sum_{i,j} v^j a_i(u_0) \Pi_p(\frac{\partial g^i}{\partial u_j}(u_0)).
\end{equation}
Nun stellt sich noch die Frage, was
$\Pi_p((\partial_j g^i)(u_0))$
ist. Hier muss $\Pi_p$ orthogonal auf $T_p^* M$ projizieren.
Entsprechend machen wir den Ansatz
\begin{equation}
\Pi_p((\partial_j g^i)(u_0)) = \sum_{k=1}^n \Xi_{ij}^k g^k(u_0).
\end{equation}
Verblüffend gilt $\Xi_{ij}^k = -\Gamma_{kj}^i$. Setzen wir der
Einfachheit halber zunächst $\Pi_p=\id$, das ist der Fall, wenn
es keine äußere Krümmung in einen ambienten Raum gibt. Die duale
Paarung $\omega(X)=\langle\omega,X\rangle$ ergibt ein Skalarfeld,
das totale Differential davon ist
\begin{equation}
\mathrm d\langle\omega,X\rangle = \sum_j\partial_j\langle\omega,X\rangle g^j
= \sum_j (\langle\partial_j\omega,X\rangle+\langle\omega,\partial_j X\rangle)g^j.
\end{equation}
Setzt man nun $\omega:=g^b$ und $X:=g_a$, dann ergibt sich
\begin{align}
0 &= \mathrm d\delta_a^b = \mathrm d\langle g^b,g_a\rangle
= \sum_j (\langle\partial_j g^b,g_a\rangle+\langle g^b,\partial_j g_a\rangle)g^j\\
&= \sum_j (\langle{\textstyle\sum_k}\Xi_{bj}^k g^k,g_a\rangle
  +\langle g^b,{\textstyle\sum_k}\Gamma_{aj}^k g_k\rangle)g^j
= \sum_j (\Xi_{bj}^a+\Gamma_{aj}^b)g^j.
\end{align}
Koeffizientenvergleich mit dem Nullvektor bringt
$\Xi_{bj}^a+\Gamma_{aj}^b=0$.

Nun muss man nur noch argumentieren, warum das auch bei vorhandenen
Projektionen geht. Dazu braucht man lediglich festellen, dass
$\omega(X)=\omega(\Pi_p(X))$ ist. Sei dazu $V$ ein Vektorraum
und $U\subseteq V$ ein Untervektorraum von $V$. Man kann $v\in V$
nun zerlegen in $v=v_t+v_n$, wobei $v_t\in U$ und $v_n$ normal
dazu ist. Sei $\Pi$ die orthogonale Projektion auf $U$, d.\,h.
$\Pi(v):=v_t$. Sei außerdem $\omega\in U^*$. Zu zeigen ist
$\omega(v)=\omega(\Pi(v))$. Nun gilt
\begin{equation}
\omega(v) = \omega(v_t+v_n) = \omega(v_t)+\omega(v_n)
\end{equation}
und
\begin{equation}
\omega(\Pi(v)) = \omega(v_t).
\end{equation}
Zu zeigen bleibt demnach lediglich $\omega(v_n)=0$. Nun ist aber
auch vorausgesetzt, dass es auf $V$ ein Skalarprodukt
$\langle v,w\rangle$ gibt, sonst könnte man nicht sagen, was
orthogonal bedeutet. Dieses induziert die musikalischen Isomorphismen.
Demnach ist $\omega(v)=\langle\omega^\sharp,v\rangle$. Da $\omega\in U^*$
ist, muss $\omega\in U$ sein. Demnach ist
$\langle\omega^\sharp,v_n\rangle=0$, denn $\omega^\sharp\perp v_n$.

Für die kovariante Ableitung des Kovektorfeldes ergibt sich damit
\begin{equation}
\nabla_v X = \sum_k \bigg(\sum_j v^j\partial_j a_k
-\sum_{i,j} \Gamma_{kj}^i v^j a_i\bigg)g^k,
\end{equation}
bzw. kurz: $(\nabla_v X)_k = v^j\partial_j a_k-\Gamma_{kj}^i v^j a_i$.

Man führt noch die Kurzschreibweise $\nabla_i X := \nabla_{g_i} X$
ein. Für $v=g_i$ ist dann $v^j = \delta_i^j$. Somit ergibt sich
\begin{align}
(\nabla_j X)^k &= \partial_j a^k + {\textstyle\sum_i}\Gamma_{ij}^k a^i,\\
(\nabla_j X)_k &= \partial_j a_k - {\textstyle\sum_i}\Gamma_{kj}^i a_i.
\end{align}
Zu Bemerken ist noch, dass $\Gamma_{ij}^k = \Gamma_{ji}^k$ gilt,
denn $\partial_i\partial_j\varphi = \partial_j\partial_i\varphi$,
wobei $\varphi$ als zweimal stetig differenzierbar vorausgesetzt ist.

\section{Konforme Abbildungen}

Eine differenzierbare Abbildung wollen wir
\emph{konform}\index{konforme Abbildung} nennen, wenn
sie \emph{winkeltreu}\index{winkeltreu}\index{winkelerhaltend} ist.
Sei $f\colon U\to V$ eine konforme Abbildung, wobei $U\subseteq\R^n$
offen ist und $V\subseteq\R^m$ mit $n\le m$. Wir betrachten nun
einen Punkt $p\in U$ und zwei sich in diesem Punkt
schneidende Kurven $\gamma_1,\gamma_2$. Das bedeutet $p=\gamma_1(0)$
und $p=\gamma_2(0)$. Der Schnittwinkel der Kurven muss erhalten
bleiben. Das heißt, die
Bildkurven müssen im Bildpunkt den gleichen Schnittwinkel besitzen
wie die ursprünglichen. Somit muss gelten%
\begin{equation}
\cos\varphi =
\frac{\langle v_1,v_2\rangle}{|v_1|\cdot |v_2|}
= \frac{\langle(f\circ\gamma_1)'(0),(f\circ\gamma_2)'(0)\rangle}
{|(f\circ\gamma_1)'(0)|\cdot |(f\circ\gamma_2)'(0)|}
= \frac{\langle Jv_1,Jv_2\rangle}{|Jv_1|\cdot |Jv_2|},
\end{equation}
wobei
\[J:=Df(p),\quad v_1:=\gamma_1'(0),\quad v_2:=\gamma_2'(0).\]
Wir betrachten die $\gamma_k(t):=p+t\mathbf e_k$, das sind die zu
den Koordinatenachsen parallelen Geraden. Somit muss gelten%
\begin{equation}\label{eq:winkeltreu-ONB}
\delta_{ij} = \frac{\langle\mathbf e_i,\mathbf e_j\rangle}
{|\mathbf e_i|\cdot |\mathbf e_j|}
= \frac{\langle J\mathbf e_i,J\mathbf e_j\rangle}
{|J\mathbf e_i|\cdot |J\mathbf e_j|}
= \frac{g_{ij}}{|J\mathbf e_i|\cdot |J\mathbf e_j|}.
\end{equation}
Schärfer lässt sich zeigen, dass es an jedem Punkt eine reelle Zahl
$\lambda$ gibt, sodass $g_{ij} = \lambda^2\delta_{ij}$,
bzw. $G = \lambda^2 E$ in Matrix"=Schreibweise.

\begin{theorem}
Sei $J\colon\R^n\to\R^m$ eine injektive lineare Abbildung. Ist $J$
winkelerhaltend, dann gibt es eine reelle Zahl $\lambda\ne 0$, so dass
$\langle Jv,Jw\rangle = \lambda^2\langle v,w\rangle$ für alle
$v,w$ gilt.
\end{theorem}

\noindent\strong{Beweis.}
Zunächst soll gezeigt werden, dass $|Jv|$ für alle normierten
Vektoren $v$ denselben Wert besitzt. Oder pathetisch ausgedrückt,
dass die Abbildung $v\mapsto |Jv|$ auf der Einheitssphäre konstant ist.
Wir folgen dem Ansatz aus \cite{Kriegl} auf S. 277--278
»33.7 Lemma (Lineare konforme Abbildungen)«. Wir beachten
\begin{equation}
|v| = |w| \iff 0 = |v|^2 - |w|^2 = \langle v+w,v-w\rangle \iff v+w\perp v-w.
\end{equation}
Weil $J$ winkelerhaltend ist, muss für $|v|=|w|$ gelten
\begin{equation}
0 = \langle J(v+w), J(v-w)\rangle = \langle Jv+Jw,Jv-Jw\rangle
= |Jv|^2-|Jw|^2.
\end{equation}
Sei nun $\lambda:=|Jv|$ für $|v|=1$. Somit ist $|J\mathbf e_k|=\lambda$
für jeden Basisvektor $\mathbf e_k$ der Standardbasis. Gemäß
\eqref{eq:winkeltreu-ONB} gilt somit $g_{ij} = \lambda^2\delta_{ij}$.
Für $v = \sum_k v_k \mathbf e_k$ und $w = \sum_k w_k\mathbf e_k$
können wir die restliche Aussage über die Linearität von $J$
und Bilinearität des Skalarproduktes direkt ausrechnen. Das ist die
Rechnung
\begin{align*}
\langle Jv,Jw\rangle &= \langle J\sum_i v_i\mathbf e_i,J\sum_j v_j\mathbf e_j\rangle
= \sum_{i,j} v_i w_j\langle J\mathbf e_i,J\mathbf e_j\rangle
= \sum_{i,j} v_i w_j g_{ij}\\
&= \sum_{i,j} v_i w_j\lambda^2 \delta_{ij}
= \lambda^2\sum_k v_k w_k = \lambda^2\langle v,w\rangle.\;\qedsymbol
\end{align*}
Eine orientierungserhaltende konforme Abbildung zwischen Räumen
gleicher Dimension ist an jedem Punkt eine
Drehskalierung\index{Drehskalierung} des
Tangentialraums. Die Jacobi"=Matrix ist dann nämlich quadratisch,
und es gilt
\begin{equation}
\lambda^2 E = G = J^T J \iff E = (J/\lambda)^T(J/\lambda).
\end{equation}
Somit ist $J/\lambda$ eine orthogonale Matrix, und daher wegen
Orientierungserhaltung eine Rotationsmatrix. Demzufolge ist $J$ eine
um $\lambda$ skalierte Rotationsmatrix.

\begin{corollary}
Sei $U\subseteq\C$ offen und $f\colon U\to\C$. Die Funktion
$f$ ist genau dann orientierungserhaltend konform, wenn sie holomorph
ist und ihre Ableitung keine Nullstellen besitzt.\index{holomorph}
\end{corollary}

\noindent
\strong{Beweis.} Sei $f$ holomorph und $f'$ frei von Nullstellen.
Dann ist $f'(z)$ an jeder Stelle $z$ eine nichtverschwindende
komplexe Zahl, also eine Drehskalierung, denn jede solche komplexe Zahl
kann gemäß dem Körperisomorphismus
\begin{equation}
\Phi(a+b\ui) = \begin{pmatrix}a & -b\\ b & a\end{pmatrix},\;\;
\text{bzw.}\;\;\Phi(r\ee^{\ui\varphi})
= r\begin{pmatrix}\cos\varphi & -\sin\varphi\\
\sin\varphi & \cos\varphi\end{pmatrix}
\end{equation}
als Drehskalierung betrachtet werden. Eine Drehskalierung ist
offensichtlich winkelerhaltend.
Sei $f$ nun orientierungserhaltend konform. Dann muss die
Jacobi"=Matrix als Drehskalierung von der Form
\begin{equation}
Df(x,y) = \begin{pmatrix}
\partial_x u & \partial_y u\\
\partial_x v & \partial_y v
\end{pmatrix}
= \begin{pmatrix}
\partial_x u & -\partial_x v\\
\partial_x v & \partial_x u
\end{pmatrix}
\end{equation}
sein, wobei $f(z)=u+v\ui$ und $z=x+y\ui$. Somit sind die
Cauchy"=Riemann"=Gleichungen erfüllt. Infolge ist $f$ holomorph,
wobei $\Phi(f'(z))=Df(z)$.\;\qedsymbol


