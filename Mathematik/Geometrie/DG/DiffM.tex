
\chapter{Differenzierbare Mannigfaltigkeiten}

\section{Differentialgleichungen}

Sei $M$ eine differenzierbare Mannigfaltigkeit und sei $c\colon\R\to M$
eine differenzierbare Parameterkurve in $M$. Daher gibt es auch
$c'\colon\R\to TM$. Das bringt uns auf die folgende Idee. Hat man
ein durch $t$ parametrisiertes Vektorfeld
\begin{equation}
f\colon\R\times M\to TM,\quad f(t,p)\in T_p M,
\end{equation}
gegeben, dann lässt sich das Anfangswertproblem
\begin{equation}
c'(t) = f(t,c(t)),\quad c_0=c(t_0),\quad 
\end{equation}
formulieren. Für eine abstrakte Mannigfaltigkeit muss das
Anfangswertproblem aber nun in lokale Koordinaten übersetzt
werden. Sei dazu $\varphi$ eine lokale Karte und $c=\varphi\circ x$.
Anwendung der Kettenregel ergibt
\begin{equation}
c'(t) = (\varphi\circ x)'(t) = \mathrm d\varphi_{x(t)}(x'(t)).
\end{equation}
Aus $\mathrm d\varphi_{x(t)}(x'(t))=f(t,\varphi(x(t)))$ erhält man
\begin{equation}
x'(t) = f_\varphi(t,x(t)),\quad
f_\varphi(t,x):=\mathrm d\varphi_{x}^{-1}(f(t,\varphi(x)).
\end{equation}
In lokalen Koordinaten lässt sich das Anfangswertproblem also als
ein gewöhnliches Anfangswertproblem im Koordinatenraum darstellen.
Für eine abstrakte Mannigfaltigkeit ist auch nur $f_\varphi$ bekannt.
Wir wollen nun aber in Erfahrung bringen, welche Gestalt das
Anfangswertproblem nach einem Kartenwechsel bekommt. Sei $\psi$
dazu eine zweite Karte. Daraus ergibt sich der Vergleich
\begin{equation}
f(t,p)
= \mathrm d\varphi_x(f_\varphi(t,x))
= \mathrm d\psi_{\tilde x}(f_\psi(t,\tilde x)),\quad
p = \varphi(x) = \psi(\tilde x).
\end{equation}
Umformen bringt $x = (\varphi^{-1}\circ\psi)(\tilde x)$ und
\begin{equation}
f_\varphi(t,x) = (\mathrm d\varphi_x^{-1}\circ \mathrm d\psi_{\tilde x})(f_\psi(t,\tilde x))
= \mathrm d(\varphi^{-1}\circ \psi)_{\tilde x}(f_\psi(t,\tilde x)).
\end{equation}
Es gilt aber auch
\begin{equation}
x'(t) = (\varphi^{-1}\circ\psi\circ\tilde x)'(t)
= \mathrm d(\varphi^{-1}\circ\psi)_{\tilde x(t)}(\tilde x'(t)).
\end{equation}
Das Differential des Kartenwechsels hebt sich weg und man
erhält%
\begin{equation}
\tilde x'(t) = f_\psi(t,\tilde x(t))
= \mathrm d(\psi^{-1}\circ\varphi)_{x(t)}(f_\varphi(t,x(t))).
\end{equation}
Bei der Transformation des Anfangswertproblems werden die Werte des
parametrisierten Vektorfelds also mit dem Differential der
Kartenwechselabbildung transformiert.

\newpage
\section{Dynamische Systeme}

\begin{definition}[Dynamisches System]\mbox{}\\*
Ein \emdef{dynamisches System} ist eine Abbildung
$\Phi\colon T\times M\to M$, welche
die beiden Eigenschaften
\begin{gather}
\label{eq:dyn-Sys-1}
\Phi(0,x) = x,\\
\label{eq:dyn-Sys-2}
\Phi(t_1+t_2,x) = \Phi(t_2,\Phi(t_1,x))
\end{gather}
erfüllt. Man bezeichnet $M$ als \emdef{Zustandsraum} des Systems und
$T$ als \emdef{Menge der Zeitpunkte}.
Für $T=\R$ oder $T=\R^+$ spricht man von einem
\emdef{Zeit-kontinuierlichen} System, für $T=\Z$ oder $T=\N$ von einem
\emdef{Zeit-diskreten}.
\end{definition}

\noindent
Wir wollen uns nun auf Zeit-kontinuierliche Systeme beschränken,
bei denen der Zustandsraum $M$ eine differenzierbare Mannigfaltigkeit
ist. Man betrachte das autonome Anfangswertproblem
\begin{equation}\label{eq:AWP-M}
c'(t) = f(c(t)),\quad c(0)=c_0,
\end{equation}
wobei das Vektorfeld $f\colon M\to TM$ hinreichend gutartig sein soll,
so dass zu jedem $c_0$ eine eindeutige Lösung $c\colon\R\to M$
existiert. 

\begin{theorem}\label{autonom-fasert}
Besitzt das Anfangswertproblem \eqref{eq:AWP-M} zu jedem $c_0$ eine
eindeutige Lösung, dann verläuft durch jeden Punkt von $M$ genau
eine Lösung, d.\,h. keine zwei Lösungen können sich schneiden
oder berühren.
\end{theorem}
\noindent\strong{Beweis.}
Seien $c_1(t)$ und $c_2(t)$ zwei Lösungen der Dgl. und sei
$c_1(t_1)=c_2(t_2)$. Setze $a=t_1-t_2$, dann gilt $c_2(t_2)=c_1(t_2+a)$.
Es muss gezeigt werden, dass $c_2$ nur Parameter"=verschoben
zu $c_1$ um $a$ ist, d.\,h. $c_2(t)=c_1(t+a)$ für alle $t$. Dazu
definieren wir $c(t):=c_1(t+a)$. Für $c$ ergibt sich das
Anfangswertproblem
\begin{equation}
c'(t) = c_1'(t+a) = f(c_1(t+a)) = f(c(t)),\quad c(t_2)=c_1(t_2+a).
\end{equation}
Außerdem gilt
\begin{equation}
c_2'(t) = f(c_2(t)), \quad c_2(t_2)=c_1(t_2+a).
\end{equation}
Das ist beides das selbe Anfangswertproblem. Da die Lösung nach
Voraussetzung eindeutig ist, muss $c(t)=c_2(t)$
für alle $t$ sein.\;\qedsymbol

\begin{theorem}
Unter der Voraussetzung, dass es zu jedem $c_0$ eine eindeutige
Lösung des Anfangswertproblems \eqref{eq:AWP-M} gibt, ist durch
$\Phi(t,c_0)=c(t)$ ein dynamisches System gegeben.
\end{theorem}
\noindent\strong{Beweis.}
Die Eigenschaft \eqref{eq:dyn-Sys-1} ist gemäß $\Phi(0,c_0)=c_0$
trivial erfüllt. Die Eigenschaft \eqref{eq:dyn-Sys-2} bekommt
die Form $c(t_1+t_2)=\Phi(t_2,c(t_1))$. Nach Satz
\ref{autonom-fasert} verläuft durch den Zustand $c(t_1)$ genau
eine Bahn $p(t)=\Phi(t,c(t_1))$ und nach \eqref{eq:dyn-Sys-1} gilt
$p(0)=\Phi(0,c(t_1))=c(t_1)$. Dann muss $p$ zu $c$ Parameter"=verschoben
sein und es gilt $p(t)=c(t+t_1)$. Setze speziell $t=t_2$.\;\qedsymbol

\newpage
\section{Extremwerte}

\subsection{Notwendiges Kriterium}

Hat eine differenzierbare reelle Funktion $f$ an einer Stelle einen
lokalen Extremwert, dann muss dort ihre erste Ableitung $f'$
verschwinden. Daraus ergibt sich ein grundlegendes Verfahren zur
Bestimmung der Extremwerte: Man braucht nur solche Stellen $x$
untersuchen, dan denen $f'(x)=0$ ist. Diese Stellen nennt man
kritische Stellen. Jedoch muss nicht unbedingt an jeder kritischen
Stelle auch ein Extrempunkt vorliegen, es kann sich auch um einen
Sattelpunkt handeln. Daher handelt es sich bei $f'(x)=0$ nur um
ein notwendiges Kriterium, nicht aber um ein hinreichendes.

Das notwendige Kriterium gilt auch allgemeiner für eine Funktion $f$
von mehreren Variablen. Hier muss $\mathrm df(x)=0$ sein.
Wir können dieses Kriterium auch für Skalarfelder auf
Mannigfaltigkeiten formulieren.

Sei $M$ eine differenzierbare Mannigfaltigkeit und sei
$f\colon M\to\R$ differenzierbar. Sei $\varphi$ eine lokale
Karte. Hat $f\circ\varphi$ an der Stelle $u$ einen lokalen Extremwert,
dann muss wie gesagt $\mathrm d(f\circ\varphi)(u)=0$ sein.
Mit $p:=\varphi(u)$ und Kettenregel ergibt sich%
\begin{equation}
0 = \mathrm d(f\circ\varphi)_u = \mathrm df_p\circ\mathrm d\varphi_u.
\end{equation}
An keiner Stelle $u$ kann $\mathrm d\varphi_u=0$ sein, da
$\mathrm d\varphi_u$ als injektiv vorausgesetzt ist. Demnach muss
$\mathrm df_p=0$ sein.


\subsection{Hinreichendes Kriterium}

Sei $f\colon U\to\R$ und $U\subseteq\R^n$ offen. Dann definiert
man die Hesse"=Matrix als $H_{ij}:=\partial_i\partial_j f$.
Ist nun $x$ eine kritische Stelle von $f$, dann ist ein
hinreichendes Kriterium für einen Extremwert, dass $H(f)(x)$ nicht
indefinit sein darf. Ist $H$ positiv definit, liegt ein lokales
Minimum vor, ist $H$ negativ definit, liegt ein lokales Maximum
vor. Ist $H$ indefinit, handelt es ich um einen Sattelpunkt.
Ist $H$ semidefinit, versagt das Kriterium.

Da sich das notwendige Kriterium auf Mannigfaltigkeiten formulieren
lässt, müsste dies beim hinreichenden Kriterium auch möglich sein.
Sei $f\in C^2(M,\R)$ und $\varphi$ eine lokale Karte von $M$. Dann
gilt%
\begin{align}
\partial_i\partial_j(f\circ\varphi)
&= \partial_i(\mathrm df(\partial_j\varphi))
= \partial_i(\sum_k \partial_k f\partial_j\varphi_k)\\
&= \sum_k \partial_i\partial_k f\partial_j\varphi_k
+ \sum_k \partial_k f\partial_i\partial_j\varphi_k,
\qquad (\partial_j\varphi_k=\delta_{kj})\\
&= \partial_i\partial_j f + \sum_k\Gamma_{ij}^k\partial_k f.
\end{align}
Für die Christoffel"=Symbole
$\Gamma_{ij}^k = \partial_i\partial_j\varphi_k$
benötigt man entweder eine Karte oder einen Zusammenhang.
Ein genauer Blick klärt uns jedoch darüber auf, dass der Summand
an den kritischen Stellen wegen $\mathrm df=0$ entfällt, denn
dann ist auch $\partial_k f=0$ für alle $k$.

Definiert man in Anlehnung an den Nabla"=Operator die formale Notation
$\mathrm d := \sum_k\mathrm dx^k\partial_k$,
dann kann man formal rechnen%
\begin{equation}\textstyle
\mathrm d\otimes\mathrm d
= (\sum_i\mathrm dx^i\partial_i)\otimes(\sum_j\mathrm dx^j\partial_j)
= \sum_{i,j} (\partial_i\partial_j)\,\mathrm dx^i\otimes\mathrm dx^j.
\end{equation}
Man definiert nun den reduzierten Hesse-Tensor als%
\begin{equation}\textstyle
H(f) = (\mathrm d\otimes\mathrm d)(f)
= \sum_{i,j} \partial_i\partial_j f\,\mathrm dx^i\otimes\mathrm dx^j.
\end{equation}

\newpage
\section{Extremwerte unter Nebenbedingungen}

Manchmal möchte man für eine Funktion $f(x,y)$ ein Optimum finden,
wobei der Definitionsbereich durch eine Nebenbedingung $g(x,y)=0$
eingeschränkt wird. Laut dem Verfahren der lagrangeschen
Multiplikatoren ist die Gleichung $\nabla f = \lambda\nabla g$
eine notwendige Bedingung dafür. Eigentlich benötigt man anstelle
der Gradienten bloß die totalen Differentiale, es ist nur so, dass
im Koordinatenraum beides koinzidiert. Infolgedessen ist das
Verfahren allgemein für Funktionen auf Mannigfaltigkeiten
formulierbar.

\begin{theorem}[Notwendiges Kriterium]\mbox{}\\*
Sei $M$ eine zweidimensionale differenzierbare Mannigfaltigkeit.
Seien $f\colon M\to\R$ und $g\colon M\to\R$
differenzierbar. Sei $N:=g^{-1}(0)$, wobei 0 ein regulärer Wert 
von $g$ ist. Hat die Einschränkung $f|_N$ an der Stelle $p$ einen
lokalen Extremwert, dann muss $\mathrm df_p$ kollinear zu
$\mathrm dg_p$ sein, d.\,h. es gibt ein $\lambda\in\R$ mit
$\mathrm df_p = \lambda\mathrm dg_p$, bzw. es ist
$\mathrm df_p\land\mathrm dg_p=0$.
\end{theorem}
\noindent\strong{Beweis.}
Bei einer lokalen Extremstelle $p$ liegt eine waagerechte Tangente vor.
Das bedeutet, dass die Richtungsableitung $\mathrm df_p(v)$ für alle
Vektoren $v$ verschwindet, die tangential an $N$ liegen. Zur
Bestätigung dieser Beobachtung betrachten wir eine Parametrisierung
$\varphi\colon (-\varepsilon,\varepsilon) \to N$ mit
$\varphi(0)=p$ und $\varphi'(0)\ne 0$. Die Prämisse lautet nun
$(f\circ\varphi)'(0)=0$. Gemäß Kettenregel ist
\begin{equation}
0 = (f\circ\varphi)'(0) =  \mathrm df_p(\varphi'(0)).
\end{equation}
Da $\mathrm df_p$ eine lineare Abbildung ist, ist
auch $\mathrm df_p(v)=0$ für alle $v\in\R\varphi'(0)$.
Sei nun $e$ orthogonal zu $\varphi'(0)$, dann ist
$(e,\varphi'(0))$ eine Orthogonalbasis von $T_p M$. Gemäß der
Vorbetrachtung ist $\mathrm df_p$ alleinig von $v\in\R e$ abhängig.

Die Funktion $g$ verschwindet definitionsgemäß auf ihrer
Nullstellenmenge $N$, ist dort also konstant. Demnach
ist auch $(g\circ\varphi)'(0)=0$. Nach der gleichen Argumentation
kann $\mathrm dg_p$ also auch nur von $v\in\R e$ abhängig sein.

Es muss also ein $\lambda\in\R$ geben, so dass
$\mathrm df_p(v) = \mathrm dg_p(\lambda v)$ für alle $v\in T_p M$.
Aufgrund der Homogenität linearer Abbildungen ergibt sich daraus
\begin{equation}
\mathrm df_p(v) = \lambda\mathrm dg_p(v).\;\qedsymbol
\end{equation}
In Retrospektive kann man das ganze auch etwas abstrakter
betrachten: Die Nullstellenmenge $N$ ist eine Untermannigfaltigkeit von
$M$ und es gilt $T_p N=\operatorname{ker}(\mathrm dg_p)=\R\varphi'(0)$.
Die Beobachtung war gewesen, dass
$T_p N\subseteq \operatorname{ker}(\mathrm df_p)$
sein muss.

Hat man für ein lokales Koordinatensystem $\varphi\colon U\to M$ die
lokalen Darstellungen $\tilde f = f\circ\varphi$ und
$\tilde g = g\circ\varphi$, dann bekommt die Bedingung laut
\eqref{eq:Richtungsableitung-lokal} die klassische Form
\begin{equation}
\nabla\tilde f = \lambda\nabla\tilde g.
\end{equation}
Bei der praktischen Betrachtung des Verfahrens tut sich nun die
Frage auf, inwiefern das Verfahren numerischen Methoden zugänglich
ist. Dem Ansatz nach entsteht ein im Allgemeinen nichtlineares
Gleichungssystem, das man auch numerisch lösen könnte. Eigentlich
würde man auch gerne das Gradientenabstiegsverfahren auf das
ursprüngliche Optimierungsproblem anwenden, jedoch ist dieses
zunächst nur auf Optimierungsprobleme ohne Nebenbedingungen anwendbar.
Allerdings gibt es einen Trick, mit dem sich das Optimierungsproblem
mit Nebenbedingungen als eines ohne Nebenbedingungen formulieren lässt.

Für diesen Trick sei
\begin{equation}
L\colon M\times\R\to\R,\quad L(p,\lambda) := f(p)-\lambda g(p).
\end{equation}
Man bezeichne $L$ als Lagrange"=Funktion. Einer kritischen Stelle unter
Nebenbedingung entspricht nun eine gewöhnliche kritische Stelle von $L$.
Um dies einzusehen, gehen wir von der gewöhnlichen notwendigen
Bedingung $\mathrm dL=0$ aus. Einsetzen von $L$ ergibt%
\begin{equation}
0 = \mathrm dL = \mathrm df-\lambda\mathrm dg-g\mathrm d\lambda.
\end{equation}
Da $f,g$ nicht von $\lambda$ abhängig sind, ist $\mathrm d\lambda$
linear unabhängig von $\{\mathrm df,\mathrm dg\}$. Dies gestattet
die Aufteilung der Gleichung in $g\mathrm d\lambda=0$
und $\mathrm df-\lambda\mathrm dg=0$. Daraus ergibt sich wie
gewünscht die Nebenbedingung $g=0$ und das notwendige Kriterium
$\mathrm df=\lambda\mathrm dg$.

Man darf nun allerdings nicht voreilig sein und pauschal davon
ausgehen, numerische Verfahren sofort anwenden zu können. Nämlich
lässt $\mathrm dL=0$ auch Sattelpunkte zu.
Nehmen wir dazu zunächst den flachen Raum $M=\R^2$ an. Nun gibt
die Definitheit der Hesse"=Matrix $H(L)(\lambda,x,y)$ Aufschluss
über die Art von Verhalten an den kritischen Stellen $(\lambda,x,y)$.

Diese spezielle Hesse"=Matrix wird geränderte Hesse"=Matrix genannt.
Es ergibt sich%
\begin{equation}
H = \begin{bmatrix}
\partial_\lambda\partial_\lambda L & \partial_\lambda\partial_x L & \partial_\lambda \partial_y L\\
\partial_x\partial_\lambda L & \partial_x\partial_x L & \partial_x\partial_y L\\
\partial_y\partial_\lambda L & \partial_y\partial_x L & \partial_y\partial_y L
\end{bmatrix}
= \begin{bmatrix}
0
& -\partial_x g
& -\partial_y g\\
-\partial_x g
& \partial_x\partial_x f-\lambda\partial_x\partial_x g
& \partial_x\partial_y f-\lambda\partial_x\partial_y g\\
-\partial_y g
& \partial_y\partial_x f-\lambda\partial_y\partial_x g
& \partial_y\partial_y f-\lambda\partial_y\partial_y g
\end{bmatrix}.
\end{equation}
Wegen $H_{00}=0$ kann $H$ nur indefinit oder
semidefinit sein: Setze $\mathbf e_1=(1,0,0)^T$ in die Definition der
Definitheit ein, das ergibt $\mathbf e_1^T H\mathbf e_1 = 0$. Der
Hauptminor $[H]_{33} = -(\partial_x g)^2$ ist außerdem nichtpositiv.
Da es sich um einen führenden Hauptminor handelt,
kann $H$ weder positiv definit noch positiv semidefinit sein. Daher
ist $H$ negativ semidefinit, das hinreichende Kriterium versagt
in diesem Fall. Wir können nicht ausschließen, dass auch Sattelpunkte
vorliegen.

Das wirkt auf den ersten Blick recht enttäuschend. Wir können
eine Funktion $L$ aber so adaptieren, dass ihre kritischen Stellen zu
Minimumsstellen werden. Wegen $\mathrm dL=0$ ist jede kritische
Stelle eine Nullstelle von $\mathrm dL$. Demnach muss
$|\mathrm dL|$ bzw. $|\mathrm dL|^2$ an der Stelle ein
lokales Minimum haben. Für die numerischen Verfahren kann man dabei
das Differential $\mathrm dL$ auch numerisch berechnen lassen.



