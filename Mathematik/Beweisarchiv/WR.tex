
\chapter{Wahrscheinlichkeitsrechnung}

\section{Diskrete Wahrscheinlichkeitsräume}

\begin{Definition}[Diskreter Wahrscheinlichkeitsraum]%
\label{def:discrete-prob-space}\newlinefirst
Sei $\Omega$ eine höchstens abzählbare Menge. Das
Paar $(\Omega,P)$ nennt man diskreten Wahrscheinlichkeitsraum,
wenn
\[P\colon 2^\Omega\to [0,1],\quad P(A):=\sum_{\omega\in A} P(\{\omega\})\]
die Eigenschaft $P(\Omega) = 1$ besitzt.
\end{Definition}
Bemerkung: Man schreibt auch $P(\omega):=P(\{\omega\})$.

\begin{Definition}[Reelle Zufallsgröße]%
\index{Zufallsgröße}\newlinefirst
Sei $(\Omega,P)$ ein diskreter Wahrscheinlichkeitsraum.
Eine Funktion $X\colon\Omega\to\R$ nennt man Zufallsgröße.
Die Verteilung von $X$ ist definiert gemäß $P_X(A):=P(X^{-1}(A))$.
\end{Definition}

\begin{Definition}[Bedingte Wahrscheinlichkeit]%
\index{bedingte Wahrscheinlichkeit}\newlinefirst
Seien $A,B\subseteq\Omega$ und sei $P(B)\ne 0$. Dann nennt man
\[P(A\mid B) := \frac{P(A\cap B)}{P(B)}\]
die bedingte Wahrscheinlichkeit von $A$, gegeben $B$.
\end{Definition}

\begin{Lemma}\label{indicator-disjoint}
Seien $A,B$ disjunkt. Seien die $A_i$ disjunkt. Dann gilt
\begin{gather*}
1_{A\cup B} = 1_A + 1_B,\\
1\{\bigcup_{i\in I} A_i\} = \sum_{i\in I} 1\{A_i\}.
\end{gather*}
\end{Lemma}
\begin{Beweis}
Es gilt
\begin{align*}
1_{A\cup B}(\omega) &= [\omega\in A\cup B]
= [\omega\in A\lor\omega\in B]
\stackrel{\text{(P)}}= [\omega\in A\oplus\omega\in B]\\
&= [\omega\in A] + [\omega\in B] = 1_A(\omega) + 1_B(\omega).
\end{align*}
Die allgemeine Rechnung ist
\[1\{\bigcup_{i\in I} A_i\}(\omega) = [\omega\in\bigcup_{i\in I} A_i]
= [\exists i\in I\colon \omega\in A_i]
\stackrel{\text{(P)}}= \sum_{i\in I} [\omega\in A_i]
= \sum_{i\in I} 1\{A_i\}(\omega).\]
Gleichung (P) gilt hierbei laut Prämisse.\,\qedsymbol
\end{Beweis}

\newpage
\begin{Satz}[Additivität des Wahrscheinlichkeitsmaßes]%
\label{prob-additivity}\newlinefirst
Seien die $A_i$ paarweise disjunkte Mengen. Dann gilt
\[P(\bigcup_{i\in I} A_i) = \sum_{i\in I} P(A_i).\]
Für zwei disjunkte Menge $A,B$ gilt speziell
\[P(A\cup B) = P(A) + P(B).\]
\end{Satz}

\begin{Beweis}[Beweis 1]
Weil $A\cap B=\emptyset$ gilt, ist $[\omega\in A\cup B]
= [\omega\in A]+[\omega\in B]$. Deshalb gilt
\begin{gather*}
P(A\cup B) = \sum_{\omega\in A\cup B} P(\{\omega\})
= \sum_{\omega\in\Omega} [\omega\in A\cup B] P(\{\omega\})\\
= \sum_{\omega\in\Omega} ([\omega\in A]+[\omega\in B]) P(\{\omega\})
= \sum_{\omega\in\Omega} [\omega\in A]P(\{\omega\})
+ \sum_{\omega\in\Omega} [\omega\in B]P(\{\omega\})\\
= \sum_{\omega\in A} P(\{\omega\}) + \sum_{\omega\in B} P(\{\omega\})
= P(A)+B(B).
\end{gather*}
Nun allgemein. Weil die $A_i$ disjunkt sind, gilt
$[\omega\in\bigcup_{i\in I} A_i] = \sum_{i\in I} [\omega\in A_i]$. Deshalb gilt
\begin{gather*}
P(\bigcup_{i\in I} A_i)
= \sum_{\omega\in\Omega}[\omega\in\bigcup_{i\in I} A_i]P(\{\omega\})
= \sum_{\omega\in\Omega}\sum_{i\in I}[\omega\in A_i]P(\{\omega\})\\
= \sum_{i\in I}\sum_{\omega\in\Omega}[\omega\in A_i]P(\{\omega\})
= \sum_{i\in I}\sum_{\omega\in A_i}P(\{\omega\})
= \sum_{i\in I}P(A_i).\,\qedsymbol
\end{gather*}
\end{Beweis}
\begin{Beweis}[Beweis 2]
Laut Satz \ref{prob-as-expected-value},
Lemma \ref{indicator-disjoint}
und Satz \ref{expected-value-op-linear} gilt
\[P(A\cup B) = E(1_{A\cup B}) = E(1_A+1_B) = E(1_A) + E(1_B)
= P(A) + P(B).\]
Die allgemeine Rechnung ist
\[P(\bigcup_{i\in I} A_i) = E(1\{\bigcup_{i\in I} A_i\})
= E(\sum_{i\in I} 1\{A_i\})
= \sum_{i\in I} E(1\{A_i\}) = \sum_{i\in I} P(A_i).\]
\end{Beweis}

\begin{Satz}
Sei $(\Omega,P)$ ein diskreter Wahrscheinlichkeitsraum in Form von Def.
\ref{def:discrete-prob-space}. Der Raum ist in Form des Tripels
$(\Omega,2^\Omega,P)$ ein Wahrscheinlichkeitsraum, denn das Maß
$P$ erfüllt die drei kolmogorowschen Axiome.
\end{Satz}
\begin{Beweis}
Die ersten beiden Axiome, $(\forall A\colon P(A)\ge 0)$ und
$P(\Omega)=1$, gelten per Definition. Das dritte Axiom, die Additivität,
gilt laut Satz \ref{prob-additivity}. Dass es sich bei $2^\Omega$
um eine sigma-Algebra handelt, ist kaum einer ausdrücklichen
Erwähnung wert.\,\qedsymbol
\end{Beweis}

\begin{Satz}[Gesetz der totalen Wahrscheinlichkeit]%
\index{Gesetz der totalen Wahrsch.}
Sei $Z$ eine Zerlegung der Ergebnismenge
$\Omega$ in paarweise disjunkte nichtleere Mengen $B\in Z$. Dann gilt
\[P(A) = \sum_{B\in Z} P(A\mid B)P(B).\]
\end{Satz}

\begin{Beweis}
Es gilt
\begin{align*}
P(A) &= P(A\cap\Omega) = P(A\cap\bigcup_{B\in Z} B)
= P(\bigcup_{B\in Z} (A\cap B))\\
&= \sum_{B\in Z} P(A\cap B)
= \sum_{B\in Z} P(A\mid B)P(B).\,\qedsymbol
\end{align*}
\end{Beweis}

\begin{Satz}[Gesetz der totalen Wahrscheinlichkeit für Zufallsgrößen]%
\label{total-prob-rv}\newlinefirst
Seien $X,Y\colon\Omega\to\Omega'$ Zufallsgrößen. Dann gilt%
\[P(Y\in A) = \sum_{x\in X(\Omega)} P(Y\in A\mid X=x)P(X=x),\]
speziell
\[P(Y=y) = \sum_{x\in X(\Omega)} P(Y=y\mid X=x)P(X=x).\]
\end{Satz}

\begin{Beweis}
Sei $Z=X(\Omega)$. Zunächst gilt
\[\Omega = X^{-1}(Z) = X^{-1}(\bigcup_{x\in Z} \{x\})
= \bigcup_{x\in Z} X^{-1}(x)\]
gemäß Satz \ref{preimg-dl}, und gemäß Satz
\ref{disjoint-preimg} ist das eine Vereinigung nichtleerer
paarweise disjunkter Mengen. Laut dem Gesetz der totalen
Wahrscheinlichkeit gilt daher%
\begin{align*}
P(Y\in A) &= P(Y^{-1}(A)) = P(Y^{-1}(A)\cap\Omega)
= \sum_{x\in Z} P(Y^{-1}(A)\mid X^{-1}(x))P(X^{-1}(x))\\
&= \sum_{x\in Z} P(Y\in A\mid X=x)P(X=x).\,\qedsymbol
\end{align*}
\end{Beweis}

\begin{Definition}[Erwartungswert]%
\index{Erwartungswert}\label{def:expected-value}\newlinefirst
Sei $(\omega_k)$ eine beliebige Abzählung von $\Omega$.
Ist die Reihe $\sum_{k=0}^{|\Omega|} X(\omega_k)P(\{\omega_k\})$
absolut konvergent, dann nennt man%
\[E(X) := \sum_{\omega\in\Omega} X(\omega)P(\{\omega\})\]
den Erwartungswert von $X$.
\end{Definition}

\begin{Satz}\label{prob-transform}
Für $g\colon\R\to\R$ gilt
\[E(g\circ X) = \sum_{x\in X(\Omega)} g(x)P(X^{-1}(x))
= \sum_{x\in X(\Omega)} g(x)P(X=x).\]
\end{Satz}
\strong{Beweis.} Zunächst gilt
\begin{gather*}
\sum_{\substack{\omega\in\Omega\\ X(\omega)=x}}P(\omega)
= P(\bigcup_{\substack{\omega\in\Omega\\ X(\omega)=x}} \{\omega\})
= P(\{\omega\in\Omega\mid X(\omega)=x\})
= P(X^{-1}(x)).
\end{gather*}
Da die Reihe zu $E(g\circ X)$ nach Def. \ref{def:expected-value}
absolut konvergent ist, darf sie beliebig umgeordnet werden und
man bekommt
\begin{gather*}
E(g\circ X) = \sum_{\omega\in\Omega}g(X(\omega))P(\omega)
= \sum_{x\in X(\Omega)}\sum_{\substack{\omega\in\Omega\\ X(\omega)=x}} g(x)P(\omega)
= \sum_{x\in X(\Omega)} g(x)\sum_{\substack{\omega\in\Omega\\ X(\omega)=x}}P(\omega)\\
= \sum_{x\in X(\Omega)} g(x)P(X^{-1}(x)).\;\qedsymbol
\end{gather*}

\begin{Satz}
Es gilt
\[E(X) = \sum_{x\in X(\Omega)} xP(X=x).\]
\end{Satz}
\begin{Beweis} Spezialisierung von Satz \ref{prob-transform} mit
$g:=\id$.\,\qedsymbol
\end{Beweis}

\begin{Satz}\label{expected-value-op-linear}
Der Erwartungswertoperator ist ein lineares Funktional,
das heißt, es gilt $E(aX)=aE(X)$ und $E(X+Y)=E(X)+E(Y)$. 
\end{Satz}
\strong{Beweis.} Aufgrund der Konvergenz der Reihen gilt
\[E(aX) = \sum_{\omega\in\Omega}aX(\omega)P(\omega)
= a\sum_{\omega\in\Omega}X(\omega)P(\omega) = aE(X)\]
und
\begin{align*}
E(X+Y) &= \sum_{\omega\in\Omega} (X(\omega)+Y(\omega))P(\omega)
= \sum_{\omega\in\Omega} (X(\omega)P(\omega)+Y(\omega)P(\omega))\\
&= \sum_{\omega\in\Omega} X(\omega)P(\omega)
+ \sum_{\omega\in\Omega} Y(\omega)P(\omega) = E(X)+E(Y).\;\qedsymbol
\end{align*}

\begin{Satz} Ist $X\le Y$, dann ist auch $E(X)\le E(Y)$.
\end{Satz}
\strong{Beweis.} Gemäß $P(\omega)\ge 0$ ist
\begin{gather*}
X\le Y\iff X(\omega)\le Y(\omega)\iff 0\le Y(\omega)-X(\omega)
\iff 0\le (Y(\omega)-X(\omega))P(\omega).
\end{gather*}
Somit hat man
\begin{gather*}
X\le Y\implies 0\le E(Y-X) = \sum_{\omega\in\Omega} (Y(\omega)-X(\omega))P(\omega),
\end{gather*}
und gemäß Linearität daher
\begin{gather*}
X\le Y\implies 0\le E(Y-X) = E(Y)-E(X) \iff E(X)\le E(Y).\;\qedsymbol
\end{gather*}

\begin{Definition}[Unabhängige Ereignisse]%
\index{unabhängige Ereignisse}\newlinefirst
Zwei Ereignisse $A,B$ heißen unabhängig, falls $P(A\cap B)=P(A)P(B)$.
\end{Definition}

\begin{Definition}[Unabhängige Zufallsgrößen]%
\index{unabhängige Zufallsgrößen}\newlinefirst
Zwei Zufallsgrößen $X,Y\colon\Omega\to\R$ heißen unabhängig, wenn
die Ereignisse $\{X\in A\}$ und $\{X\in B\}$
für alle Mengen $A,B\subseteq\R$ unabhängig sind.
\end{Definition}

\begin{Satz}\label{rand-var-independence-char}
Zwei Zufallsgrößen $X,Y\colon\Omega\to\R$ sind genau dann unabhängig,
wenn für alle $x\in X(\Omega)$ und $y\in Y(\Omega)$ gilt:
\[P(X=x,Y=y)= P(X=x)P(Y=y).\]
\end{Satz}
\strong{Beweis.} Sind $X,Y$ unabhängig, dann ist
\begin{align*}
P(X=x,Y=y) &= P(\{X\in\{x\}\}\cap\{Y\in\{y\}\})
= P(\{X\in\{x\}\})P(\{Y\in\{y\}\})\\
&= P(X=x)P(Y=y).
\end{align*}
Umgekehrt gelte nun $P(X=x,Y=y)=P(X=x)P(Y=y)$, dann ist
\begin{gather*}
P(\{X\in A\}\cap\{Y\in B\})
= P(\bigcup_{x\in A}\{X=x\}\cap\bigcup_{y\in B}\{Y=y\})\\
= P(\bigcup_{x\in A}\bigcup_{y\in B}(\{X=x\}\cap\{Y=y\}))
= \sum_{x\in A}\sum_{y\in B}P(\{X=x\}\cap\{Y=y\})\\
= \sum_{x\in A}\sum_{y\in B}P(X=x)P(Y=y)
= \sum_{x\in A}P(X=x)\sum_{y\in B}P(Y=y)\\
= P(\bigcup_{x\in A}\{X=x\})P(\bigcup_{y\in B}\{Y=y\})
= P(X\in A)P(Y\in B).\;\qedsymbol
\end{gather*}

\begin{Definition}[Bedingter Erwartungswert]%
\index{bedingter Erwartungswert}\index{Erwartungswert!bedingter}%
\label{def:cond-expected-value}\newlinefirst
\[E(X\mid A) = \frac{E(1_A X)}{P(A)} = \frac{1}{P(A)}\sum_{\omega\in A} X(\omega)P(\{\omega\}).\]
\end{Definition}

\begin{Satz} Es gilt
\[E(X\mid A) = \frac{1}{P(A)}\sum_x xP(\{X=x\}\cap A)
= \sum_x xP(X=x\mid A),\]
wobei sich die Summe über alle $x\in X(\Omega)$ erstreckt.
\end{Satz}
\strong{Beweis.} Man kann rechnen
\begin{align*}
E(1_A X) &= \sum_{\omega\in\Omega} 1_A(\omega) X(\omega) P(\{\omega\})
= \sum_x\sum_{\omega\in X^{-1}(x)} 1_A(\omega) X(\omega) P(\{\omega\})\\
&= \sum_x x\sum_{\omega\in X^{-1}(x)} 1_A(\omega) P(\{\omega\})
= \sum_x x\sum_{\omega\in X^{-1}(x)\cap A} P(\{\omega\})\\
&= \sum_x x P(X^{-1}(x)\cap A),
\end{align*}
wobei $X^{-1}(x) = \{X=x\}$.\;\qedsymbol

\begin{Satz}\label{prob-as-expected-value}
Es gilt $P(A) = E(1_A)$, wobei $1_A$ die Indikatorfunktion ist.
\end{Satz}
\begin{Beweis}
Gemäß Definition des Erwartungswertes ist
\[E(1_A) = \sum_{\omega\in\Omega} 1_A(\omega)P(\{\omega\})
= \sum_{\omega\in A}P(\{\omega\}) = P(A).\,\qedsymbol\]
\end{Beweis}

\begin{Satz}
Es gilt $P(A\mid B) = E(1_A\mid B)$, wobei $1_A$ die Indikatorfunktion ist.
\end{Satz}
\begin{Beweis}
Gemäß Definition \ref{def:cond-expected-value}
und Satz \ref{prob-as-expected-value} ist
\[E(1_A\mid B) = \frac{E(1_A 1_B)}{P(B)} = \frac{E(1_{A\cap B})}{P(B)}
= \frac{P(A\cap B)}{P(B)} = P(A\mid B).\,\qedsymbol\]
\end{Beweis}

\begin{Satz}
Der Erwartungswert ist der Schwerpunkt der Wahrscheinlichkeitsmassen.
\end{Satz}
\begin{Beweis} Der Schwerpunkt $s$ ist charakterisiert durch die folgende
Gleichgewichtsbedingung, die wie folgt äquivalent umgeformt werden
darf:
\begin{gather*}
\sum_{x\in X(\Omega)}\!\! (s-x)P(X=x) = 0
\iff s\underbrace{\sum_{x\in X(\Omega)}\!\! P(X=x)}_{=1}\;
- \sum_{x\in X(\Omega)}\!\! xP(X=x) = 0\\
\iff s = \sum_{x\in X(\Omega)}\!\! xP(X=x) \iff s = E(X).\,\qedsymbol
\end{gather*}
\end{Beweis}

\newpage
\begin{Satz}
Für $X\colon\Omega\to\R$ und $g\colon\R\to\R$ gilt
\[P(g(X)=y) = P((g\circ X) = y) = \sum_{\mathclap{x\in g^{-1}(y)}} P(X=x)
= \sum_{\mathclap{x:g(x)=y}} P(X=x).\]
\end{Satz}
\begin{Beweis}
Es findet sich
\begin{gather*}
P(g(X)=y) = P((g\circ X)^{-1}(\{y\})) = P(X^{-1}(g^{-1}(\{y\}))
= P_X(g^{-1}(\{y\}))\\
= P_X(\bigcup\nolimits_{x\in g^{-1}(\{y\})} \{x\})
= \sum_{\mathclap{x\in g^{-1}(\{y\})}} P_X(\{x\})
= \sum_{\mathclap{x\in g^{-1}(\{y\})}} P(X=x).\,\qedsymbol
\end{gather*}
\end{Beweis}

\begin{Satz}\label{prob-fn2-preimg}
Für $X,Y\colon\Omega\to\R$ und $g\colon\R^2\to\R$ gilt
\[P(g(X,Y)=a) = \sum_{(x,y)\mathrlap{:g(x,y)=a}}P(X=x, Y=y)
= \sum_{(x,y)\mathrlap{\in X(\Omega)\times Y(\Omega)}} P(\{X=x\}\cap\{Y=y\})[g(x,y)=a].\]
\end{Satz}
\begin{Beweis}
Es findet sich
\begin{gather*}
P(g(X,Y)=a) = P(\{\omega\in\Omega\mid g(X(\omega),Y(\omega))=a\})\\
= P(\{\omega\in\Omega\mid \exists (x,y)\colon g(x,y)=a\land X(\omega)=x\land Y(\omega)=y\})\\
= P(\{\omega\in\Omega\mid \exists (x,y)\in \{(x,y)\mid g(x,y)=a\}\colon X(\omega)=x\land Y(\omega)=y\})\\
= P(\bigcup_{(x,y)\mathrlap{:g(x,y)=a}} \{\omega\in\Omega\mid X(\omega)=x\land Y(\omega)=y\})
= P(\bigcup_{(x,y)\mathrlap{:g(x,y)=a}} X^{-1}(x)\cap Y^{-1}(y))\\
= \sum_{(x,y)\mathrlap{:g(x,y)=a}} P(X^{-1}(x)\cap Y^{-1}(y))
= \sum_{(x,y)\mathrlap{:g(x,y)=a}} P(X=x,Y=y).\,\qedsymbol
\end{gather*}
\end{Beweis}

\begin{Satz}
Für unabhängige Zufallsgrößen $X,Y$ gilt
\begin{gather*}
P(X+Y=a) = \sum_{\mathclap{x\in X(\Omega)}} P(X=x)P(Y=a-x),\\
P(X-Y=a) = \sum_{\mathclap{x\in X(\Omega)}} P(X=x)P(Y=x-a).
\end{gather*}
\end{Satz}
\begin{Beweis}
Es findet sich
\begin{align*}
P(X+Y=a) &\stackrel{\text(1)}= \sum_{(x,y)\mathrlap{:x+y=a}} P(X=x,Y=y)
\stackrel{\text(2)}= \sum_{(x,y)\mathrlap{:x+y=a}}P(X=x)P(Y=y)\\
&= \sum_{(x,y)}P(X=x)P(Y=y)[x+y=a]
= \sum_x P(X=x)P(Y=a-x).
\end{align*}
Hierbei gilt (1) laut Satz \ref{prob-fn2-preimg}
und (2) laut Satz \ref{rand-var-independence-char}.\,\qedsymbol
\end{Beweis}

\begin{Satz}
Für $X,Y\colon\Omega\to\R$ und $g\colon\R^2\to\R$ gilt
\[E(g(X,Y)) = \sum_{(x,y)} g(x,y)P(X=x,Y=y),\]
wobei die Summe die $(x,y)\in X(\Omega)\times Y(\Omega)$ durchläuft.
\end{Satz}
\begin{Beweis}
Mit der Abkürzung $A_{xy}:=\{\omega\in\Omega\mid X(\omega)=x\land Y(\omega)=y\}$
findet sich%
\begin{gather*}
E(g(X,Y)) = \sum_{\omega\in\Omega} g(X,Y)(\omega)P(\{\omega\})
= \sum_{\omega\in\Omega} g(X(\omega),Y(\omega))P(\{\omega\})\\
= \sum_{(x,y)}\sum_{\omega\in A_{xy}} g(x,y)P(\{\omega\})
= \sum_{(x,y)}g(x,y)\sum_{\mathclap{\omega\in A_{xy}}} P(\{\omega\})
= \sum_{(x,y)}g(x,y)P(X=x,Y=y).
\end{gather*}
Diese Rechnung ist anlog zu der im Beweis von Satz \ref{prob-transform}.\,\qedsymbol
\end{Beweis}

\begin{Satz}[Siebformel]\newlinefirst
Es gilt $\displaystyle P(\bigcup_{i=1}^n A_i)
= \sum_{\mathclap{{\scriptstyle J\subseteq\{1,\ldots,n\}}\atop{\scriptstyle J\ne\emptyset}}}
(-1)^{|J|+1}P(\bigcap_{j\in J} A_j)$.
\end{Satz}
\begin{Beweis}
Laut Satz \ref{prod-1-minus} gilt
\[\prod_{i=1}^n 1_{\Omega\setminus A_i}(\omega)
= \prod_{i=1}^n (1-1_{A_i}(\omega))
= \sum_{J\subseteq\{1,\ldots,n\}}(-1)^{|J|}\prod_{j\in J}1_{A_j}(\omega),\]
also
\[1_{\Omega\setminus\bigcup_{i=1}^n A_i}(\omega)
= 1_{\bigcap_{i=1}^n\Omega\setminus A_i}(\omega)
= \sum_{J\subseteq\{1,\ldots,n\}}(-1)^{|J|}1_{\bigcap_{j\in J} A_j}(\omega).\]
Ergo gilt
\begin{align*}
1 - P(\bigcup_{i=1}^n A_i) &= P(\Omega\setminus\bigcup_{i=1}^n A_i)
= \sum_{\omega\in\Omega}P(\{\omega\})1_{\Omega\setminus\bigcup_{i=1}^n A_i}\\
&= \sum_{\mathclap{J\subseteq\{1,\ldots,n\}}}(-1)^{|J|}\sum_{\omega\in\Omega}
P(\{\omega\})1_{\bigcap_{j\in J} A_j}(\omega)
= \sum_{\mathclap{J\subseteq\{1,\ldots,n\}}}(-1)^{|J|}P(\bigcap_{j\in J} A_j).
\end{align*}
Im Fall $J=\emptyset$ gilt $\bigcap_{j\in J} A_j = \Omega$, dessen
Wahrscheinlichkeit eins ist. Man subtrahiert nun eins auf beiden
Seiten, und multipliziert daraufhin beide Seiten mit $-1$.\,\qedsymbol
\end{Beweis}

\newpage
\section{Allgemeine Wahrscheinlichkeitsräume}

\begin{Satz}
Der Erwartungswert ist der Schwerpunkt der Dichtefunktion.
\end{Satz}
\begin{Beweis} Der Schwerpunkt $s$ ist charakterisiert durch die
folgende Gleichgewichtsbedingung, die wie folgt äquivalent
umgeformt werden darf:
\begin{gather*}
\int_\R (s-x)f(x)\,\mathrm dx = 0
\iff s\underbrace{\int_\R\! f(x)\,\mathrm dx}_{=1}
- \int_\R xf(x)\,\mathrm dx = 0\\
\iff s = \int_\R xf(x)\,\mathrm dx = E(X).\,\qedsymbol
\end{gather*}
\end{Beweis}

\begin{Satz}\label{rv-transform-pdf}
Sei $g\colon\R\to\R$ eine streng monotone Funktion. Seien
$X,Y$ Zufallsgrößen mit Dichten $f_X,f_Y$. Ist $Y=g(X)$,
dann gilt
\[f_Y(y) = \frac{f_X(g^{-1}(y))}{|g'(g^{-1}(y))|}.\]
\end{Satz}
\strong{Beweis.} Sei $g$ streng monoton steigend. Dann kann man rechnen
\[F_Y(y) = P(Y\le y) = P(g(X)\le y) = P(X\le g^{-1}(y)) = F_X(g^{-1}(y)).\]
Gemäß der Kettenregel findet man
\[f_Y(y) = \frac{\mathrm d}{\mathrm dy}F_Y(y)
= f_X(g^{-1}(y))\frac{\mathrm d}{\mathrm dy}g^{-1}(y) = \frac{f_X(g^{-1}(y))}{g'(g^{-1}(y))}.\]
Sei $g$ nun streng monoton fallend. Dann kann man rechnen
\[F_Y(y) = P(g(X)\le y) = P(X\ge g^{-1}(y)) = 1 - P(X < g^{-1}(y))
= 1 - F_X(g^{-1}(y)).\]
Entsprechend findet man
\[f_Y(y) = -\frac{f_X(g^{-1}(y))}{g'(g^{-1}(y))}.\]
Nun ist $g'$ in beiden Fällen frei von Nullstellen. Demnach ist
$\sgn(g'(x))$ konstant für alle $x$ und wir haben allgemein
\[f_Y(y) = \sgn(g'(x))\frac{f_X(x)}{g'(x)} = \frac{f_X(x)}{|g'(x)|}\]
mit $x=g^{-1}(y)$.\;\qedsymbol

\begin{Satz}[»LOTUS: Law of the unconscious statistican«]\newlinefirst
Ist $g\colon\R\to\R$ streng monoton, dann muss gelten
\[E(g(X)) = \int_{-\infty}^\infty g(x)f_X(x)\,\mathrm dx.\]
\end{Satz}
\strong{Beweis.} Sei $Y=g(X)$. Mit Satz \ref{rv-transform-pdf}
und Substitution $y=g(x)$ kann man rechnen
\begin{align*}
E(g(X)) &= E(Y) = \int_{-\infty}^\infty yf_Y(y)\,\mathrm dy
= \int_{-\infty}^\infty y\frac{f_X(g^{-1}(y))}{|g'(g^{-1}(y))|}\,\mathrm dy\\
&= \int_{g^{-1}(-\infty)}^{g^{-1}(\infty)} g(x)
\frac{f_X(x)}{|g'(x)|}g'(x)\,\mathrm dx\\
&= \sgn(g')\int_{-\sgn(g')\infty}^{\sgn(g')\infty}g(x) f_X(x)\mathrm dx
= \int_{-\infty}^\infty g(x) f_X(x)\mathrm dx.\;\qedsymbol
\end{align*}

\newpage
\section{Stochastische Prozesse}%
\index{stochastischer Prozess}

\subsection{Markow-Prozesse mit endlichem Zustandsraum}

\begin{Definition}[Markow-Prozess]\index{Markow-Prozess}
Sei $X(t)$ ein stochastischer Prozess mit $t\ge 0$ und $X(t)\in S$,
wobei $S$ ein endlicher Zustandsraum ist. Der Prozess heißt
Markow"=Prozess, wenn die Markow"=Eigenschaft
\[P(X(s+t)=j\mid \{X(s)=i\}\cap\bigcap_{0\le u<s}\{X(u)=x_u\}) = P(X(s+t)=j\mid X(s)=i)\]
erfüllt ist. Das heißt, für die bedingte Wahrscheinlichkeit, dass
$X$ in der Zukunft den Zustand $j$ einnimmt, spielt nur der aktuelle
Zustand $i$ eine Rolle, nicht aber Zustände der Vergangenheit.
\end{Definition}

\noindent
\strong{Bemerkung.} Eine geläufige Notation
ist $P(A\mid B,C):=P(A\mid B\cap C).$ Es gilt
\[P(A\mid B\cap C) = P_B(A\mid C) = P_C(A\mid B),\]
wobei $P_B(M):=P(M\mid B)$ und $P_C(M):=P(M\mid C)$.

\begin{Definition}[Homogener Markow-Prozess]%
\index{homogener Markow-Prozess}
Ein Markow-Prozess $X(t)$ heißt homogen, wenn die Gleichung
\[p_{ij}(t) := P(X(s+t)=j\mid X(s)=i) = P(X(t)=j\mid X(0)=i)\]
für jedes $s$ erfüllt ist. Man nennt $P=(P_{ij})$ die Übergangsmatrix.
\end{Definition}

\begin{Satz}[Kolmogorow-Chapman-Gleichung]%
\index{Kolmogorow-Chapman-Gleichung}\newlinefirst
Für die Übergangsmatrix eines homogenen Markow"=Prozesses gilt
\[P(s+t) = P(s)P(t).\]
\end{Satz}

\begin{Beweis}
Wir schreiben kurz $P_i(X(t)=j):=P(X(t)=j\mid X(0)=i)$. Gemäß dem
Gesetz der totalen Wahrscheinlichkeit \ref{total-prob-rv} gilt
\[p_{ij}(s+t) = P_i(X(s+t)=j)
= \sum_{k\in S} P_i(X(s)=k) P_i(X(s+t)=j\mid X(s)=k).\]
Aufgrund der Markow-Eigenschaft und der Homogenität gilt nun
\begin{gather*}
P_i(X(s+t)=j\mid X(s)=k) = P(X(s+t)=j\mid X(s)=k, X(0)=i)\\
= P(X(s+t)=j\mid X(s)=k) = P(X(t)=j\mid X(0)=k) = P_k(X(t)=j) = p_{kj}(t).
\end{gather*}
Man erhält die Matrizenmultiplikation
\[p_{ij}(s+t) = \sum_{k\in S} p_{ik}(s) p_{kj}(t),\;\,
\text{kurz}\;\; P(s+t)=P(s)P(t).\,\qedsymbol\]
\end{Beweis}

\begin{Definition}[Intensitätsmatrix]%
\label{def:intensity-matrix}\index{Intensitätsmatrix}\newlinefirst
Ist $P(t)$ die Übergangsmatrix eines homogenen Markow"=Prozesses, nennt man
\[Q := P'(0) = \lim_{h\to 0}\frac{P(h)-E}{h}\]
die Intensitätsmatrix, wobei mit $E$ die Einheitsmatrix gemeint ist.
\end{Definition}
\strong{Bemerkung.} Weil $P(t)$ für $t\ge 0$ definiert ist, stimmt der
gewöhnliche Grenzwert für $h\to 0$ mit dem rechtsseitigen Grenzwert
für $h\searrow 0$ überein.

\begin{Satz}\label{intensity-matrix-exists}
Der Grenzwert in Def. \ref{def:intensity-matrix} existiert.
\end{Satz}

\begin{Satz}
Für die Übergangsmatrix gilt
\[P(h) = E + hQ + o(h),\,\text{bzw.}\; p_{ij}(h) = \delta_{ij} + hq_{ij} + o(h).\]
\end{Satz}
\begin{Beweis}
Weil $P$ laut Satz \ref{intensity-matrix-exists} an der Stelle $0$
differenzierbar ist, besteht die Linearisierung
\[P(h) = P(0) + hP'(0) + o(h) = E + hQ + o(h).\,\qedsymbol\]
\end{Beweis}

\begin{Satz}[Kolmogorowsche Vorwärtsgleichung]\newlinefirst
Die Übergangsmatrix erfüllt das Anfangswertproblem
\[P'(t)=P(t)Q,\quad P(0)=E.\]
\end{Satz}
\begin{Beweis}
Laut der Chapman"=Kolmogorow"=Gleichung ist
\[P(t) = P(0+t) = P(0)P(t).\]
Ergo muss $P(0)=E$ sein. Laut der Chapman"=Kolmogorow"=Gleichung,
Def. \ref{def:intensity-matrix} und Satz \ref{intensity-matrix-exists}
gilt zudem
\[P'(t) = \lim_{h\to 0}\frac{P(t+h)-P(t)}{h}
= \lim_{h\to 0}\frac{P(t)P(h)-P(t)}{h}
= P(t)\lim_{h\to 0}\frac{P(h)-E}{h} = P(t)Q.\;\qedsymbol\]
\end{Beweis}

\begin{Satz}
Die kolmogorowsche Vorwärtsgleichung besitzt die eindeutige Lösung
$P(t)=\ee^{tQ}$, wobei mit $\ee^A=\exp(A)$ das Matrixexponential
gemeint ist. 
\end{Satz}
\begin{Beweis}
Analog zur gewöhnlichen Exponentialfunktion gilt
\begin{gather*}
\frac{\mathrm d}{\mathrm dt}\ee^{tQ}
= \frac{\mathrm d}{\mathrm dt}\sum_{k=0}^\infty \frac{(tQ)^k}{k!}
= \sum_{k=1}^\infty \frac{\mathrm d}{\mathrm dt}\bigg(\frac{t^k Q^k}{k!}\bigg)
= \sum_{k=1}^\infty k\frac{t^{k-1} Q^k}{k!}\\
= \sum_{k=0}^\infty (k+1)\frac{t^k Q^{k+1}}{(k+1)!}
= \sum_{k=0}^\infty \frac{t^k Q^{k+1}}{k!} = \ee^{tQ}Q = Q\ee^{tQ}.
\end{gather*}
Daher ist $\ee^{tQ}$ eine Lösung der Differentialgleichung und
wegen $\exp(0)=E$ des Anfangswertproblems. Angenommen, es gibt eine
weitere Lösung $P$, dann kann man $P(t) = R(t)\ee^{tQ}$
schreiben mit $R(t):=P(t)\ee^{-tQ}$. Da $P$ die
Differentialgleichung erfüllen soll, muss gelten
\[0 = P'(t) - P(t)Q = R'(t)\ee^{tQ} + R(t)\ee^{tQ}Q - R(t)\ee^{tQ}Q = R'(t)\ee^{tQ}.\]
Multipliziert man beide Seiten der Gleichung mit $\ee^{-tQ}$, ergibt sich
$R'(t)=0$. Damit ist $R$ konstant mit $R(t)=R(0)=E$ laut Anfangsbedingung.
Es gibt also keine weitere Lösung außer $P(t)=\ee^{tQ}$.\,\qedsymbol
\end{Beweis}

\begin{Satz}\label{intensity-matrix-row-sum}
Für die Intensitätsmatrix gilt $\sum_{j\in S} q_{ij} = 0$.
\end{Satz}
\begin{Beweis}
Weil $p_{ij}(t)$ eine Wahrscheinlichkeitsfunktion in $j$ ist, muss
$\sum_{j\in S}p_{ij}(t)=1$ gelten. Demzufolge ist
\[0  = \tfrac{\mathrm d}{\mathrm dt} 1 = \sum_{j\in S} p_{ij}'(t)
= \sum_{j\in S} q_{ij}.\,\qedsymbol\]
\end{Beweis}

\begin{Satz}[Mastergleichung]\index{Mastergleichung}\newlinefirst
Die Übergangsmatrix erfüllt die Mastergleichung
\[p_{ij}'(t) = \sum_{k\ne j} (p_{ik}(t)q_{kj} - p_{ij}(t)q_{jk}).\]
\end{Satz}
\begin{Beweis}
Da die Zeilensummen laut Satz \ref{intensity-matrix-row-sum}
verschwinden, gilt $q_{jj} = -\sum_{k\ne j} q_{jk}$.
Damit erhält man die Umformung
\begin{align*}
p_{ij}'(t) &= \sum_k p_{ik}(t)q_{kj}
= \sum_{k\ne j} p_{ik}(t)q_{kj} + p_{ij}(t)q_{jj}
= \sum_{k\ne j} p_{ik}(t)q_{kj} - \sum_{k\ne j} p_{ij}(t)q_{jk}\\
&= \sum_{k\ne j} (p_{ik}(t)q_{kj} - p_{ij}(t)q_{jk}).\,\qedsymbol
\end{align*}
\end{Beweis}
\strong{Bemerkung.} Man kann die Mastergleichung alternativ in der Form
\[p_j'(t) = \sum_{k\ne j} (w_{jk}p_k(t) - w_{kj}p_j(t))\]
schreiben, wobei $p_j(t):=p_{ij}(t)$ und $w_{ij}:=q_{ji}$ ist.
Zudem kann man $w_{kk}:=0$ für jedes $k$ setzen, weil die Hauptdiagonale
nicht in die Gleichung eingeht und redundante Information enthält.

\section{Mathematische Statistik}

\subsection{Schätzfunktionen}%
\index{Schaetzfunktion@Schätzfunktion}

\begin{Definition}[Arithmetischer Mittelwert]\newlinefirst
Das arithmetische Mittel von unabhängigen und identisch verteilten
Zufallsgrößen $X_k\colon\Omega\to\R$ ist definiert als
\[\textstyle\overline X := \frac{1}{n}\sum_{k=1}^n X_k.\]
\end{Definition}

\begin{Satz}
Sei $X_k = w+\varepsilon_k$ eine Streuung um einen festen wahren Wert
$w$. Die Streuung sei unverzerrt, das heißt, es gelte
$E(\varepsilon_k)=0$ für alle $k$. Dann ist das arithmetische Mittel
der $X_k$ ein erwartungstreuer Schätzer von $w$, das heißt, es gilt
$E(\overline X)=w$.
\end{Satz}
\begin{Beweis} Aufgrund von
$E(X_k) = E(w+\varepsilon_k) = w+E(\varepsilon_k) = w$ gilt
\[E(\overline X) = E\bigg(\frac{1}{n}\sum_{k=1}^n X_k\bigg)
= \frac{1}{n}\sum_{k=1}^n E(X_k) = \frac{1}{n}\sum_{k=1}^n w
= \frac{1}{n}nw = w.\,\qedsymbol\]
\end{Beweis}
