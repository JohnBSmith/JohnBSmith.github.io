
\chapter{Algebra}

\section{Gruppentheorie}

\subsection{Grundlagen}

\begin{Definition}[Gruppe]
Das Tupel $(G,*)$ bestehend aus einer Menge $G$ und
Abbildung $*\colon G\times G\to\Omega$ heißt Gruppe, wenn die folgenden
Axiome erfüllt sind:
\begin{enumerate}
\item[(G1)] Für alle $a,b\in G$ gilt $a*b\in G$. D.\,h., man darf $G=\Omega$ setzen.
\item[(G2)] Es gilt das Assoziativgesetz: für alle $a,b,c\in G$ gilt $(a*b)*c=a*(b*c)$.
\item[(G3)] Es gibt ein Element $e\in G$, so dass $e*g=g=g*e$ für jedes $g\in G$ gilt.
\item[(G4)] Zu jedem $g\in G$ gibt es ein $g^{-1}\in G$ so dass $g*g^{-1}=e=g^{-1}*g$ gilt.
\end{enumerate}
Das Element $e$ wird neutrales Element der Gruppe genannt.
Das Element $g^{-1}$ wird inverses Element zu $g$ genannt.
Anstelle von $a*b$ schreibt man auch kurz $ab$. Ist $(G,+)$ eine
Gruppe, dann schreibt man immer $a+b$, und $-g$ anstelle von $g^{-1}$.
\end{Definition}

\begin{Satz}
Das neutrale Element einer Gruppe $G$ ist eindeutig bestimmt.
D.\,h., es gibt keine zwei unterschiedlichen neutralen Elemente. 
\end{Satz}
\begin{Beweis}
Seien $e,e'$ zwei neutrale Elemente von $G$. Nach Axiom (G3)
gilt dann $e=e'e$, und weiter $e'e=e'$ bei nochmaliger Anwendung
von (G3). Daher ist $e=e'$.\;\qedsymbol
\end{Beweis}

\begin{Satz}
Sei $G$ eine Gruppe. Zu jedem Element $g\in G$ ist das inverse
Element $g^{-1}$ eindeutig bestimmt. D.\,h., es kann keine zwei
unterschiedlichen inversen Elemente zu $g$ geben.
\end{Satz}
\begin{Beweis}
Seien $a,b$ zwei inverse Elemente zu $g$. Nach Axiom (G3), Axiom (G2)
und Axiom (G4) gilt
\[a \stackrelrm{(G3)}= ae \stackrelrm{(G4)} = a(gb) \stackrelrm{(G2)}
= (ag)b \stackrelrm{(G4)}= eb \stackrelrm{(G3)}= b.\]
Daher ist $a=b$.\;\qedsymbol
\end{Beweis}

\begin{Definition}[Untergruppe]
Sei $(G,*)$ eine Gruppe. Eine Teilmenge $U\subseteq G$ heißt
Untergruppe von $G$, kurz $U\le G$, wenn $U$ bezüglich derselben
Verknüpfung $*$ selbst eine Gruppe $(U,*)$ bildet.
\end{Definition}

\begin{Satz}
Jede Gruppe $G$ besitzt die Untergruppen $\{e\}\le G$ und $G\le G$,
wobei $e\in G$ das neutrale Element ist. Man spricht von den
trivialen Untergruppen.
\end{Satz}
\begin{Beweis}
Die Aussage $G\le G$ ist trivial, denn $G\subseteq G$ ist allgemeingültig
und $(G,*)$ bildet nach Voraussetzung eine Gruppe. Zu (G1):
Es gilt $ee=e$. Da es nur diese eine Möglichkeit gibt, sind damit alle
überprüft.
Zu (G2): Das Assoziativgesetz wird auf Elemente der Teilmenge vererbt.
Zu (G3): Das neutrale Element ist in $\{e\}$ enthalten.
Zu (G4): Das neutrale Element ist gemäß $ee=e$ zu sich selbst invers.
Da $e$ das einzige Element von $\{e\}$ ist, sind damit alle
überprüft.\;\qedsymbol
\end{Beweis}

\begin{Satz}[Untergruppenkriterium]
Sei $G$ eine Gruppe und $H$ eine nichtleere Teilmenge von $G$. Sind
die beiden Prämissen
\begin{enumerate}
\item $a,b\in H \implies ab\in H$,
\item $a\in H\implies a^{-1}\in H$,
\end{enumerate}
erüllt, ist $H$ bereits eine Untergruppe von $G$.
\end{Satz}
\begin{Beweis}
Die Abgeschlossenheit gilt wegen der ersten Prämisse.
Das Assoziativgesetz vererbt sich auf die Elemente der Teilmenge.
Nun existiert mindestens ein $x\in H$. Aufgrund der zweiten
Prämisse muss somit $x^{-1}\in H$ sein und infolge $e = x^{-1}x$
ein Element von $H$. Die zweite Prämisse sichert schließlich ab,
dass jedes weitere Element von $H$ ein Inverses in $H$ besitzt.
Der Nachweis aller Gruppenaxiome ist erbracht.\,\qedsymbol
\end{Beweis}

\begin{Satz} Sei $X$ eine Menge. Die Menge der bijektiven
Selbstabbildungen auf $X$ bildet bezüglich der Verkettung eine Gruppe,
die man als symmetrische Gruppe $S(X)$ bezeichnet.
\end{Satz}
\begin{Beweis}
Die Verkettung zweier Bijektionen ist ebenfalls bijektiv. Das
Assoziativgesetz gilt für die Verkettung allgemein. Das neutrale
Element ist offenbar die identische Abbildung. Zu einer Bijektion $f$
nimmt die Umkehrabbildung $f^{-1}$ die Rolle des inversen Elements
ein, denn $f\circ f^{-1}=\id$ und $f^{-1}\circ f=\id$. Demnach
sind alle Gruppenaxiome erfüllt.\,\qedsymbol
\end{Beweis}

\begin{Satz}
Sei $X$ eine nichtleere algebraische Struktur, beispielsweise eine
Gruppe, ein Ring oder Vektorraum. Die Menge der Automorphismen bildet
bezüglich Verkettung eine Gruppe, die man Automorphismengruppe
$\operatorname{Aut}(X)$ nennt. Sie ist eine Untergruppe der
symmetrischen Gruppe $S(X)$.  
\end{Satz}
\begin{Beweis}
Offenbar ist $\operatorname{Aut}(X)$ eine nichtleere Teilmenge von
$S(X)$. Die Verkettung zweier Automorphismen ist ebenfalls ein
Automorphismus. Jeder Automorphismus besitzt einen inversen
Automorphismus. Laut Untergruppenkriterium muss $\operatorname{Aut}(X)$
eine Untergruppe von $S(X)$ sein.\,\qedsymbol
\end{Beweis}

\begin{Satz}
Sei $K$ ein Körper. Die invertierbaren Matrizen $A\in K^{n\times n}$
bilden eine Gruppe, die man allgemeine lineare Gruppe
$\operatorname{GL}(n,K)$ nennt. Sie ist kanonisch isomorph zur
Automorphismengruppe $\operatorname{Aut}(K^n)$.
\end{Satz}
\begin{Beweis}
Die Gruppenaxiome sind erfüllt, wobei die Einheitsmatrix das
neutrale Element ist und die jeweilige inverse Matrix das
inverse Element zu einer Matrix. Weil die Abbildung%
\[\varphi\colon K^{m\times n}\to\operatorname{Hom}(K^n,K^m),\quad
\varphi(A)(\mathbf v) := A\mathbf v\]
bereits einen kanonischen Isomorphismus darstellt, erhält man bei
Setzung $m=n$ und Einschränkung auf $\operatorname{GL}(n,K)$
einen Monomorphismus. Weil zu jeder bijektiven linearen Abbildung genau
eine invertierbare Matrix gehört, muss%
\[\varphi\colon\operatorname{GL}(n,K)\to\operatorname{Aut}(K^n)\]
außerdem surjektiv sein.\,\qedsymbol
\end{Beweis}

\newpage
\section{Ringtheorie}

\subsection{Grundlagen}

\begin{Definition}[Ring]
Eine Struktur $(R,+,\cdot)$ heißt genau dann Ring, wenn die folgenden
Axiome erfüllt sind:
\begin{enumerate}
\item[1.] $(R,+)$ ist eine kommutative Gruppe.
\item[2.] $(R,\cdot)$ ist eine Halbgruppe.
\item[3.] Für alle $a,b,c\in R$ gilt $a(b+c) = ab+ac$. (Linksdistributivgesetz)
\item[4.] Für alle $a,b,c\in R$ gilt $(a+b)c = ac+bc$. (Rechtsdistributivgesetz)
\end{enumerate}
\end{Definition}
Bemerkung: Das neutrale Element von $(R,+)$ wird als Nullelement
bezeichnet und meist $0$ geschrieben.

\begin{Definition}[Ring mit Eins]
Ein Ring $R$ heißt genau dann Ring mit Eins, wenn $(R,\cdot)$ ein
Monoid ist. Monoid heißt, es gibt ein Element $e\in R$, so dass
$e\cdot a = a$ und $a\cdot e = a$ für alle $a\in R$.
\end{Definition}
Bemerkung: Man bezeichnet $e$ als Einselement des Rings.

\begin{Satz}
Sei $R$ ein Ring und $0\in R$ das Nullelement.\\
Für jedes $a\in R$ gilt $0\cdot a = 0$ und $a\cdot 0 = 0$.
\end{Satz}
\begin{Beweis} Man rechnet
\[0a = 0a+0 = 0a+0a-0a = (0+0)a-0a = 0a-0a = 0.\]
\end{Beweis}
Die Rechnung für $a\cdot 0$ ist analog.\;\qedsymbol

\begin{Satz}\label{Minus-vorziehen}
Sei $R$ ein Ring und $a,b\in R$. Es gilt $(-a)b = -(ab) = a(-b)$.
\end{Satz}
\begin{Beweis}
Man rechnet
\begin{align*}
(-a)b &= (-a)b+0 = (-a)b+ab-(ab) = ((-a)+a)b-(ab)\\
&= 0b-(ab) = 0-(ab) = -(ab).\;\qedsymbol
\end{align*}
\end{Beweis}

\begin{Satz}[»Minus mal minus macht plus«]\newlinefirst
Sei $R$ ein Ring und $a,b\in R$. Es gilt
$(-a)(-b) = ab$.
\end{Satz}
Beachtung von $-(-x)=x$ nach zweifacher Anwendung von
Satz \ref{Minus-vorziehen} bringt
\[(-a)(-b) = -((-a)b) = -(-(ab)) = ab.\;\qedsymbol\]

\begin{Definition}
Sei $(M,+,0)$ ein Monoid. Für $n\in\Z_{\ge 0}$ und $a\in M$ definiert
man $na$ rekursiv als
\[0a := 0,\quad (n+1)a := na + a.\]
\end{Definition}

\begin{Satz}
Sei $(M,+,0)$ ein Monoid. Für $m,n\in\Z_{\ge 0}$ und $a\in M$ gilt
\begin{gather}
(m+n)a = ma + na,\\
(mn)a = m(na).
\end{gather}
\end{Satz}
\begin{Beweis}
Induktionsanfang ist $(m+0)a = ma = ma+0 = ma + 0a$. Der Schritt ist%
\[(m+n+1)a \stackrelrm{def}= (m+n)a + a
\stackrelrm{IV}= ma+na + a
\stackrelrm{def}= ma + (n+1)a.\]
Induktionsanfang ist $(m\cdot 0)a = 0a = 0 = m\cdot 0 = m(0a)$.
Der Schritt ist
\begin{align*}
(m(n+1))a &= (mn+m)a = (mn)a+ma \stackrelrm{IV}= m(na)+ma\\
&= m((na)+a) \stackrelrm{def}=
m((n+1)a).\,\qedsymbol
\end{align*}
\end{Beweis}

\begin{Satz}
Sei $R$ ein Ring mit Eins $e$. Für $n\in\Z$ und
$a\in R$ gilt $(ne)a = na$.
\end{Satz}
\begin{Beweis}
Der Induktionsanfang ist $(0e)a = 0_R a = 0_R = 0a$.
Der Schritt ist
\[((n+1)e) a \stackrelrm{def}= (ne+e)a = nea + ea \stackrelrm{IV}=
na+a \stackrelrm{def}= (n+1)a.\]
Für $n>0$ gilt zudem
\[((-n)e)a \stackrelrm{def}= (-(ne))a
= -((ne)a) = -(na) \stackrelrm{def}= (-n)a.\,\qedsymbol\]
\end{Beweis}

\newpage
\subsection{Ringhomomorphismen}

\begin{Definition}[Ringhomomorphismus]
Seien $R,R'$ Ringe. Eine Abbildung $\varphi\colon R\to R'$ heißt
Ringhomomorphismus, falls
\begin{gather*}
\varphi(x+y) = \varphi(x)+\varphi(y),\\
\varphi(xy) = \varphi(x)\varphi(y)
\end{gather*}
für alle $x,y\in R$ gilt. Liegen Ringe mit Eins vor, und gilt
zusätzlich $\varphi(1)=1$, dann spricht man von einem unitären
Ringhomomorphismus.
\end{Definition}

\begin{Satz}
Bei jedem Ringhomomorphismus $\varphi$ gilt
$\varphi(kx) = k\varphi(x)$ für $k\in\Z$.
\end{Satz}
\begin{Beweis}
Für $k>0$ ist
\[\varphi(kx) = \varphi(\sum_{i=1}^k x)
= \sum_{i=1}^k \varphi(x) = k\varphi(x).\]
Nun der Fall $k=0$. Man rechnet $f(0) = f(0+0) = f(0)+f(0)$.
Subtraktion von $f(0)$ auf beiden Seiten ergibt $f(0)=0$.
Schließlich bleibt noch $f(-kx)=-kf(x)$ für $k>0$ zu zeigen. Hier
rechnet man zunächst
\[0 = f(0) = f(-x+x) = f(-x)+f(x).\]
Subtraktion von $f(x)$ auf beiden Seiten ergibt $f(-x) = -f(x)$.
Somit gilt
\[f(-kx) = -f(kx) = -kf(x).\;\qedsymbol\]
\end{Beweis}

\section{Polynomringe}

\subsection{Einsetzungshomomorphismus}

\begin{Definition}[Einsetzungshomomorphismus]\newlinefirst
Die Abbildung $\Phi\colon\R[X]\to\Abb(\R,\R)$ mit $\Phi(f)(x):=f(x)$
nennt man Einsetzungshomomorphismus.
\end{Definition}

\begin{Satz}
Beim Einsetzungshomomorphismus $\Phi$ handelt es sich um eine lineare
Abbildung.
\end{Satz}
\begin{Beweis}
Es gilt
\begin{align*}
\Phi(f+g)(x) &= \sum_k (a_k + b_k) x^k = \sum_k a_k x^k + \sum_k b_k x^k\\
&= \Phi(f)(x) + \Phi(g)(x) = (\Phi(f)+\Phi(g))(x)
\end{align*}
und
\begin{align*}
\Phi(\lambda f)(x) &= \sum_k \lambda a_k x^k = \lambda\sum_k a_k x^k
= \lambda\Phi(f)(x) = (\lambda\Phi(f))(x).\,\qedsymbol
\end{align*}
\end{Beweis}

\newpage
\begin{Satz}
Der Einsetzungshomomorphismus $\Phi$ ist injektiv.
\end{Satz}
\begin{Beweis}
Sei $f=\sum_{k=0}^n a_k X^k$
und $g=\sum_{k=0}^n b_k X^k$, wobei $n=\max(\deg f,\deg g)$.
Zu zeigen ist
\[(\forall x\in\R\colon \Phi(f)(x)=\Phi(g)(x))\implies f=g,\]
das heißt
\[(\forall x\in\R\colon \sum_k a_k x^k = \sum_k b_k x^k)\implies (\forall k\colon a_k=b_k).\]
Die Umformung der Voraussetzung ergibt $\sum_k (b_k-a_k)x^k = 0$.
D.\,h., jedes der $(b_k-a_k)$ muss verschwinden. Zu zeigen ist also
lediglich
\[(\forall x\in\R\colon \sum_{k=0}^n c_k x^k = 0)\implies (\forall k\colon c_k=0).\]
Wenn $f(x)=0$ für alle $x$ ist, muss auch die Ableitung $D^m f(x)=0$
sein. Es gilt $D^k x^k = k!$, und daher
\[D^n\sum_{k=0}^n c_k x^k = n!\cdot c_n = 0 \implies c_n=0.\]
Demnach ergibt sich dann aber auch
\[D^{n-1}\sum_{k=0}^n c_k x^k = (n-1)!\cdot c_{n-1} = 0\implies c_{n-1}=0\]
usw. Man erhält $c_k=0$ für alle $k$.\;\qedsymbol
\end{Beweis}

\section{Körper}

\subsection{Geordnete Körper}

\begin{Definition}[Geordneter Körper]\label{def:of}
Eine Körper $K$ heißt geordnet bezüglich einer strengen Totalordnung,
wenn die beiden Axiome
\begin{gather*}
a<b \implies a+c<b+c,\\
a>0\land b>0\implies ab>0
\end{gather*}
für alle $a,b,c\in K$ erfüllt sind.
\end{Definition}

\begin{Satz}\label{of-negate}
Sei $K$ ein geordneter Körper und $a\in K$. Es gilt $a>0\iff -a<0$. 
\end{Satz}
\begin{Beweis}
Gemäß Def. \ref{def:of} Axiom~1 gilt%
\[0<a \iff -a < a-a = 0.\,\qedsymbol\]
\end{Beweis}

\begin{Satz}\label{of-sq-positive}
Sei $K$ ein geordneter Körper. Für jedes $a\in K$ mit $a\ne 0$ gilt
$a^2>0$.
\end{Satz}
\begin{Beweis}
Im Fall $a>0$ ist $a^2>0$ aufgrund von Def. \ref{def:of} Axiom~2, setze
$b:=a$.
Übrig bleibt der Fall $a<0$. Gemäß Satz \ref{of-negate} ist
$-a>0$. Laut Axiom~2 gilt andererseits%
\[-a > 0 \implies 0 < (-a)^2 = a^2.\]
Somit ist auch in diesem Fall $a^2>0$.\,\qedsymbol
\end{Beweis}

\begin{Satz}\label{of-1-positive}
Sei $K$ ein geordneter Körper. Für $1_K$ gilt $1_K>0$.
\end{Satz}

\begin{Beweis}
Wegen $1_K = 1_K 1_K$ ist $1_K$ ein Quadrat. Weil zudem $1_K\ne 0$ ist,
erhält man $1_K>0$ gemäß Satz \ref{of-sq-positive}.\,\qedsymbol
\end{Beweis}

\begin{Satz}
Sei $K$ ein geordneter Körper. Für $n\in\Z_{>0}$ gilt $n1_K>0$.
\end{Satz}

\begin{Beweis}
Der Induktionsanfang ist $1\cdot 1_K = 1_K > 0$, wobei $1_K>0$ gemäß
Satz \ref{of-1-positive} gilt. Der Induktionsschritt ist
\[(n+1)1_K \stackrelrm{(Def)}= n1_K + 1_K > 1_K > 0,\]
denn die Induktionsvoraussetzung $n1_K>0$ impliziert
$n1_K+1_K>1_K$ gemäß Def. \ref{def:of} Axiom 1.\,\qedsymbol
\end{Beweis}

\begin{Satz}\label{of-ineq-mul}
Sei $K$ ein geordneter Körper. Für $a,b,c\in K$ gilt
\begin{gather*}
a<b\land c>0\implies ca<cb,\\
a\le b\land c\ge 0\implies ca\le cb.
\end{gather*}
\end{Satz}
\begin{Beweis}
Gemäß Def. \ref{def:of} Axiom~1 und Axiom~2 gilt
\[a<b\iff 0<b-a \implies 0<c(b-a) = cb-ca\iff ca<cb.\]
Im Fall $c=0$ ist $ca\le cb$ klar. Für $c>0$ gilt
\[a\le b\iff a<b\lor a=b\implies ca<cb\lor ca=cb\iff ca\le cb.\,\qedsymbol\]
\end{Beweis}

\begin{Satz}\label{of-nn-int-mul}
Sei $K$ ein geordneter Körper und $n\in\Z_{\ge 0}$. Für $a\ge 0$ gilt
$na\ge 0$.
\end{Satz}
\begin{Beweis} Der Induktionsanfang $n=0$ ist trivial. Der Schritt ist
\[(n+1)a \stackrelrm{(Def)}= na+a \ge na \ge 0,\]
denn gemäß Induktionsvoraussetzung ist $na\ge 0$. Die Ungleichung
$na+a\ge na$ erhält man, indem auf beiden Seiten von
$a\ge 0$ der Wert $an$ addiert wird.\,\qedsymbol
\end{Beweis}

\begin{Satz}
Sei $K$ ein geordneter Körper. Sei $a\in K$ und $m,n\in\Z$.
Es gilt
\[m\le n\land a\ge 0\implies ma\le na.\]
\end{Satz}
\begin{Beweis}
Wegen $m\le n$ ist $n-m\ge 0$. Laut Satz \ref{of-nn-int-mul}
gilt somit
\[0\le a \implies 0\le (n-m)a = na-ma\iff ma\le na.\,\qedsymbol\]
\end{Beweis}

\begin{Satz}\label{of-sum-of-sq-positive}
Sei $K$ ein geordneter Körper und $a_k\in K$. Es gilt
\[\textstyle (\exists k\colon a_k\ne 0)\implies \sum_{k=1}^n a_k^2 > 0.\]
\end{Satz}
\begin{Beweis}
Aufgrund der Prämisse existiert die Permutation, die das
erste nichtverschwindende $a_k$ mit $a_1$ vertauscht, weshalb ohne
Beschränkung der Allgemeinheit $a_1\ne 0$ angenommen werden darf.
Laut Satz \ref{of-sq-positive} ist $a_k^2\ge 0$ für jedes $k$.
Induktion über die $k$. Der Induktionsanfang $a_1>0$ wurde bereits
erläutert. Nun der Induktionsschritt. Mit dem Axiom~1 von Def. \ref{def:of}
und der Induktionsvoraussetzung $0 < \sum_{k=1}^{n-1} a_k^2$ findet sich
\[0\le a_n^2 < a_n^2 + \sum_{k=1}^{n-1} a_k^2 = \sum_{k=1}^n a_k^2.\,\qedsymbol\]
\end{Beweis}

\newpage
\section{Formale Potenzreihen}

\begin{Definition}[Formale Potenzreihe]\newlinefirst
Sei $R$ ein kommutativer Ring mit Einselement. Eine Folge
$a\colon\N_{\ge 0}\to R$ bezeichnet man auch als formale Potenzreihe
und schreibt
\[\sum_{k=0}^\infty a_k X^k := a = (a_k) = (a_k)_{k=0}^\infty
= (a_0,a_1,a_2,\ldots).\]
Addition und Multiplikation von formalen Potenzreihen ist hierbei
definiert als
\begin{align*}
& \sum_{k=0}^\infty a_k X^k + \sum_{k=0}^\infty b_k X^k
:= \sum_{k=0}^\infty (a_k + b_k)X^k, && \text{bzw.}\;\;(a_k) + (b_k) := (a_k + b_k),\\
& \bigg(\sum_{i=0}^\infty a_i X^i\bigg)\bigg(\sum_{j=0}^\infty b_j X^j\bigg)
:= \sum_{k=0}^\infty \bigg(\sum_{i=0}^k a_i b_{k-i}\bigg)X^k,
&& \text{bzw.}\;\;(a_i)(b_j) := ({\textstyle\sum_{i=0}^k a_i b_{k-i}}).
\end{align*}
\end{Definition}

\begin{Satz} Es gilt
\[\sum_{i=0}^k a_i b_{k-i} = \sum_{i=0}^k\sum_{j=0}^k a_i b_j [k=i+j].\qquad ([k=i+j]=\delta_{k,i+j})\]
\end{Satz}
\begin{Beweis} Man findet
\[\sum_{i=0}^k\sum_{j=0}^k a_i b_j [k{=}i{+}j]
= \sum_{i=0}^k\sum_{j=0}^k a_i b_{k-i} [k{-}i{=}j]
= \sum_{i=0}^k a_i b_{k-i} [0{\le}k{-}i{\le}k]
= \sum_{k=0}^k a_i b_{k-i}.\]
Die letzte Gleichung wird ersichtlich durch die äquivalente Umformung
\[0\le k-i\land k-i\le k\iff i\le k\land 0\le i.\,\qedsymbol\]
\end{Beweis}

\begin{Satz}
Formale Potenzreihen mit Koeffizienten in $R$ bilden bezüglich ihrer
definierten Addition und Multiplikation einen kommutativen
Ring mit Einselement, der durch $R[[X]]$ symbolisiert wird.
\end{Satz}
\begin{Beweis}
Addition und Multiplikation sind per Definition abgeschlossen.
Das neutrale Element der Addition ist, wie unschwer zur erkennen,
die Nullfolge. Das additiv inverse Element zu $(a_k)$ ist $(-a_k)$, denn%
\[(a_k) + (-a_k) = (a_k - a_k) = (0, 0, 0, \ldots) = 0.\]
Die Addition ist kommutativ, denn
\[(a_k) + (b_k) = (a_k + b_k) = (b_k + a_k) = (b_k) + (a_k).\]
Die Addition ist assoziativ, denn
\begin{align*}
((a_k) + (b_k)) + (c_k) &= (a_k + b_k) + (c_k) = (a_k + b_k + c_k)\\
&= (a_k) + (b_k + c_k) = (a_k) + ((b_k) + (c_k)).
\end{align*}
Die Multiplikation ist kommutativ, denn mit Satz \ref{sum-rev}
findet sich
\begin{gather*}
\textstyle (a_k)(b_k) = (\sum_{i=0}^k a_i b_{k-i})
= (\sum_{i=0}^k a_{k-i}b_{k-(k-i)})
= (\sum_{i=0}^k b_i a_{k-i}) = (b_k)(a_k).
\end{gather*}
\end{Beweis}
Die Multiplikation ist assoziativ, denn
\begin{gather*}
\textstyle
((a_k)(b_k))(c_k) = (\sum_{i=0}^k\sum_{j=0}^k a_i b_j[k{=}i{+}j])(c_k)\\
\textstyle
= \sum_{i'=0}^k\sum_{j'=0}^k\sum_{i=0}^{i'}\sum_{j=0}^{i'} a_i b_j c_{j'}[i'{=}i{+}j][k{=}i'{+}j']\\
\textstyle
= \sum_{j'=0}^k\sum_{i=0}^{k-j'}\sum_{j=0}^{k-j'} a_i b_j c_{j'}[k{=}i{+}j{+}j']\\
\textstyle
= \sum_{j'=0}^k\sum_{i=0}^k\sum_{j=0}^k a_i b_j c_{j'}[k{=}i{+}j{+}j'].
\end{gather*}
Die letzte Gleichung wird klar durch die Überlegung
\[i > k-j'\iff i > i+j+j'-j'\iff i > i+j \iff 0 > j\iff j < 0.\]
Das Distributivgesetz ist erfüllt, denn
\begin{gather*}
\textstyle (c_k)((a_k)+(b_k)) =  (c_k)(a_k + b_k)
= (\sum_{i=0}^k c_i (a_{k-i} + b_{k-i}))\\
\textstyle
= (\sum_{i=0}^k c_i a_{k-i} + \sum_{i=0}^k c_i b_{k-i})
= (\sum_{i=0}^k c_i a_{k-i}) + (\sum_{i=0}^k c_i b_{k-i})\\
\textstyle
= (c_k)(a_k) + (c_k)(b_k).
\end{gather*}
Das Einselement ist $a_k=[k=0]$, also $(a_k) = (1,0,0,0,\ldots)$.\,\qedsymbol

\begin{Definition}[Formale Potenzreihen in zwei Variablen]\newlinefirst
Man definiert $R[[X,Y]]:=R[[X]][[Y]]$.
\end{Definition}

\begin{Definition}[Exponentialreihe] Man definiert
\[\exp(X) := \sum_{k=0}^\infty \frac{X^k}{k!}.\]
\end{Definition}

\begin{Satz}
Es gilt $\exp(X+Y) = \exp(X)\exp(Y)$.
\end{Satz}
\begin{Beweis}
Mit der kurzen Vorbetrachtung
$\frac{1}{n!}\binom{n}{k} = \frac{1}{n!}\frac{n!}{k!(n-k)!} = \frac{1}{k!(n-k)!}$
findet sich
\begin{align*}
\exp(X+Y) &= \sum_{n=0}^\infty\frac{(X+Y)^n}{n!}
= \sum_{n=0}^\infty\frac{1}{n!}\sum_{k=0}^n\binom{n}{k}X^k Y^{n-k}
= \sum_{n=0}^\infty\sum_{k=0}^n\frac{X^k}{k!}\frac{Y^{n-k}}{(n-k)!}\\
&= \bigg(\sum_{n=0}^\infty\frac{X^n}{n!}\bigg)
\bigg(\sum_{n=0}^\infty\frac{Y^n}{n!}\bigg)
= \exp(X)\exp(Y).\,\qedsymbol
\end{align*}
\end{Beweis}

\begin{Definition}[Reihen der Hyperbelfunktionen] Man definiert
\begin{gather*}
\cosh(X) := \sum_{k=0}^\infty \frac{X^k}{(2k)!},\quad
\sinh(X) := \sum_{k=0}^\infty \frac{X^{2k+1}}{(2k+1)!}.
\end{gather*}
\end{Definition}

\begin{Satz}[Paritätszerlegung der Exponentialreihe]%
\label{exp-parity}\newlinefirst
Es gilt $\exp(X)=\cosh(X)+\sinh(X)$.
\end{Satz}
\begin{Beweis}
Mit der Zerlegung $1 = [k\in 2\Z] + [k\in 2\Z+1]$ findet sich
\begin{align*}
\exp(X) &= \sum_{k=0}^\infty\frac{X^k}{k!}
= \sum_{k=0}^\infty\frac{X^k}{k!}[k\in 2\Z] + \sum_{k=0}^\infty\frac{X^k}{k!}[k\in 2\Z+1]\\
&= \sum_{k=0}^\infty\frac{X^{2k}}{(2k)!}
+ \sum_{k=0}^\infty\frac{X^{2k+1}}{(2k+1)!}
= \cosh(X) + \sinh(X).\,\qedsymbol
\end{align*}
\end{Beweis}

\newpage
\begin{Definition}[Reihen der Winkelfunktionen] Man definiert
\begin{gather*}
\cos(X) := \sum_{k=0}^\infty (-1)^k\frac{X^k}{(2k)!},\quad
\sin(X) := \sum_{k=0}^\infty (-1)^k\frac{X^k}{(2k+1)!}.
\end{gather*}
\end{Definition}

\begin{Satz}\label{cosh-sinh-imag-arg}
Es gilt $\cosh(\ui X) = \cos(X)$ und $\sinh(\ui X) = \ui\sin(X)$,\\
wobei $\ui$ die imaginäre Einheit ist.
\end{Satz}
\begin{Beweis}
Aufgrund $\ui^2=-1$ gilt $\ui^{2k} = (-1)^k$ und $\ui^{2k+1} = (-1)^k\ui$.
Hiermit findet sich
\begin{gather*}
\cosh(\ui X) = \sum_{k=0}^\infty\frac{(\ui X)^{2k}}{(2k)!}
= \sum_{k=0}^\infty\frac{\ui^{2k} X^{2k}}{(2k)!}
= \sum_{k=0}^\infty (-1)^k\frac{X^{2k}}{(2k)!} = \cos(X),\\
\sinh(\ui X) = \sum_{k=0}^\infty\frac{(\ui X)^{2k+1}}{(2k+1)!}
= \sum_{k=0}^\infty\frac{\ui^{2k+1} X^{2k+1}}{(2k+1)!}
= \ui\sum_{k=0}^\infty (-1)^k\frac{X^{2k+1}}{(2k+1)!}
= \ui\sin(X).\,\qedsymbol
\end{gather*}
\end{Beweis}

\begin{Satz}[Eulersche Formel]\newlinefirst
Es gilt $\exp(\ui X) = \cos(X)+\ui\sin(X)$, wobei $\ui$ die
imaginäre Einheit ist.
\end{Satz}
\begin{Beweis}
Man findet
\[\exp(\ui X) \stackrel{\text{(1)}}= \cosh(\ui X) + \sinh(\ui X)
\stackrel{\text{(2)}}= \cos(X)+\ui\sin(X).\]
Die Überlegung zu (1) verläuft auf direkte Weise analog zu der von
Satz \ref{exp-parity}. Die Umformung (2) gilt gemäß Satz
\ref{cosh-sinh-imag-arg}.\,\qedsymbol
\end{Beweis}

\section{Zahlenbereiche}

\subsection{Die natürlichen Zahlen}

\begin{Definition}[Natürliche Zahlen]\newlinefirst
Man bezeichnet $\N$ bezüglich einer Nachfolgerabbildung $s\colon\N\to\N$
als die natürlichen Zahlen, wenn die folgenden Axiome erfüllt sind:
\begin{gather*}
\text{(P1)}\quad 0\in\N,\\
\text{(P2)}\quad \text{$s$ ist injektiv},\\
\text{(P3)}\quad \forall n\in\N\colon s(n)\ne 0,\\
\text{(P4)}\quad \forall M\colon 0\in M\land (\forall n\in\N\colon n\in M\Rightarrow s(n)\in M)\Rightarrow \N\subseteq M.
\end{gather*}
\end{Definition}

\begin{Definition}[Addition natürlicher Zahlen]\newlinefirst
Man definiert rekursiv
\[a+0 := a,\quad a + s(b) := s(a + b).\]
\end{Definition}

\begin{Satz}
Mit $1:=s(0)$ gilt $s(a) = a+1$.
\end{Satz}
\begin{Beweis}
Es findet sich $a+1 = a+s(0) = s(a+0) = s(a)$.\,\qedsymbol
\end{Beweis}

\begin{Satz}[Assoziativgesetz der Addition]\newlinefirst
Für alle $a,b,c\in\N$ gilt $(a+b)+c = a+(b+c)$.
\end{Satz}
\begin{Beweis}
Induktion über $c$. Im Anfang $c=0$ gilt
\[(a+b)+c = (a+b)+0 = a+b = a+(b+0) = a+(b+c).\]
Zum Schritt. Induktionsvoraussetzung sei $(a+b)+c = a+(b+c)$. Man findet
\[(a+b)+s(c) = s((a+b)+c) \stackrel{\mathrm{IV}}= s(a+(b+c))
= a+s(b+c) = a+(b+s(c)).\,\qedsymbol\]
\end{Beweis}

\newpage
\begin{Satz}[Neutrales Element der Addition]%
\label{nat-zero}\newlinefirst
Für alle $a\in\N$ gilt $0+a = a+0 = a$.
\end{Satz}
\begin{Beweis}
Per Definition gilt $a+0=a$. Zu $0+a$ per Induktion über $a$.
Im Anfang $a=0$ ist $0+a = 0$ per Definition. Zum Schritt.
Induktionsvorausetzung sei $0+a=a$. Man findet
\[0+s(a) = s(0+a) \stackrel{\mathrm{IV}}= s(a).\,\qedsymbol\]
\end{Beweis}


\begin{Satz}[Kommutativgesetz der Addition]\newlinefirst
Für alle $a,b\in\N$ gilt $a+b = b+a$.
\end{Satz}
\begin{Beweis}
Zunächst $a+1 = 1+a$ per Induktion über $a$. Im Anfang $a=0$ gilt
die Aussage gemäß Satz \ref{nat-zero}. Zum Schritt. Man findet
\[1+s(a) = s(1+a) \stackrel{\mathrm{IV}}= s(a+1) = a+s(1).\]
Nun $a+b=b+a$ per Induktion über $b$. Der Fall $b=0$
gilt gemäß Satz \ref{nat-zero}. Anfang sei $b=1$. Dieser
wurde zuvor gezeigt. Zum Schritt. Man findet
\begin{align*}
s(b) + a &= (b+1)+a = b+(1+a) = b+(a+1) = b+s(a)\\
&= s(b+a)\stackrel{\mathrm{IV}}= s(a+b) = a+s(b).\,\qedsymbol
\end{align*}
\end{Beweis}

\begin{Definition}[Multiplikation natürlicher Zahlen]\newlinefirst
Man definiert rekursiv
\[a\cdot 0 := 0,\quad a\cdot s(b) := a\cdot b+a.\]
\end{Definition}

\begin{Satz}[Distributivgesetz der Multiplikation]\newlinefirst
Für alle $a,b,c\in\N$ gilt $(a+b)c = ac+bc$.
\end{Satz}
\begin{Beweis} Induktion über $c$. Im Anfang $c=0$ resultieren
beide Seiten der Gleichung im Wert~$0$. Zum Schritt. Man findet
\[(a+b)s(c) = (a+b)c+(a+b) \stackrel{\mathrm{IV}}= ac+bc+a+b = ac+a+bc+b
= as(c) + bs(c).\qedsymbol\]
\end{Beweis}

\begin{Lemma}\label{nat-mul-zero}
Für alle $a\in\N$ gilt $0a=0$.
\end{Lemma}
\begin{Beweis}
Induktion über $a$. Im Anfang $a=0$ ist per Definition $0a=0$.
Der Schritt ist
\[0s(a) = 0a+0 \stackrel{\mathrm{IV}}= 0+0 = 0.\]
\end{Beweis}

\begin{Satz}\label{nat-mul-one}
Für alle $a\in\N$ gilt $a\cdot 1=a$ und $1\cdot a=a$.
\end{Satz}
\begin{Beweis}
Die Formel $a\cdot 1 = a$ folgt unmittelbar aus der Definition
und bereits bekannten Regeln.

Die Formel $1\cdot a = a$ per Induktion über $a$. Im Anfang $a=0$ folgt
die Regel unmittelbar aus der Definition. Der Schritt ist
\[1s(a) = 1a+1 \stackrel{\mathrm{IV}}= a+1 = s(a).\,\qedsymbol\]
\end{Beweis}

\begin{Satz}[Kommutativgesetz der Multiplikation]\newlinefirst
Für alle $a,b\in\N$ gilt $ab=ba$.
\end{Satz}
\begin{Beweis}
Induktion über $b$. Im Anfang $b=0$ gilt die Regel gemäß
Lemma \ref{nat-mul-zero}. Der Schritt ist
\[as(b) = ab+a \stackrel{\mathrm{IV}}= ba+a = ba + 1a = (b+1)a = s(b)a.\,\qedsymbol\]
\end{Beweis}

\subsection{Die ganzen Zahlen}

\begin{Definition}[Ganze Zahlen]\newlinefirst
Man definiert die ganzen Zahlen $\Z$ als Quotientenmenge
\[\Z := (\N\times\N)/{\sim},\quad (x,y)\sim (x',y')\defiff x+y' = x'+y.\]
\end{Definition}

\begin{Satz}
Die Menge $\Z$ bildet bezüglich den wohldefinierten Operationen
\begin{gather*}
[(x,y)] + [(x',y')] := [(x+x',y+y')],\\
[(x,y)]\cdot [(x',y')] := [(xx'+yy',xy'+x'y)]
\end{gather*}
einen kommutativen unitären Ring.
\end{Satz}
\begin{Beweis}
Wohldefiniert heißt, dass das Resultat der Operation nicht von den
gewählten Repräsentanten abhängt. Sei dazu $(x,y)\sim (a,b)$ und
$(x',y')\sim (a'b')$. Zu zeigen ist%
\[(x+x',y+y') \sim (a+a',b+b'), \iff x+x'+b+b' = y+y'+a+a'.\]
Mit den Prämissen gilt $x+b=y+a$ und $x'+b'=y'+a'$, womit
\[(x+b)+(x'+b') = (y+a)+(y'+a'), \iff x+x'+b+b' = y+y'+a+a'.\]
Mit der Multiplikation verhält es sich ein wenig komplizierter.
Zu Vereinfachung wird zunächst gezeigt:
\begin{gather*}
[(x,y)]\cdot [(x',y')] = [(a,b)]\cdot [(x',y')]\\
\iff (xx'+yy',xy'+yx')\sim (ax'+by',ay'+bx')\\
\iff xx'+yy' + ay'+bx' = ax'+by' + xy'+yx'\\
\iff (x+b)x' + (a+y)y' = (a+y)x' + (x+b)y'.
\end{gather*}
Diese Gleichung ist gemäß Voraussetzung $(x,y)\sim (a,b)$
bzw. $x+b=a+y$ erfüllt.

Analog bestätigt man
\[[(a,b)]\cdot [(x',y')] = [(a,b)]\cdot [(a',b')].\]
Gemäß Transitivität ergibt sich somit
\[[(x,y)]\cdot [(x',y')] = [(a,b)]\cdot [(a',b')].\]
Es ist nun zu bestätigen, dass $(\Q,+)$ eine kommutative Gruppe ist.
Das Assoziativgesetz:
\begin{gather*}
([(x,y)]+[(x',y')])+[(x'',y'')]
= [(x+x',y+y')] + [(x'',y'')]\\
= [(x+x'+x'',y+y'+y'')]
= [(x,y)]+[(x'+x'',y'+y'')]\\
= [(x,y)]+([(x',y')]+[(x'',y'')]).
\end{gather*}
Das neutrale Element ist $[(0,0)]$, denn
\[[(x,y)]+[(0,0)] = [(x+0,y+0)] = [(x,y)].\]
Das inverse Element zu $[(x,y)]$ ist $[(y,x)]$, denn es gilt
\begin{gather*}
[(x,y)]+[(y,x)] = [(x+y,y+x)] = [(0,0)]\\
\iff (x+y,y+x)\sim (0,0)\iff x+y+0 = y+x+0.
\end{gather*}
Das Kommutativgesetz:
\[[(x,y)]+[(x',y')] = [(x+x',y+y')]
= [(x'+x,y'+y)]
= [(x',y')]+[(x,y)].\]
Es ist nun zu bestätigen, dass $(\Q,\cdot)$ ein kommutatives
Monoid bildet. Das Assoziativgesetz:
\begin{gather*}
([(x,y)]\cdot [(x',y')])\cdot [(x'',y'')]
= [(xx'+yy',xy'+x'y)]\cdot [(x'',y'')]\\
= [(xx'x''+x''yy'+xy'y''+x'yy'',\;
xx'y''+yy'y''+xx''y'+x'x''y)]\\
= [(x,y)]\cdot [(x'x''+y'y'',x'y''+x''y')]
= [(x,y)]\cdot ([(x',y')]\cdot [(x'',y'')]).
\end{gather*}
Das Kommutativgesetz:
\begin{gather*}
[(x,y)]\cdot [(x',y')] = [(xx'+yy',\;xy'+yx')]\\
= [(x'x+y'y,\;x'y+xy')] = [(x',y')]\cdot [(x,y)].
\end{gather*}
Das neutrale Element ist $[(1,0)]$, denn es gilt
\[[(x,y)]\cdot [(1,0)] = [(x\cdot 1+y\cdot 0,\;1\cdot y+x\cdot 0)]
= [(x,y)].\]
Schließlich ist noch das Distributivgesetz zu bestätigen.
Man findet
\begin{gather*}
[(a,b)]\cdot ([(x,y)]+[(x',y')])
= [(a,b)]\cdot [(x+x',y+y')]\\
= [(ax+ax'+by+by',\;ay+ay'+bx+bx')]\\
= [(ax+by,ay+bx)]+[(ax'+by',ay'+bx')]\\
= [(a,b)]\cdot [(x,y)] + [(a,b)]\cdot [(x',y')].
\end{gather*}
Somit sind alle Axiome bestätigt.\,\qedsymbol
\end{Beweis}

\begin{Definition}[Monoidhomomorphismus]\newlinefirst
Seien $(M,+)$ und $(M',+')$ zwei Monoide. Eine Abbildung
$\varphi\colon M\to M'$ heißt Monoidhomomorphismus, wenn
für alle $a,b\in M$ gilt
\[\varphi(a+b) = \varphi(a)+\varphi(b)\]
und $\varphi(0)=0'$ ist.
\end{Definition}

\begin{Satz}[Einbettung der natürlichen Zahlen in die ganzen]%
\label{embedding-nat-int}\newlinefirst
Die Abbildung $\varphi\colon\N_0\to\Z$ mit $\varphi(n):=[(n,0)]$
ist ein Monoidmonomorphismus.
\end{Satz}
\strong{Beweis.} Es ergibt sich
\[\varphi(a+b) = [(a+b,0)] = [(a,0)]+[(b,0)] = \varphi(a)+\varphi(b).\]
Außerdem ist $\varphi(0)=[(0,0)]$, und $[(0,0)]$
ist das neutrale Element von $(\Z,+)$.

Schließlich ist noch die Injektivität zu prüfen:
\begin{gather*}
[(a,0)] = \varphi(a) = \varphi(b)  = [(b,0)]\iff (a,0)\sim (b,0)\\
\iff a+0 = b+0 \iff a=b.\;\qedsymbol
\end{gather*}
\strong{Bemerkung.}
Anstelle von $\varphi(n)=[(n,0)]$ darf man daher kurz
$n=[(n,0)]$ schreiben. Außerdem definiert man $a-b:=a+(-b)$. Daraus
ergibt sich nun
\[[(x,y)] = [(x,0)]+[(0,y)] = [(x,0)] - [(y,0)] = x-y.\]
Die umständliche Schreibweise $[(x,y)]$ wird ab jetzt nicht
mehr benötigt.

\begin{Definition}[Totalordnung der ganzen Zahlen]\newlinefirst
Auf $\Z$ wird die folgende strenge Totalordnung definiert:
\[[(x,y)] < [(x',y')] \defiff x+y'<x'+y.\]
\end{Definition}

\begin{Satz}[Einbettung der Totalordnung]\mbox{}\\*
Die Abbildung $\varphi$ aus Satz \ref{embedding-nat-int}
genügt der Forderung
\[a<b \implies \varphi(a)<\varphi(b).\]
\end{Satz}
\begin{Beweis}
Nach den Definitionen ist
\[\varphi(a)<\varphi(b)\iff [(a,0)]<[(b,0)]\iff a+0<0+b\iff a<b.\,\qedsymbol\]
\end{Beweis}

\subsection{Die rationalen Zahlen}

\begin{Definition}[Rationale Zahlen]\newlinefirst
Man definiert die rationalen Zahlen $\Q$ als Quotientenmenge
\[\Q := (\Z\times\Z_{\ge 1})/{\sim},\quad (x,y)\sim (x',y')\defiff xy' = x'y.\]
\end{Definition}

\noindent
Für die Äquivalenzklasse $[(x,y)]\in\Q$ schreiben wir im Folgenden
$\frac{x}{y}$.

\begin{Satz}
Die Menge $\Q$ bildet bezüglich den wohldefinierten Operationen
\begin{gather*}
\frac{x}{y}+\frac{x'}{y'} := \frac{xy'+x'y}{yy'},\quad
\frac{x}{y}\cdot\frac{x'}{y'} := \frac{xx'}{yy'}
\end{gather*}
einen Körper.
\end{Satz}
\begin{Beweis}
Wohldefiniert bedeutet, dass das Ergebnis der
Operationen nicht von den gewählten Repräsentanten der Argumente
abhängig ist. Sei dazu $(a,b)\sim (x,y)$ und
$(a',b')\sim (x',y')$. Zu zeigen ist nun
\begin{align*}
&(ab'+a'b,bb')\sim (xy'+x'y,yy')\\
&\iff (ab'+a'b)(yy') = (xy'+x'y)(bb')\\
&\iff ab' yy' + a'byy' = xy'bb'+x'ybb'.
\end{align*}
Substituiert man $ay=xb$ und $a'y'=x'b'$ auf
der linken Seite der Gleichung, ergibt sich die rechte Seite.
Zu zeigen ist weiterhin
\begin{align*}
(aa',bb')\sim (xx',yy')
\iff aa'yy' = xx'bb'.
\end{align*}
Wieder wird linke Seite der Gleichung über $ay=xb$
und $a'y'=x'b'$ in die rechte Seite überführt.
Die Wohldefiniertheit der Operationen ist damit bestätigt.

Es bleibt zu prüfen, dass $(\Q,+,\cdot)$ allen Körperaxiomen genügt.
Das neutrale Element der Addition ist $0/1$, denn es gilt
\[\frac{x}{y}+\frac{0}{1} = \frac{x\cdot 1+0\cdot y}{y\cdot 1} = \frac{x}{y}.\]
Das neutrale Element der Multiplikation ist $1/1$, denn es gilt
\[\frac{x}{y}\cdot\frac{1}{1} = \frac{x\cdot 1}{y\cdot 1} = \frac{x}{y}.\]
Die Assoziativität der Addition ergibt sich ohne größere Umstände:
\begin{align*}
\bigg(\frac{x}{y}+\frac{x'}{y'}\bigg)+\frac{x''}{y''}
&= \frac{xy'+x'y}{yy'} + \frac{x''}{y''}
= \frac{xy'y''+x'yy''+x''yy'}{yy'y''},\\
\frac{x}{y}+\bigg(\frac{x'}{y'}+\frac{x''}{y''}\bigg)
&= \frac{x}{y}+\frac{x'y''+x''y'}{y'y''}
= \frac{xy'y''+x'yy''+x''yy'}{yy'y''}.
\end{align*}
Die Assoziativität der Multiplikation ist etwas einfacher:
\[\bigg(\frac{x}{y}\cdot\frac{x'}{y'}\bigg)\cdot\frac{x''}{y''}
= \frac{xx'}{yy'}\cdot\frac{x''}{y''} = \frac{xx'x''}{yy'y''}
= \frac{x}{y}\cdot\frac{x'x''}{y'y''}
= \frac{x}{y}\cdot\bigg(\frac{x'}{y'}\cdot\frac{x''}{y''}\bigg).\]
Das Kommutativgesetz der Addition:
\[\frac{x}{y}+\frac{x'}{y'} = \frac{xy'+x'y}{yy'}
= \frac{x'y+xy'}{y'y}
= \frac{x'}{y'}+\frac{x}{y}.\]
Das Kommutativgesetz der Multiplikation:
\[\frac{x}{y'}\cdot\frac{x'}{y'}
= \frac{xx'}{yy'} = \frac{x'x}{y'y}
= \frac{x'}{y'}\cdot\frac{x}{y}.\]
Das additiv inverse Element zu $x/y$ ist $(-x)/y$, denn es gilt
\[\frac{x}{y}+\frac{-x}{y} = \frac{xy+(-x)y}{y^2}
= \frac{0}{y^2} = \frac{0}{1}.\]
Das multiplikativ inverse Element zu $x/y$ mit $x\ne 0$
ist $y/x$, denn es gilt
\[\frac{x}{y}\cdot\frac{y}{x} = \frac{xy}{xy} = \frac{1}{1}.\]
Schließlich findet bestätigt man noch das Distributivgesetz:
\begin{align*}
&\frac{a}{b}\cdot\bigg(\frac{x}{y}+\frac{x'}{y'}\bigg)
= \frac{a}{b}\cdot\frac{xy'+x'y}{yy'}
= \frac{axy'+ax'y}{byy'},\\
&\frac{ax}{by}+\frac{ax'}{by'}
= \frac{axby'+ax'by}{byby'}
= \frac{b}{b}\cdot\frac{axy'+ax'y}{byy'}.
\end{align*}
Hierbei beachtet man, dass $b/b=1/1$ das multiplikativ
neutrale Element ist.\,\qedsymbol
\end{Beweis}

\newpage
\begin{Satz}[Einbettung der ganzen Zahlen in die rationalen]\newlinefirst
Sei $\varphi\colon\Z\to\Q$ mit $\varphi(z):=z/1$. Die
Abbildung $\varphi$ ist ein Eins"=erhaltender Ringmonomorphismus.
\end{Satz}
\begin{Beweis}
Die Erhaltung des Einselements ergibt sich
trivial. Ferner findet man
\[\varphi(a+b) = \frac{a+b}{1} = \frac{a\cdot 1+b\cdot 1}{1\cdot 1}
= \frac{a}{1}+\frac{b}{1} = \varphi(a)+\varphi(b)\]
und
\[\varphi(ab) = \frac{ab}{1} = \frac{ab}{1\cdot 1} = \frac{a}{1}\cdot\frac{b}{1}
= \varphi(a)\cdot\varphi(b).\,\qedsymbol\]
\end{Beweis}
\strong{Bemerkung.}
Vermittels der Einbettung können wir die ganze Zahl $z$ ab jetzt
mit der rationalen Zahl $z/1$ identifizieren. Das heißt, man schreibt
einfach $z=z/1$ anstelle von $\varphi(z)=z/1$.

\begin{Definition}[Division rationaler Zahlen]\mbox{}\\*
Wie in jedem Körper ist die Division für $a,b\in\Q$, $b\ne 0$
definiert als $a/b := ab^{-1}$.
\end{Definition}

