\documentclass[a4paper,10pt,fleqn,twocolumn,twoside]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mdframed}
\usepackage{microtype}

\usepackage{libertine}
\usepackage[cmintegrals]{newtxmath} 
\usepackage[scaled=0.80]{DejaVuSans}
\renewcommand\ttdefault{lmvtt}

\usepackage{color}
\definecolor{c1}{RGB}{00,40,80}
\usepackage[colorlinks=true,linkcolor=c1]{hyperref}
\usepackage{geometry}
\geometry{a4paper,left=25mm,right=10mm,top=24mm,bottom=26mm}
\setlength{\columnsep}{4mm}
\numberwithin{equation}{section}
\setcounter{tocdepth}{2}

\newcommand{\N}{\mathbb N}
\newcommand{\Z}{\mathbb Z}
\newcommand{\R}{\mathbb R}
\newcommand{\C}{\mathbb C}
\newcommand{\ee}{\mathrm e}
\newcommand{\ui}{\mathrm i}

\DeclareMathOperator{\real}{Re}
\DeclareMathOperator{\imag}{Im}
\DeclareMathOperator{\sgn}{sgn}

\newtheoremstyle{rmbox}%
  {0pt}% space above
  {0pt}% space below
  {}% bodyfont
  {}% indent
  {\sffamily\bfseries}% head font
  {~}% punctuation between head and body
  {0pt}% space after theorem head
  {\thmnote{#3.}}

\theoremstyle{rmbox}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Satz}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Korollar}

\definecolor{greenblue}{rgb}{0.0,0.32,0.4}
\definecolor{grayblue}{rgb}{0.2,0.2,0.4}

\surroundwithmdframed[topline=false,rightline=false,bottomline=false,%
  linecolor=greenblue, linewidth=3.5pt, innerleftmargin=4pt,%
  innertopmargin=2pt, innerbottommargin=6pt,%
  innerrightmargin=0pt%
]{definition}

\newcommand{\framedtheorem}[1]{%
\surroundwithmdframed[topline=false,rightline=false,bottomline=false,%
  linecolor=grayblue, linewidth=3.5pt, innerleftmargin=4pt,%
  innertopmargin=2pt, innerbottommargin=6pt,%
  innerrightmargin=0pt%
]{#1}}

\framedtheorem{theorem}
\framedtheorem{lemma}
\framedtheorem{corollary}

\begin{document}


\noindent
{\LARGE\sffamily\bfseries Aufzeichnungen
{\mdseries\rmfamily\large\hfill Juni 2018}\\[-2pt]
zur Mathematik\par}


\tableofcontents

\section{Grundlagen}
\subsection{Zerlegung des Allquantors}
Eine periodische Funktion $f$ erfüllt die Gleichung
\begin{equation}
f(x) = f(x+T)
\end{equation}
definiert. Macht man eine Substitution $x:=u-T$, so ergibt sich
\begin{equation}
f(u-T) = f((u-T)+T) = f(u).
\end{equation}
Somit gilt auch $f(x)=f(x-T)$. Diese Folgerung war sehr kurz,
eigentlich zu kurz um wissenschaftlich zu sein.

Eine Funktion $f{:}\;\mathbb R\rightarrow\mathbb R$
heißt periodisch mit Periode $T$, falls die
Funktionalgleichung
\begin{equation}
\forall x{\in}\mathbb R{:}\;\; f(x) = f(x+T)
\end{equation}
erfüllt ist. Für die Gleichung ergibt sich zunächst
der folgende abstrakte Syntaxbaum (AST):
\begin{verbatim}
  (=
      (f x)
      (f (+ x T)))
\end{verbatim}
Aber was ist mit dem Allquantor? Der Allquantor ist eigentlich
eine Funktion in zwei Variablen. Das erste Argument ist eine Menge $M$,
das zweite ein Prädikat $p$. Der Allquantor überprüft nun, ob das
Prädikat $p$ für alle Elemente von $M$ gültig ist. Wir wandeln nun
die Schreibweise durch
\begin{equation}
\forall x{\in}M{:}\;\; p(x)\quad\longrightarrow\quad
\mathrm{all}(M,p)
\end{equation}
um. Die Funktionalgleichung wird als nun in der Form
\begin{equation}\label{periodisch-all}
\mathrm{all}(\mathbb R,\lambda x. f(x) = f(x+T))
\end{equation}
dargestellt. Dazu gehört folgender AST:
\begin{verbatim}
  (all IR
      (lambda (x)
          (=
              (f x)
              (f (+ x T)))))
\end{verbatim}
Unter einer \textit{freien Substitution} versteht man nun den
Austausch jedes Vorkommens einer \textit{freien Variable}
durch einen AST. Durch den $\lambda$-Term wird die
Variable $x$ nun gebunden, ist also nicht mehr frei.
Daher können wir nicht einfach eine freie Substitution
$x{:=}u{-}T$ durchführen.

Viel mehr gilt die folgende Regel. Ist $g$ eine passende
Bijektion, so gilt
\begin{equation}\label{all-Umformung}
\mathrm{all}(M,p) = \mathrm{all}(g^{-1}(M),\;p\circ g).
\end{equation}
Z.B. wählt man $M:=\{1,2,3\}$ und $p(x):=(x{<}4)$
sowie $g(x):=x/2$. Somit ergibt sich
\begin{gather*}
(\forall x{\in}\{1,2,3\}{:}\;\; x<4)\\
= (\forall x{\in}\{2,4,6\}{:}\;\; x/2<4).
\end{gather*}
Sei nun $g(x):=x-T$. Nun ist $g^{-1}(\mathbb R)=\mathbb R$.
Wendet man das nun auf (\ref{periodisch-all}) an, so ergibt
sich
\begin{equation}
\mathrm{all}(\mathbb R, \lambda x.f(x-T)=f(x)).
\end{equation}
Es handelt sich also eigentlich nicht um eine Substitution,
sondern um die Verkettung des Prädikats mit einer Funktion.
Sicherlich lässt sich eine solche durch eine Substitution
darstellen, aber das ist sehr schwammig. Und diese Schwammigkeit
fällt erst auf, wenn der Allquantor auch ausgeschrieben wird.
Im Allquantor ist ja, wie wir gesehen haben, eine Variablenbindung
enthalten.

Doch warum darf man (\ref{all-Umformung}) eigentlich anwenden?
Nun, hierzu zerlegen wir den Allquantor weiter. Es ist nämlich
\begin{equation}
\mathrm{all}(M,p) = (p(M)=\{\mathrm{true}\}).
\end{equation}
Sei $\mathrm{id}$ die identische Funktion. Nun ist aber
$p$ das selbe wie $p\circ \mathrm{id}$. Außerdem gilt ja
$\mathrm{id} = g\circ g^{-1}$. Somit ergibt sich
\begin{equation}
\begin{split}
& p(M) = (p\circ g\circ g^{-1})(M)\\
& = (p\circ g)(g^{-1}(M)).
\end{split}
\end{equation}
In der letzten Gleichung wurde $(f\circ g)(M)=f(g(M))$
verwendet. Das soll noch schnell gezeigt werden. Es gilt
\begin{equation}
\begin{split}
&(f\circ g)(M)\\
&= \{(f\circ g)(x)|\;x\in M\}\\
&= \{f(y)|\; y=g(x) \wedge x\in M\}\\
&= \{f(y)|\; y\in g(M)\}
= f(g(M)).
\end{split}
\end{equation}
Nun gut, das ist auch ein Pseudobeweis. Wir können hier noch
\begin{equation}
\bigcup_{i\in I} f(A_i)
= f(\bigcup_{i\in I} A_i)
\end{equation}
verwenden. Dann gilt aber
\begin{gather*}
(f\circ g)(M) = \bigcup_{x\in M} \{f(g(x))\}
= \bigcup_{x\in M} f(\{g(x)\})\\
= f(\bigcup_{x\in M}\{g(x)\})
= f(g(M)).
\end{gather*}

Für den Existenzquantor gilt analog
\begin{equation}
\exists x{\in}A{:}\;p(x)\quad\text{gdw.}\quad\mathrm{true}\in p(A).
\end{equation}
Für die Beschreibung von Mengen gilt
außerdem
\begin{equation}
\begin{split}
&\{x{\in}A|\;p(x)\} = \mathrm{filter}(A,p)\\
&= p^{-1}(\{\mathrm{true}\}).
\end{split}
\end{equation}
Die Beschreibung von Mengen lässt sich also als
Urbildmenge darstellen.

Für den Anzahlquantor gilt außerdem
\begin{equation}
\exists^{=n} x{\in}A{:}\; p(x)
\quad\text{gdw.}\quad \#\mathrm{filter}(A,p)=n.
\end{equation}

\subsection[Allquantifizierung über Produktmengen]%
{Allquantifizierung\newline über Produktmengen}
Sei $M:=A\times B$. Sei $M_x:=\pi_1^{-1}(\{x\})$, das ist die
Faser von $x$ für die Projektion $\pi_1(x,y):=x$. Es gilt nun
\begin{equation}
M=\bigcup_{x\in A} M_x.
\end{equation}
Es gilt außerdem (was zu zeigen ist)
\begin{equation}\label{eq:forall-union}
\forall t{\in}\bigcup_{i\in I} A_i\,[P(t)]
\iff\forall i{\in}I\,\forall t{\in}A_i\,[P(t)].
\end{equation}
Daher ist
\begin{equation}
\begin{split}
&\forall (x,y){\in}M\,[P(x,y)]\\
&\iff\forall x{\in}A\,\forall (x,y){\in}M_x\,[P(x,y)].
\end{split}
\end{equation}
Wegen
\begin{equation}
\begin{split}
M_x &= \{x\}\times B\\
&= \{(x,y)\mid x\in\{x\}\land y\in B\}\\
&= \{(x,y)\mid y\in B\}
\end{split}
\end{equation}
gilt nun
\begin{equation}
(x,y)\in M_x\iff y\in B.
\end{equation}
Somit gilt
\begin{equation}
\begin{split}
&\forall (x,y){\in}M\,[P(x,y)]\\
&\iff\forall x{\in}A\;\forall y{\in}B\,[P(x,y)].
\end{split}
\end{equation}
Verwendet man $\pi_2$ anstelle von $\pi_1$, so gelangt man
zu der Erkenntnis $\forall x\forall y\iff\forall y\forall x$.

Betrachten wir nun \eqref{eq:forall-union} für endliche
Zerlegungen. Sei dazu $I(n):=\{1,...,n\}$ und $U_n:=U_{n-1}\cup A_n$
mit Anfang $U_1:=A_1$. Nun gilt $U_n=\bigcup_{i\in I(n)}A_i$.

Es ist nun
\begin{equation}
\begin{split}
&\forall t\in U_n\,[P(t)]\\
&\iff\forall t\in U_{n-1}\cup A_n\,[P(t)]\\
&\iff\forall t\in U_{n-1}\,[P(t)]\;\land\;\forall t\in A_n\,[P(t)]
\end{split}
\end{equation}
Falls \eqref{eq:forall-union} für $n-1$ gilt (Induktionsvoraussetzung),
so ist
\begin{equation}
\begin{split}
& \forall t\in U_{n-1}\,[P(t)]\\
& \iff\forall i{\in}I(n-1)\;\forall t{\in}A_i\,[P(t)].
\end{split}
\end{equation}
Zusammenführen, d.\,h.
\begin{equation}
\begin{split}
& \forall t{\in}A_n\,[P(t)]\;\land\;
\forall i{\in}I(n-1)\;\forall t{\in}A_i\,[P(t)]\\
&\iff\forall i{\in}I(n)\;\forall t{\in}A_i\,[P(t)],
\end{split}
\end{equation}
bringt \eqref{eq:forall-union} für $n$.
Die Induktion beginnen wir zunächst bei $n=1$, um möglichen
Problemen mit der leeren Menge aus dem Weg zu gehen.

Im allgemeinen Fall verwenden wir zunächst die prädikatenlogische
Definition der Vereinigungsmenge:
\begin{equation}\label{eq:union-def}
\bigcup_{i\in I}A_i := \{x\mid\exists i{\in}I\,[x\in A_i]\}.
\end{equation}
Nun gilt
\begin{equation}
\begin{split}
&\forall t\in\bigcup_{i\in I} A_i\,[P(t)]\\
&\iff\forall t[t\in\bigcup_{i\in I}A_i\implies P(t)]\\
&\iff\forall t[\exists i\,[t\in A_i]\implies P(t)]\\
&\iff\forall t[\forall i\,[t\in A_i\implies P(t)]]\\
&\stackrel{?!}{\iff}\forall i\,\forall t[t\in A_i\implies P(t)]\\
&\iff\forall i\forall t{\in}A_i[P(t)].
\end{split}
\end{equation}
Was noch zu zeigen ist, ist die Regel
\begin{equation}
\forall x\forall y\,[P(x,y)]
\iff \forall y\forall x\,[P(x,y)].
\end{equation}

\subsection{Zahlen als Mengen}
Die Potenzmenge einer Menge $M$ wird auch als $2^M$ notiert, weil
$|2^M| = 2^{|M|}$ gilt falls $M$ endlich ist. Nach dem Von-Neumann-Modell
ist aber $2:=\{0,1\}$. Daher entspricht $2^M$ der Menge
\begin{equation}
\{f\mid f\colon M\to\{0,1\}\}.
\end{equation}
Jeder Teilmenge entspricht eine Funktion $f$, welche für jedes
$x\in M$ auswählt, ob $x$ vorkommen soll oder nicht.
Die Potenzmenge kann daher auch als Menge aller charakteristischen
Funktionen von $M$ gesehen werden.

Die bisherige Betrachtung ermöglicht nun in Erfahrung zu bringen, was
$3^M$, $4^M$, usw. bedeutet. Bei $n^M$ handelt es sich um die
Menge der Funktionen
\begin{equation}
\{f\mid f\colon M\to\{0,1,\ldots,n-1\}\}.
\end{equation}
Eine Funktion $f$ zählt also für jedes $x\in M$ wie oft es vorkommen
soll, wobei $n-1$ die Maximale Anzahl ist. Somit kann $n^M$ als
Menge von Multimengen interpretiert werden.

Man definiert normalerweise $A^1:=A$ und $A^{n+1}:=A\times A^n$.
Jetzt stellt sich aber die Frage, was denn $A^0$ ist. Weiterhin
gültig sein sollte
\begin{equation}
|A^0| = |A|^0 = 1.
\end{equation}
Daher müsste sich eine einelementige Menge ergeben. Die einfachste
einelementige Menge ist $\{0\}$. Andererseits ist $A^n$ eine Menge
von $n$-Tupeln. Also müsste $A^0$ das leere Tupel enthalten. Somit
müsste $0=\{\}=()$ sein. Das kartesische Produkt ist eigentlich nicht
assoziativ. Aus diesem Grund definiert man explizit
\begin{equation}
(x,y,z) := (x,(y,z))
\end{equation}
und so weiter. Beginnt man mit der leeren Menge, so ergeben sich
die alternativen Darstellungen:
\begin{gather}
() := \{\},\\
(a) := (a,\{\}),\\
(a,b) := (a,(b,\{\})),\\
(a,b,c) := (a,(b,(c,\{\}))),
\end{gather}
und so weiter. Dies entspricht der Darstellung von Listen
in Lisp, also einfach verketteten Listen.

Bei $f\colon A^0\to B$ handelt es sich somit um eine Funktion, welche
dem leeren Tupel einen Wert zuordnet. Eine solche nullstellige
Funktion entspricht einer Konstante. In der Informatik muss die
»Funktion« natürlich zusätzlich referenziell transparent sein.

%\newpage
\section{Analysis}
\subsection{Halley-Verfahren}
Im Folgenden wird die Herleitung des Halley"=Verfahrens unter
Verwendung einer Padé"=Approximation dargestellt.
Die Padé"=Approximation $R[m,0]$ ist die Taylorreihe. Sei
\begin{equation}
a_k = \frac{1}{k!} f^{(k)}(x_0).
\end{equation}
Die Taylorreihe ist
\begin{equation}
R[m,0] = \sum_{k=0}^m a_k(x-x_0)^k.
\end{equation}
Sei\\
$\mbox{}\qquad A=\begin{vmatrix}
a_{m-n+1} & a_{m-n+2} & \ldots & a_{m+1}\\
\ldots & \ldots & \ldots & \ldots\\
a_m & a_{m+1} & \ldots & a_{m+n}\\
\sum\limits_{i=n}^m a_{i-n}x^i &
\sum\limits_{i=n-1}^m a_{i-n+1}x^i
&\ldots & \sum\limits_{i=0}^m a_i x^i
\end{vmatrix}$\\
und\\
$\mbox{}\qquad B=\begin{vmatrix}
a_{m-n+1} & a_{m-n+2} & \ldots & a_{m+1}\\
\ldots &\ldots &\ldots &\ldots\\
a_m & a_{m+1} &\ldots & a_{m+n}\\
x^n & x^{n-1} &\ldots & x^0
\end{vmatrix}$.\\
Es ist $R[m,n]=A/B$.
Ersetze dann $x$ gegen\\
$x-x_0$. Es ist
\begin{equation}
\begin{split}
& R[1,1] = \frac{a_1(a_0+a_1 x)-a_0a_2x}{a_1-a_2x}\\
& = \frac{a_0a_1+(a_1^2-a_0a_2)x}{a_1-a_2x}.
\end{split}
\end{equation}
Die Nullstelle von $f$ ist gesucht, und die Approximation
muss dort auch ungefähr null sein. Setzt man also $R[1,1](x)=0$,
so folgt
\begin{equation}
0=a_0a_1+(a_1^2-a_0a_2)x.
\end{equation}
Ersetzt man noch $x$ gegen $x-x_0$ und formt danach um,
so erhält man
\begin{equation}
x=x_0-\frac{a_0a_1}{a_1^2-a_0a_2}.
\end{equation}
Ausgeschrieben bekommt man also $x=\varphi(x_0)$ mit
\begin{equation}
\varphi(x) = x-\frac{2f(x)f'(x)}{2f'(x)^2-f(x)f''(x)}.
\end{equation}
Das Halley"=Verfahren ist dann die Fixpunktiteration
$x_{n+1}=\varphi(x_n)$.
Man sieht, dass das Halley"=Verfahren in das Newton"=Verfahren
übergeht, wenn man $f(x)f''(x)$ verschwinden lässt.

% \newpage
\subsection{Integral der Potenzfunktion}
Ich will eine ungewöhnliche Methode zur Berechnung des Integrals
\begin{equation}
\int x^n\,\mathrm dx
\end{equation}
vorführen. Wähle die Substitution $x=\ee^u$. Es gilt nun
\begin{equation}
\frac{\mathrm dx}{\mathrm du}=\frac{\mathrm d}{dx}\ee^u=\ee^u
\end{equation}
und somit $\mathrm dx = \ee^u\,\mathrm du$. Man hätte auch
\begin{equation}
x^n = \ee^{\ln(x)n} = \ee^{un}
\end{equation}
rechnen können, was vielleicht eher
\begin{equation}
\frac{\mathrm du}{\mathrm dx} = \frac{\mathrm d}{\mathrm dx}\ln(x) = \frac{1}{x}
\end{equation}
suggeriert hätte. Hier muss man bedenken, dass die Substitution
nochmals ausgeführt werden kann, dass also%
\begin{equation}
\frac{1}{x} = \frac{1}{\ee^u}
\end{equation}
gilt. Nach Substitutionsregel ergibt sich nun
\begin{equation}
\begin{split}
&\int x^n\,\mathrm dx = \int \ee^{nu}\ee^u\mathrm du
= \int \ee^{(n+1)u}\,\mathrm du\\
&= \frac{1}{n+1}\ee^{(n+1)u} = \frac{x^{n+1}}{n+1}.
\end{split}
\end{equation}
Es geht noch weiter. Im Fall $n=-1$ gilt
\begin{equation}
\int \frac{1}{x}\,\mathrm dx
= \int\frac{1}{\ee^u}\,\ee^u\mathrm du
= \int\mathrm du = u.
\end{equation}
Aber Umformen der Substitution ergibt ja $u=\ln x$.

\subsection{Zum Basler Problem}
Betrachte die Summenformel
\begin{equation}
\sum_{k=m}^{n-1} q^k = \frac{q^n-q^m}{q-1}.\qquad (q\ne 1)
\end{equation}
Mit Differentialrechnung lässt sich daraus die Formel
\begin{equation}
\sum_{k=m}^{n-1} k^p q^k 
= \Big(q\frac{\mathrm d}{\mathrm dq}\Big)^p\;\frac{q^n-q^m}{q-1}
\end{equation}
gewinnen, das ist eine bekannte Technik. Man beachte dabei
\begin{equation}
\Big(q\frac{\mathrm d}{\mathrm dq}\Big)^p
\ne q^p \Big(\frac{\mathrm d}{\mathrm dq}\Big)^p.\qquad (p\ge 2)
\end{equation}
Die Vorgehensweise wird nun umgedreht, so dass integriert wird,
anstelle zu differenzieren:
\begin{gather}
\int_0^q \frac{1}{q}\sum_{k=m}^{n-1} q^k \mathrm dq
= \int_0^q\bigg(\frac{1}{q}\bigg)\frac{q^n-q^m}{q-1}\,\mathrm dq.
\end{gather}
Es ergibt sich
\begin{equation}
\sum_{k=m}^{n-1}\frac{q^k}{k^2}
= \int_0^q\frac{1}{q}\int_0^q\frac{q^n-q^m}{q^2-q}\,\mathrm dq\,\mathrm dq.
\end{equation}
Man setzt nun $m=1$ und lässt $n\to\infty$ gehen.
Das bringt%
\begin{equation}
\sum_{k=1}^\infty\frac{q^k}{k^2}
= \int_0^q\frac{1}{q}\int_0^q\frac{1}{1-q}\,\mathrm dq\,\mathrm dq.
\end{equation}
Um die Polstelle lässt sich in der komplexen Ebene herumintegerieren.
Dabei ergibt sich
\begin{equation}
\sum_{k=1}^\infty\frac{q^k}{k^2}
= \int_q^0 \frac{\ln(1-q)}{q}\,\mathrm dq,
\end{equation}
und somit
\begin{equation}
\sum_{k=1}^\infty\frac{1}{k^2}
= \lim_{q\to 1}\int_q^0 \frac{\ln(1-z)}{z}\,\mathrm dz.
\end{equation}
Die Definitionslücke bei $z=0$ lässt sich stetig beheben. Dann muss
aber auch das Integral existieren. Mittels Substitution $1-z:=\ee^x$
ergibt sich noch
\begin{equation}
\sum_{k=1}^\infty\frac{1}{k^2}
= \lim_{q\to 1}\int_{\ln(1-q)}^0 \frac{x\ee^x}{\ee^x-1}\,\mathrm dx.
\end{equation}
Demnach gilt
\begin{equation}
\sum_{k=1}^\infty\frac{1}{k^2}
= \int_{-\infty}^0 \frac{x\ee^x}{\ee^x-1}\,\mathrm dx.
\end{equation}
Substitution $x:=-x$ ergibt nun
\begin{equation}
\sum_{k=1}^\infty\frac{1}{k^2}
= \int_0^\infty \frac{x\ee^{-x}}{1-\ee^{-x}}\,\mathrm dx.
\end{equation}
Erweitert man den Bruch nun mit $\ee^x$, was wegen $\ee^x\ne 0$
gefahrlos getan werden kann, dann ergibt sich%
\begin{equation}
\sum_{k=1}^\infty\frac{1}{k^2}
= \int_0^\infty \frac{x}{\ee^x-1}\,\mathrm dx.
\end{equation}
Schaut man sich den Graph des Integranden an, dann bemerkt man,
dass sich dieses Integral besonders gut numerisch integrieren
lässt.

Die Bernoulli-Zahlen $\bar B_k$ mit $\bar B_1=-1/2$
sind implizit definiert durch%
\begin{equation}
\frac{x}{\ee^x-1} = \sum_{k=0}^\infty \bar B_k\frac{x^k}{k!}.
\end{equation}
Demnach gilt:
\begin{equation}
\sum_{k=1}^\infty\frac{1}{k^2}
= \lim_{x\to\infty}\sum_{k=0}^\infty \bar B_k\frac{x^{k+1}}{(k+1)!}.
\end{equation}

%\newpage
\subsection{Integraldarstellung der Zeta-Funktion}

\subsubsection{Vorbetrachtung}
Wir wollen zunächst eine Formel für das wiederholte Integral
\begin{gather}
(I_a^n f)(x) := \left(\int_a^x\right)^n f(x)\,(\mathrm dx)^n\\
= \int_a^x\int_a^x\ldots\int_a^x f(x)\,\mathrm dx\mathrm dx\ldots\mathrm dx
\end{gather}
herleiten.

Aus der Formel für Parameterintegrale erhält man
zunächst den Spezialfall%
\begin{equation}
\int_a^x \frac{\partial \varphi(x,t)}{\partial x}\,\mathrm dt+\varphi(x,x)
= \frac{\mathrm d}{\mathrm dx}\int_a^x \varphi(x,t)\,\mathrm dt.
\end{equation}
Einsetzen von $\varphi(x,t):=(x-t)^n f(t)$ bringt für $n>0$ nun
\begin{equation}
n\int_a^x (x-t)^{n-1}f(t)\,\mathrm dt
= \frac{\mathrm d}{\mathrm dx}\int_a^x (x-t)^n f(t)\,\mathrm dt.
\end{equation}
Wiederholt man das noch $n$ mal, dann findet man
\begin{equation}
n!\,f(x) =
\left(\frac{\mathrm d}{\mathrm dx}\right)^{n+1} \int_a^x (x-t)^n f(t)\,\mathrm dt,
\end{equation}
wobei $n!=\Gamma(n+1)$ gilt. Man definiert nun noch
\begin{equation}
(I_a f)(x) := \int_a^x f(t)\,\mathrm dt.
\end{equation}
Da sich Integral und Ableitung gegenseitig aufheben, ergibt sich
\begin{equation}
\Gamma(n+1)\, (I_a^{n+1}f)(x) = \int_a^x (x-t)^n f(t)\,\mathrm dt.
\end{equation}
Umformen bringt die folgende Formel:

\begin{theorem}[Riemann-Liouville-Integral]
\begin{equation}\label{eq:Riemann-Liouville-Integral}
(I_a^n f)(x) = \frac{1}{\Gamma(n)}\int_a^x (x-t)^{n-1}f(t)\,\mathrm dt.
\end{equation}
\end{theorem}
Für $n$ kann nun sogar eine komplexe Zahl eingesetzt werden, wobei
man hofft, dass das Integral konvergiert.

\newpage
\subsubsection{Integraldarstellung}
\begin{definition}[Satz und Definition. Zeta-Funktion]\mbox{}\\
Für $\real(s)>1$ konvergiert die Reihe:
\begin{equation}
\zeta(s) := \sum_{k=1}^\infty \frac{1}{k^s}.
\end{equation}
\end{definition}
Ohne Beweis. Betrachte nun die Summenformel
\begin{equation}
\sum_{k=m}^{n-1} q^k = \frac{q^n-q^m}{q-1}.\qquad (q\ne 1)
\end{equation}
Mit Differentialrechnung lässt sich daraus die Formel
\begin{equation}
\sum_{k=m}^{n-1} k^p q^k 
= \Big(q\frac{\mathrm d}{\mathrm dq}\Big)^p\;\frac{q^n-q^m}{q-1}
\end{equation}
gewinnen, das ist eine bekannte Technik. Man beachte dabei
\begin{equation}
\Big(q\frac{\mathrm d}{\mathrm dq}\Big)^p
\ne q^p \Big(\frac{\mathrm d}{\mathrm dq}\Big)^p.\qquad (p\ge 2)
\end{equation}
Die Vorgehensweise wird nun umgedreht, so dass integriert wird,
anstelle zu differenzieren. Es ergibt sich%
\begin{equation}
\sum_{k=m}^{n-1} \frac{q^k}{k^p}
= \left(\int_0^q \frac{1}{q}\right)^p \frac{q^n-q^m}{q-1}\,(\mathrm dq)^p.
\end{equation}
Damit ist folgendes gemeint:
\begin{equation}
\sum_{k=m}^{n-1} \frac{q^k}{k^p}
= \int_0^q \frac{1}{q}\int_0^q \frac{1}{q}\ldots\int_0^q \frac{1}{q}
\left(\frac{q^n-q^m}{q-1}\right)\,\mathrm dq\mathrm dq\ldots\mathrm dq.
\end{equation}
Wir setzen nun $m=1$. Verlangen wir $q<1$, dann können wir $n\to\infty$
auf beiden Seiten der Gleichung anwenden und erhalten:%
\begin{equation}
\sum_{k=1}^\infty \frac{q^k}{k^p}
= \left(\int_0^q \frac{1}{q}\right)^p \frac{q}{1-q}\,(\mathrm dq)^p
= \left(\int_0^q \mathrm dq \frac{1}{q}\right)^p \frac{q}{1-q}.
\end{equation}
Beachtet man nun $\frac{\mathrm d\ln q}{\mathrm dq}=\frac{1}{q}$
und stellt dies zu $\mathrm d\ln q = \frac{\mathrm dq}{q}$ um,
dann wird klar, dass wir hier mit der Substitution $x=\ln q$
weiterarbeiten können. Es ergibt sich:%
\begin{equation}
\sum_{k=1}^\infty \frac{q^k}{k^p}
= \left(\int_{\ee^x=0}^{\ee^x=q} \mathrm dx\right)^p \frac{\ee^x}{1-\ee^x}.
\end{equation}
Nun werden aber auch alle $q$ in den Grenzen bis auf das letzte
von innen nach außen gegen $\ee^x$ ersetzt. Dann ergibt sich
immer $\ee^x=\ee^x$, also $x=x$. Somit gilt:%
\begin{equation}
\sum_{k=1}^\infty \frac{q^k}{k^p}
= [x:=\ln q]\left(\int_{-\infty}^{x} \mathrm dx\right)^p \frac{\ee^x}{1-\ee^x}.
\end{equation}
Wendet man nun Formel \eqref{eq:Riemann-Liouville-Integral}
mit $n=p$ an, dann ergibt sich%
\begin{equation}
\sum_{k=1}^\infty \frac{q^k}{k^p}
= \frac{1}{\Gamma(p)}\int_{-\infty}^{\ln q} (\ln q-t)^{p-1}\frac{\ee^t}{1-\ee^t}\,\mathrm dt.
\end{equation}
Wir substituieren nun $x=-t$ und erhalten
\begin{equation}
\sum_{k=1}^\infty \frac{q^k}{k^p}
= \frac{1}{\Gamma(p)}\int_{\infty}^{-\ln q} (\ln q+x)^{p-1}\frac{\ee^{-x}}{\ee^{-x}-1}\,\mathrm dx.
\end{equation}
Den Integrand können wir wegen $\ee^x\ne 0$ gefahrlos mit $\ee^x$
erweitern und erhalten%
\begin{equation}
\frac{\ee^{-x}}{\ee^{-x}-1} = \frac{1}{1-\ee^x}.
\end{equation}
Wir können nun auf beiden Seiten $q\to 1$ anwenden, wobei das Integral
dann natürlich für beide Grenzen als uneigentliches zu verstehen
ist. Wegen $\ln q\to 0$ ergibt sich%
\begin{equation}
\sum_{k=1}^\infty \frac{1}{k^p}
= \frac{1}{\Gamma(p)}\int_{\infty}^0 x^{p-1}\frac{1}{1-\ee^x}\,\mathrm dx
= \frac{1}{\Gamma(p)}\int_0^\infty \frac{x^{p-1}}{\ee^x-1}\,\mathrm dx.
\end{equation}
Nimmt man jetzt an, dass Formel \eqref{eq:Riemann-Liouville-Integral}
auch für gewisse komplexe Zahlen $n=s$ gültig ist, dann ergibt sich
für die Zeta"=Funktion die Integraldarstellung:%
\begin{theorem}[Integraldarstellung der Zeta-Funktion]
\begin{equation}
\zeta(s) = \frac{1}{\Gamma(s)}\int_0^\infty \frac{x^{s-1}}{\ee^x-1}\,\mathrm dx.
\end{equation}
\end{theorem}
Tatsächlich gilt auch diese Formel für $\real(s)>1$, was an dieser
Stelle nicht weiter gezeigt werden soll. Stattdessen erhalten wir
daraus die Einsicht, dass das Riemann"=Liouville"=Integral offenbar
konsistente Resultate liefern kann. Die genauen Voraussetzungen dafür
stehen momentan im Dunklen und müssten herausgearbeitet werden.

\subsection{Metamorphose}

Seien $f(x)$ und $g(x)$ zwei reelle Funktionen und sei $r$ aus
dem Intervall $[0,1]$. Eine Metamorphose von $f$ zu $g$
lässt sich durch die Funktion
\begin{equation}
h(x) = (1-r)f(x)+rg(x)
\end{equation}
modellieren. Dabei handelt es sich um das punktweise gewichtete
arithmetische Mittel der beiden Funktionen. Man bezeichnet dies
auch als Konvexkombination.

Allgemeiner muss es sich bei $f$ und $g$ natürlich nicht um relle
Funktionen handeln. Für zwei Parameterkurven oder  zwei Vektorfelder
lässt sich so auch eine Metamorphose bilden.

Sind $F(x,y)=0$ und $G(x,y)=0$ zwei implizite Funktionen, so
lässt sich die Metamorphose durch
\begin{equation}
H(x,y) = (1-r)F(x,y)+rG(x,y) = 0.
\end{equation}
modellieren. Setzt man $F(x,y)=y-f(x)$ und $G(x,y)=y-g(x)$,
so erhält man das zuvor beschriebene Modell als Spezialfall.

Sind allgemeiner $F$ und $G$ Funktionen mit mehreren
Variablen, so kann die Metamorphose der impliziten Funktionen
analog durch
\begin{equation}
(1-r)F(x_1,\ldots,x_n)+rG(x_1,\ldots,x_n)=0.
\end{equation}
beschrieben werden.

\newpage

\subsection{Grünwald-Letnikow-Ableitung}

Den Translationsoperator $T_h$ definiert man durch
\begin{equation}
(T_h f)(x) := f(x+h).
\end{equation}
Für den Differenzoperator gilt nun:
\begin{equation}
(\Delta_h f)(x) := f(x+h)-f(x) = (T_h-1) f(x).
\end{equation}
Setzt man nun die binomische Reihe ein, dann ergibt sich%
\begin{equation}
\Delta_h^n = (T_h-1)^n
= (-1)^n \sum_{k=0}^\infty \binom{n}{k} (-1)^k T_h^k.
\end{equation}
Wegen $T_h^k = T_{hk}$ ergibt sich nun
\begin{equation}
(\Delta_h^n f)(x) = (-1)^n \sum_{k=0}^\infty \binom{n}{k} (-1)^k f(x+kh).
\end{equation}
Für eine natürliche Zahl $n$ geht die Reihe nur bis $n=k$. Wir wollen
jetzt aber auch komplexe Zahlen für $n$ einsetzen.

Nun ergibt sich heuristisch
\begin{equation}
(D^n f)(x) = \lim_{h\to 0} \bigg(\frac{\Delta_h}{h}\bigg)^n f(x)
= \lim_{h\to 0}\frac{1}{h^n} (\Delta_h^n f)(x).
\end{equation}
Das führt uns zu folgender Definition:
\begin{definition}[Umgekehrte Grünwald-Letnikow-Ableitung]
\begin{equation}
(D^n f)(x) := \lim_{h\to 0}
\frac{(-1)^n}{h^n} \sum_{k=0}^\infty \binom{n}{k} (-1)^k f(x+kh).
\end{equation}
\end{definition}
Substitutiert man nun $h:=-h$ dann ergibt sich:
\begin{definition}[Direkte Grünwald-Letnikow-Ableitung]
\begin{equation}
(D^n f)(x) := \lim_{h\to 0}
\frac{1}{h^n} \sum_{k=0}^\infty \binom{n}{k} (-1)^k f(x-kh).
\end{equation}
\end{definition}
Man beachte nun aber auch
\begin{gather}
(a+b)^n = a^n \bigg(1+\frac{b}{a}\bigg)^n\\
= a^n\sum_{k=0}^\infty \binom{n}{k}\bigg(\frac{b}{a}\bigg)^k
= \sum_{k=0}^\infty \binom{n}{k} a^{n-k}b^k,
\end{gather}
falls die binomische Reihe konvergiert. Demnach ergibt sich%
\begin{equation}
\Delta_h^n = (T_h-1)^n = \sum_{k=0}^\infty \binom{n}{k}(-1)^k T_h^{n-k}.
\end{equation}
Das führt nun zu:
\begin{definition}[Definition. Grünwald-Letnikow-Ableitung]
\begin{equation}
(D^n f)(x) := \lim_{h\to 0}
\frac{1}{h^n} \sum_{k=0}^\infty \binom{n}{k} (-1)^k f(x+(n-k)h).
\end{equation}
\end{definition}

\newpage
\section{Lineare Algebra}
\subsection{Lineare Abbildungen}
Seien $V,W$ zwei Vektorräume über dem Körper $K$. Eine Abbildung
$f\colon V\to W$ heißt \emph{additiv}, wenn für alle $v,w\in V$ gilt:%
\begin{equation}
f(v+w) = f(v)+f(w)
\end{equation}
und \emph{homogen}, wenn für alle $v\in V$ und $\lambda\in K$ gilt:
\begin{equation}
f(\lambda v) = \lambda f(v).
\end{equation}
Ist eine additive Abbildung auch homogen? Man bemerkt zunächst%
\begin{equation}
f(2v) = f(v+v) = f(v)+f(v) = 2f(v).
\end{equation}
Allgemein ergibt sich bei dieser Betrachtung $f(nv) = nf(v)$ für jede
natürliche Zahl $n\ge 1$. Weiterhin gilt%
\begin{equation}
f(0v) = f(0) = f(0+0) = f(0) + f(0).
\end{equation}
Aus $f(0)=f(0)+f(0)$ folgt $f(0)=0=0f(v)$.

Beachte nun
\begin{equation}
0 = f(\underbrace{-v+v}_{=0}) = f(-v)+f(v).
\end{equation}
Daraus folgt $f(-v) = -f(v)$.
Nach den bisherigen Ausführungen ergibt sich $f(nv) = nf(v)$ für alle
$n\in\Z$.

Die Fragestellung lässt sich auch für rationale Zahlen bejahen.
Die grundlegende Feststellung dazu ist
\begin{equation}
f(v) = f(\tfrac{1}{2}v+\tfrac{1}{2}v) = f(\tfrac{1}{2}v) + f(\tfrac{1}{2}v)
= 2f(\tfrac{1}{2}v).
\end{equation}
Division durch zwei bringt $\tfrac{1}{2}f(v) = f(\tfrac{1}{2}v)$.
Allgemein gilt wieder $\frac{1}{n}f(v) = f(\tfrac{1}{n}v)$ für
$n\in\N$ mit $n\ge 1$. Ist $q$ nun eine rationale Zahl, so gibt
es die Darstellung $q=\frac{m}{n}$ mit $m\in\Z$ und $n\in\N, n\ge 1$.
Es gilt nun
\begin{equation}
\begin{split}
f(qv) &= f(m\cdot\tfrac{1}{n}\cdot v) = m\cdot f(\tfrac{1}{n}\cdot v)\\
&= m\cdot\tfrac{1}{n}\cdot f(v) = qf(v).
\end{split}
\end{equation}
Was ist nun mit reellen Zahlen? Sei dazu $s_n:=\sum_{k=0}^n q_k$
eine Reihe von rationalen Zahlen $q_k$, welche gegen eine reelle
Zahl $r$ konvergiert. Am besten $q_k = \frac{d_k}{10^k}$ mit
$q_0\in\Z$ und $q_{k\ne 0}\in\{0\ldots 9\}$.

Nun gilt
\begin{equation}
\begin{split}
&f(rv) = f\bigg(\bigg(\lim_{n\to\infty}\sum_{k=0}^n q_k\bigg)v\bigg)
\stackrel{?}= f\bigg(\lim_{n\to\infty}\bigg(\sum_{k=0}^n q_k\bigg)v\bigg)\\
&= f\bigg(\lim_{n\to\infty}\sum_{k=0}^n q_k v\bigg)
\stackrel{??}= \lim_{n\to\infty} f\bigg(\sum_{k=0}^n q_k v\bigg)
= \lim_{n\to\infty}\sum_{k=0}^n q_k f(v)\\
&= \lim_{n\to\infty}\bigg(\sum_{k=0}^n q_k\bigg) f(v)
\stackrel{?}= \bigg(\lim_{n\to\infty}\sum_{k=0}^n q_k\bigg) f(v)
= r f(v).
\end{split}
\end{equation}
Um die Fragezeichen zu klären, nimmt man nun an, dass $V$ und $W$
mit einer Norm ausgestattet und somit metrische Räume sind.
Der folgende elementare Satz ist jetzt aufschlussgebend.

\textbf{Satz.} Eine Abbildung $f\colon X\to Y$ zwischen metrischen
Räumen $(X,d_x)$ und $(Y,d_y)$ ist genau dann stetig, wenn für
jede konvergente Folge $(x_n)$ mit $x_n\in X$ die Eigenschaft
\begin{equation}
f\Big(\lim_{n\to\infty} x_n\Big) = \lim_{n\to\infty} f(x_n)
\end{equation}
gilt.

Wenn kein metrischer Raum vorliegt, lassen sich die Begriffe
Cauchy-Folge und Vollständigkeit nicht mehr formulieren und es
liegt eventuell nicht einmal mehr ein Hausdorff-Raum vor, was eine
sehr komische Situation darstellt. Sind die Vektorräume nicht
topologisch, so lässt sich nicht einmal mehr der Begriff des
Grenzwertes formulieren.

\subsection{Hodge-Stern-Operator}
\subsubsection{Orientierung}
Sei $V$ ein $\R$-Vektorraum und sei $B=(b_k)_{k=1}^n$ eine Basis
von $V$, die wir positiv orientiert nennen. Ist $B'$ eine andere
Basis, so gibt es eine Basiswechselmatrix $T_{B'}^B$. Sei nun
\begin{equation}
s := \sgn(\det(T_{B'}^B)).
\end{equation}
Die Basis $B'$ heißt nun \emph{positiv orientiert}, wenn
$s>0$ ist und \emph{negativ orientiert}, wenn $s<0$ ist.

Im Koordinatenraum soll natürlich die Standardbasis positiv
orientiert sein.

Beachte, dass für das äußere Produkt gilt:
\begin{equation}
\bigwedge_{k=1}^n b_k' = \det(T_B^{B'}) \bigwedge_{k=1}^n b_k.
\end{equation}
Angenommen, die Basis $B'$ ist nun eine Permutation von $B=(b_k)$,
also die Festlegung
\begin{equation}
B' := (b_{\sigma(k)})_{k=1}^n, \quad \sigma\in\operatorname{Sym}(n).
\end{equation}
Die Basiswechselmatrix ist nun die Permutationsmatrix und somit gilt:
\begin{equation}
\det(T_{B'}^B) = \sgn(\sigma).
\end{equation}

\subsection{Skalarprodukträume}
Ist $V$ ein Skalarproduktraum und ist
$B=(e_k)_{k=1}^n$ eine Orthonormalbasis von $V$,
so ist der Hodge-Stern-Operator eine lineare Abbildung,
definiert durch%
\begin{equation}
\begin{split}
&*(e_{\sigma(1)}\wedge\ldots\wedge e_{\sigma(k)})\\
&:= \sgn(\sigma)\,s(B)\,e_{\sigma(k+1)}\wedge\ldots\wedge e_{\sigma(n)}
\end{split}
\end{equation}
mit $*\colon \Lambda^k(V)\to\Lambda^{n-k}(V)$,
wobei $0\le k\le n$ gilt.

Dabei ist $s(B)=+1$, wenn $B$ positiv orientiert ist,
und $s(B)=-1$, wenn $B$ negativ orientiert ist.

Sei $B=(b_k)$ nun eine Orthogonalbasis. Man definiert nun
$g_{ij}:=\langle b_i,b_j\rangle$. Jetzt lassen sich den
Basisvektoren durch
\begin{equation}
e_k := \frac{b_k}{\|b_k\|} = \frac{b_k}{\sqrt{g_{kk}}}
\end{equation}
normierte Basisvektoren zuordnen. Damit ergibt sich
\begin{equation}
\begin{split}
&*(b_{\sigma(1)}\wedge\ldots\wedge b_{\sigma(k)}) =\\
&= r \sgn(\sigma)\,s(B)\,b_{\sigma(k+1)}\wedge\ldots\wedge b_{\sigma(n)}
\end{split}
\end{equation}
mit
\begin{equation}
\begin{split}
r &= \frac{\sqrt{g_{\sigma(1)\sigma(1)}\ldots g_{\sigma(k)\sigma(k)}}}
{\sqrt{g_{\sigma(k+1)\sigma(k+1)}\ldots g_{\sigma(n)\sigma(n)}}}\\
&=\frac{g_{\sigma(1)\sigma(1)}\ldots g_{\sigma(k)\sigma(k)}}{\sqrt{\det g}}.
\end{split}
\end{equation}

\begin{thebibliography}{x}
\bibitem{} Joakim Munkhammar: »Riemann"=Liouville Fractional Derivatives
and the Taylor"=Riemann Series«. U.U.D.M. Project Report 2004:7.
Department of Mathematics, Uppsala University.
\end{thebibliography}

\vfill\noindent
\texttt{Dieses Heft steht unter der\\
Creative-Commons-Lizenz CC0.}

\end{document}


