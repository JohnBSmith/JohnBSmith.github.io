\documentclass[a4paper,11pt,fleqn,twoside]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{ngerman}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{color}
\definecolor{c1}{RGB}{00,40,80}
\usepackage[colorlinks=true,linkcolor=c1]{hyperref}
\usepackage{geometry}
\geometry{a4paper,left=35mm,right=20mm,top=28mm,bottom=46mm}
\setlength{\columnsep}{4mm}
\numberwithin{equation}{section}

\newcommand{\sgn}{\operatorname{sgn}}
\newcommand{\Z}{\mathbb Z}
\newcommand{\R}{\mathbb R}
\newcommand{\C}{\mathbb C}
\newcommand{\ui}{\mathrm i}
\newcommand{\ee}{\mathrm e}
\newcommand{\strong}[1]{{\sf\bfseries #1}}
\newcommand{\entspricht}{\;\;\hat =\;}

\theoremstyle{definition}
\newtheorem{Aufgabe}{\sffamily Aufgabe}[section]

\begin{document}
\thispagestyle{empty}

\noindent
{\huge\sf\bfseries Aufgaben}

\tableofcontents


\section{Analysis}
\subsection{Integralrechnung}
\begin{Aufgabe}
Berechne $\displaystyle\int x^2\sin x\,\mathrm dx$.
\end{Aufgabe}
\noindent\strong{Lösung.}
Die partielle Integration lautet
\begin{equation}
\int f(x)g'(x)\,\mathrm dx = fg-\int f'(x)g(x)\,\mathrm dx.
\end{equation}
Für $f(x)=x^2$ und $g(x)=\sin x$ bekommt man
\begin{equation}
\int x^2\sin x\,\mathrm dx = x^2(-\cos x) - \int 2x(-\cos x)\,\mathrm dx.
\end{equation}
und weiter
\begin{equation}
\int x\cos x\,\mathrm dx = x\sin x - \int \sin x\,\mathrm dx = x\sin x + \cos x.
\end{equation}
Zusammen ergibt das
\begin{equation}
\int x^2\sin x\,\mathrm dx = -x^2\cos x +2x\sin x+2\cos x.
\end{equation}
Probe durch Ableiten: ok. $\Box$

\begin{Aufgabe}
Berechne $\displaystyle\int\ee^x\sin x\,\mathrm dx$.
\end{Aufgabe}

\noindent\strong{Lösung.}
Mit partieller Integration ergibt sich
\begin{align}
\int \ee^x\sin x\,\mathrm dx &= \ee^x\sin x - \int \ee^x\cos x\,\mathrm dx,\\
\int \ee^x\cos x\,\mathrm dx &= \ee^x\cos x + \int \ee^x\sin x\,\mathrm dx.
\end{align}
Zusammen ist das ein Gleichungssystem. Die Aussage der unteren
Gleichung wird in die obere eingesetzt. Somit ergibt sich
\begin{equation}
\int \ee^x\sin x\,\mathrm dx = \ee^x\sin x - \ee^x\cos x - \int \ee^x\sin x\,\mathrm dx.
\end{equation}
Umformen ergibt
\begin{equation}
2\int \ee^x\sin x = \ee^x\sin x-\ee^x\cos x
\end{equation}
und somit
\begin{equation}
\int \ee^x\sin x\,\mathrm dx = \frac{1}{2}\ee^x(\sin x-\cos x)
\end{equation}
Probe durch Ableiten: ok. $\Box$

Auf diese Art lässt sich auch $\displaystyle\int \ee^{ax}\sin x\,\mathrm dx$
berechnen.

\strong{Alternative Lösung.}
Ansatz: Substitution $x:=\ui u$. Das bringt
\begin{equation}
\ee^x\sin x = \ee^{\ui u}\sin(\ui u).
\end{equation}
Nun gilt aber
\begin{equation}
\sin(\ui u)=\ui\sinh u = \frac{\ui}{2}(\ee^u-\ee^{-u}).
\end{equation}
Somit ergibt sich
\begin{equation}
\ee^x\sin x = \frac{\ui}{2}\ee^{\ui u}(\ee^u-\ee^{-u}).
\end{equation}
Nun ist $\frac{\mathrm dx}{\mathrm du}=\ui$, also
$\mathrm dx=\ui\mathrm du$. Damit ergibt sich
\begin{equation}
\int \ee^x\sin x\,\mathrm dx
= \frac{\ui^2}{2}\int \ee^{\ui u}(\ee^u-\ee^{-u})\,\mathrm du
\end{equation}
Kurze Kosmetik: Setze noch schnell $\ui^2=-1$. Mit dem Minus wird
die Differenz im Integral umgedreht. Dann das Produkt mit dem
Faktor $\ee^{\ui u}$ ausmultiplizieren. Es ergibt sich
\begin{equation}
\int \ee^x\sin x\,\mathrm dx
= \frac{1}{2}\int (\ee^{\ui u}\ee^{-u}-\ee^{\ui u}\ee^u)\,\mathrm du
\end{equation}
Nun ist aber $\ee^a e^b=\ee^{a+b}$. Somit ergibt sich
für den Term im Integral
\begin{equation}
\ee^{\ui u-u}-\ee^{\ui u+u} = \ee^{(\ui-1)u}-\ee^{(\ui+1)u}.
\end{equation}
Jetzt können wir straight forward durchintegrieren, ohne
die partielle Integration bemühen zu müssen. Es ergibt sich
\begin{equation}
\int \ee^x\sin x
= \frac{1}{2}\bigg[
\frac{1}{\ui-1}\ee^{(\ui-1)u}-\frac{1}{\ui+1}\ee^{(\ui+1)u}
\bigg]
\end{equation}
Nun gilt $\frac{1}{\ui-1}=-\frac{1}{2}-\frac{1}{2}\ui$ und
$\frac{1}{\ui+1} = \frac{1}{2}-\frac{1}{2}\ui$. Damit ergibt sich
\begin{align}
\int \ee^x\sin x\,\mathrm dx
&= \frac{1}{4}\Big[(-1-\ui)\ee^{u(\ui-1)}-(1-\ui)\ee^{u(\ui+1)}\Big]\\
&= \frac{\ee^{u\ui}}{4}\Big[(-1-\ui)\ee^{-u}-(1-\ui)\ee^u\Big]
= \frac{\ee^{u\ui}}{4}\Big[(\ui-1)\ee^u-(\ui+1)\ee^{-u}\Big]\\
&= \frac{\ee^{u\ui}}{4}\Big[\ui(\ee^u-\ee^{-u})-(\ee^u+\ee^{-u})\Big]
= \frac{\ee^{u\ui}}{2}\Big[\ui\sinh u-\cosh u\Big]\\
&= \frac{\ee^{u\ui}}{2}\Big[\sin(\ui u)-\cos(\ui u)\Big].
\end{align}
Jetzt kann man Resubstituieren und bekommt
\begin{equation}
\int \ee^x\sin x\,\mathrm dx = \frac{\ee^x}{2}(\sin x-\cos x).
\end{equation}
Alternativ kann auch
\begin{equation}
\sin x = -\ui\sinh(ix) = \frac{1}{\ui}\sinh(\ui x)
=\frac{\ee^{\ui x}-\ee^{-\ui x}}{2\ui}
\end{equation}
benutzt werden. Dabei ergibt sich eine äquivalente
Rechnung. Man braucht in diesem Fall aber keine Substitution.

Der Kern dieser Rechnungen sind die
\emph{eulersche Formel}\footnote{Bei der eulerschen Formel handelt
es sich um eine Identität. Aus historischen Gründen wird nur der
Spezialfall $x=\pi$ als \emph{eulersche Identät} bezeichnet.}
\begin{equation}
\ee^{\ui x}=\cos x+\ui\sin x
\end{equation}
und die Zerlegung
\begin{equation}
\ee^{x}=\cosh x+\sinh x.
\end{equation}
Daneben braucht man die Gleichung
\begin{equation}
\ee^{a+b}=\ee^a \ee^b.
\end{equation}

\strong{Zweite alternative Lösung.}
Mir ist jetzt noch eine wesentlich radikalere Technik eingefallen.
Verwende die Substitution $\ee^x=u$. Nun ist
$\frac{\mathrm du}{\mathrm dx}=\ee^x$ und daher
$\mathrm du=\ee^x \mathrm dx$.

Man rechnet nun
\begin{align}
&\int \ee^x\sin x\,\mathrm dx
 = \int \sin x\,\mathrm du = \int\frac{\ee^{\ui x}-\ee^{-\ui x}}{2\ui}\mathrm du
 = \frac{1}{2\ui}\int (u^\ui-u^{-\ui})\mathrm du\\
&= \frac{1}{2\ui}\bigg(\frac{u^{\ui+1}}{\ui+1}-\frac{u^{-\ui+1}}{-\ui+1}\bigg)
 = \frac{u}{2\ui}\bigg(\frac{u^\ui}{\ui+1}+\frac{u^{-\ui}}{\ui-1}\bigg)\\
&= \frac{u}{2\ui}\bigg[\bigg(\frac{1}{2}-\frac{1}{2}\ui\bigg)u^\ui
   +\bigg(-\frac{1}{2}-\frac{1}{2}\ui\bigg)u^{-\ui}\bigg]
 = \frac{u}{2}\bigg[\frac{u^\ui-u^{-\ui}}{2\ui}-\frac{u^\ui+u^{-\ui}}{2}\bigg]\\
&= \frac{\ee^x}{2}\bigg[\frac{\ee^{\ui x}-\ee^{-\ui x}}{2\ui}-\frac{\ee^{\ui x}+e^{-\ui x}}{2}\bigg]
 = \frac{\ee^x}{2}(\sin x-\cos x).\;\Box
\end{align}

\strong{Dritte alternative Lösung.}
\emph{Es war gestern aber schon sehr spät geworden, sodass ich es
gestern nicht mehr aufschreiben wollte.}
Mir war die Idee gekommen, dass $\ee^x$ bei der Laplace-Transformation
vielleicht wegfällt. Das klappt auf eine gewisse Art tatsächlich.

Also pass auf. Bei Integration im Originalbereich erhält man eine
Division durch die abhängige Variable im Bildbereich. Du siehst also,
Integrieren ist im Bildbereich ganz einfach. Bezeichnen wir mit
$L(f)$ die Laplace-Trafo. Die macht aus einer Funktion eine neue
Funktion. Man schreibt daher $F(p)=L\{f(t)\}(p)$. Hier ist
$f(t)$ die Originalfunktion und $F(p)$ die Bildfunktion.

Was ich nun gesagt habe, lässt sich so ausdrücken:
\begin{equation}
L\bigg\{\int_0^t f(x)\,\mathrm dx\bigg\}(p) = \frac{1}{p}L\{f(t)\}(p).
\end{equation}

Somit ergibt sich
\begin{equation}
L\bigg\{\int_0^t \ee^x\sin x\;\mathrm dx\bigg\}(p)
=\frac{1}{p}L\{\ee^t\sin t\}(p).
\end{equation}

Jetzt brauchen wir die Definitionsformel für die
Laplace-Trafo:
\begin{equation}
L\{f(t)\}(p):=\int_0^{\infty} \ee^{-pt}f(t)\,\mathrm dt.
\end{equation}
Damit ergibt sich
\begin{equation}
L\{\ee^t\sin t\}(p)
= \int_0^{\infty} \ee^{-pt}\ee^t\sin t\,\mathrm dt
= \int_0^{\infty} \ee^{-(p-1)t}\sin t\,\mathrm dt
= L\{\sin t\}(p-1).
\end{equation}
Die Laplace-Trafo der Sinus-Funktion kann als bekannt
vorausgesetzt werden. Dem Bronstein entnimmt man
\begin{equation}
L\{\sin(at)\}(p) = \frac{a}{p^2+a^2}.
\end{equation}
Damit ergibt sich
\begin{equation}
L\{\sin t\}(p-1) = \frac{1}{(p-1)^2+1}.
\end{equation}
Also insgesamt
\begin{equation}
L\bigg\{\int_0^t \ee^x\sin x\;\mathrm dx\bigg\}(p)
= \frac{1}{p}\bigg[\frac{1}{(p-1)^2+1}\bigg].
\end{equation}
Jetzt wendest du auf beiden Seiten die Umkehr-Trafo an. Es ist
$L^{-1}L=\mathrm{id}$. Somit ergibt sich%
\begin{equation}
\int_0^t \ee^x\sin x\;\mathrm dx
= L^{-1}\bigg\{\frac{1}{p}\bigg[\frac{1}{(p-1)^2+1}\bigg]\bigg\}(t).
\end{equation}
Der Bruch wird nun einer Partialbruchzerlegung unterworfen.
In Maxima bringt die Eingabe
\begin{verbatim}
    Term: partfrac(1/p*1/((p-1)^2+1),p);
    expand(Term);
\end{verbatim}
das Ergebnis
\begin{equation}
\frac{1}{p^2-2p+2}-\frac{p/2}{p^2-2p+2}+\frac{1}{2p}.
\end{equation}
Leider verwendet Maxima dabei keine komplexen Zahlen. Dann würden
auch die Terme mit quadratischen Divisoren in Partialbrüche
mit linearen Divisoren zerlegt werden.

Aber wir können auch hiermit weiterarbeiten, da der Bronstein
die Rücktrafo für diese Terme enthält. Dabei ergibt sich
\begin{gather*}
\ee^t\sin t - \frac{1}{2}(\cos t+\sin t)\ee^t + \frac{1}{2}
\end{gather*}
Kürzen führt uns zu
\begin{equation}
\frac{\ee^t}{2}(\sin t-\cos t)+\frac{1}{2}.
\end{equation}
Also ist
\begin{equation}
\int_0^t \ee^x\sin x\;\mathrm dx
= \frac{\ee^t}{2}(\sin t-\cos t)+\frac{1}{2}.\;\Box
\end{equation}
%
\strong{Vierte alternative Lösung.}

Mir ist jetzt noch etwas eingefallen.
Sieh mal, die Funktionen
\begin{equation}
s[A,d](x):=A\sin(x+d)
\end{equation}
bilden einen Funktionenraum
der gegen Differentiation und Integration abgeschlossen ist. D.\,h.
dass die Ableitung und eine Stammfunktion wieder
von der Form $A\sin(x+d)$ sein wird. Die Suche eines Integrals
kann damit auf die Suche von $A,d$ beschränkt werden. Zwei Zahlen
sind viel einfacher zu finden als eine ganze Funktion.

Nun rechnet man folgendes:
\begin{align}
&\frac{\mathrm d}{\mathrm dx}(\ee^x\sin x)
= \ee^x\sin x+\ee^x\cos x = \ee^x\,(\sin x+\cos x)\\
&= \ee^x \sqrt{2}\sin(x+\pi/4)
= \ee^x A\sin(x+d).
\end{align}
Das legt die Vermutung nahe, dass auch die Funktionen
\begin{equation}
\ee^x A\sin(x+d)
\end{equation}
einen gegen Integration und Ableitung abgeschlossenen
Funktionenraum bilden.

Wir machen daher den Ansatz
\begin{equation}
\int \ee^x\sin x\;\mathrm dx = \ee^x A\sin(x+d).
\end{equation}
Leitet man nun auf beiden Seiten ab, so ergibt sich
\begin{equation}
\ee^x\sin x = \ee^x A\sin(x+d)+\ee^x A\cos(x+d).
\end{equation}
Da $\ee^x>0$ für alle $x$ ist, können wir $\ee^x$ sorgenlos
rausdividieren. Somit erhält man
\begin{equation}
\frac{1}{A}\sin x = \sin(x+d)+\cos(x+d).
\end{equation}
Jetzt benutzt man die Additionstheoreme
\begin{align}
\sin(x+d) &= \sin x\cos d + \cos x\sin d,\\
\cos(x+d) &= \cos x\cos d - \sin x\sin d.
\end{align}
Damit ergibt sich
\begin{equation}
\frac{1}{A}\sin x = (\cos d-\sin d)\sin x+(\sin d+\cos d)\cos x.
\end{equation}
Da auf der linken Seite kein Kosinus-Term ist, würden wir den
Kosinusterm auf der rechten Seite gerne zum verschwinden bringen.

Dann muss aber $\sin d+\cos d=0$ sein.
Man kann nun die Identität
\begin{equation}
\sin d+\cos d=\sqrt{2}\sin(d+\pi/4)
\end{equation}
benutzen, die schon weiter oben vorkam. Damit ergibt sich
\begin{equation}
\sin(d+\pi/4)=0.
\end{equation}
Da Sinus periodisch ist, gibt es unendlich viele Lösungen. Davon
nehmen wir die einfachste Lösung, also $d=-\pi/4$.

Somit erhalten wir
\begin{equation}
\sin x = A\sin (x-\pi/4)+A\cos(x-\pi/4).
\end{equation}
Um $A$ zu bestimmen, können wir uns jetzt ein $x$ aussuchen.
Man beobachtet, dass $x=0$ nichts bringt. Stattdessen nimmt
man $x=\pi/4$. Damit ergibt sich
\begin{equation}
\frac{1}{\sqrt{2}} = \sin(\pi/4) = A\sin(0)+A\cos(0) = A.
\end{equation}
Damit erhalten wir
\begin{equation}
\int \ee^x\sin x\;\mathrm dx = \frac{\ee^x}{\sqrt{2}}\sin(x-\pi/4).
\end{equation}
Mit dem Additionstheorem ergibt sich
\begin{align}
\sin(x-\pi/4) &= \sin x\cos(-\pi/4)+\cos x\sin(-\pi/4)\\
&= \sin x\cos(\pi/4)-\cos x\sin(\pi/4)\\
&= \frac{\sin x}{\sqrt{2}}-\frac{\cos x}{\sqrt{2}}
= \frac{1}{\sqrt{2}}(\sin x-\cos x).
\end{align}
Einsetzen bringt
\begin{equation}
\int \ee^x\sin x\;\mathrm dx = \frac{\ee^x}{2}(\sin x-\cos x).\;\Box
\end{equation}


\subsection{Konvergenz}
\begin{Aufgabe}
Berechne
\[g = \lim_{x\to 0}\frac{\sum_{k=1}^n a_k x^k}{\sin(bx)}.
\qquad(\forall k\colon a_k\ne 0)\]
\end{Aufgabe}
\noindent
\strong{Lösung.}
Wegen $x\ne 0$ kann der Bruch mit $\frac{bx}{bx}$ erweitert
werden. Damit ergibt sich
\[\frac{\sum_{k=1}^n a_k x^k}{\sin(bx)}
= \underbrace{\bigg(\frac{bx}{\sin(bx)}\bigg)}_{\to 1}
\underbrace{\bigg(\frac{a_1}{b}+\sum_{k=2}^n\frac{a_k}{b}x^{k-1}\bigg)}_{\to a_1/b}.
\]
Nach den Grenzwertsätzen ist der gesamte Ausdruck konvergent, wenn
die beiden Faktoren konvergent sind und $g$ ist das Produkt
der Grenzwerte der Faktoren. Somit ist $g=a_1/b$. $\Box$

Verwende alternativ die Regel von L'Hôpital.

\begin{Aufgabe}
Berechne
\[g = \lim_{x\to\frac{\pi}{2a}} \frac{1-\sin(ax)}{(\pi-2ax)^2}.
\qquad(a\ne 0)\]
\end{Aufgabe}
\noindent
\strong{Lösung.}
Verwende die Substitution $x=\frac{\pi}{2a}-\frac{u}{a}$.
Nun ist
\[
\frac{1-\sin(ax)}{(\pi-2ax)^2}
= \frac{1-\sin(\frac{\pi}{2}-u)}{4u^2}
= \frac{1-\cos u}{4u^2}\\
= \frac{\frac{u^2}{2!}+\frac{u^4}{4!}+\ldots}{4u^2}
= \frac{1}{4} \Big(\frac{1}{2!}+\frac{u^2}{4!}+\ldots\Big).
\]
Wenn $x\to\pi/4$ geht, muss $u\to 0$ gehen.

Somit ist $g=1/8$. $\Box$

Verwende alternativ die Regel von L'Hôpital zweimal hintereinander.

\begin{Aufgabe}
Bestimme
\[g=\lim_{x\downarrow 0} x^x.\]
\end{Aufgabe}
\noindent
\strong{Lösung.} Es ist $x^x=\exp(x\ln x)$. Wegen der Stetigkeit von $\exp$
gilt nun
\[\lim_{x\to 0}\exp(f(x)) = \exp(\lim_{x\to 0} f(x)).\]
Nun ist $x\ln x = (\ln x)/(1/x).$
Mit der Regel von L'Hôpital ergibt sich
\[\lim_{x\downarrow 0} \frac{\ln x}{\frac{1}{x}}
= \lim_{x\downarrow 0} \frac{\frac{1}{x}}{-\frac{1}{x^2}}
= \lim_{x\downarrow 0}\frac{x^2}{x}
= \lim_{x\downarrow 0} x = 0.\]
Somit ist $g=1$. $\Box$

\begin{Aufgabe}
Bestimme
\[g=\lim_{x\downarrow 0} x^{1/x}.\]
\end{Aufgabe}
\noindent
\strong{Lösung.} Es ist $x^{1/x}=\exp(\frac{\ln x}{x})$.
Nun gilt
\[\lim_{x\downarrow 0}\frac{\ln x}{x}
\stackrel{\text{L'H}}= \lim_{x\downarrow 0}\frac{1}{x}
= -\infty = \lim_{x\downarrow -\infty} x.\]
Somit ist
\[g = \exp(\lim_{x\downarrow -\infty} x)
= \lim_{x\downarrow -\infty} \exp(x) = 0.\;\Box\]

\section{Kombinatorik}
\subsection{Endliche Summen}
\begin{Aufgabe}
Vereinfache $\displaystyle\sum_{k=1}^n (2k+4)$.
\end{Aufgabe}
\strong{Lösung.}
\begin{equation}
\sum_{k=1}^n (2k+4) = 2\sum_{k=1}^n k + \sum_{k=1}^n 4
= 2\cdot\frac{n}{2}(n+1)+4n = n^2+n+4n = n^2+5n.
\end{equation}

\subsection{Rekursionsgleichungen}

\begin{Aufgabe}\label{qPotenzen}
Gegeben ist die Rekursionsgleichung $a_{n+1} = qa_n$
mit der Anfangsbedingung $a_0=A.$
Gesucht ist die explizite Form von $a_n$.
\end{Aufgabe}

\begin{Aufgabe}
Gegeben ist die Rekursionsgleichung
$a_{n+1} = qa_n+r$
mit der Anfangsbedingung
$a_0=A.$
Gesucht ist die explizite Form von $a_n$.
\end{Aufgabe}

\noindent
Bemerkung. Es gilt:
\[\sum_{k=0}^n q^{n-k} = \sum_{0\le k\le n} q^{n-k}
\quad\stackrel{k:=(n-k)}=\quad\sum_{0\le (n-k)\le n} q^{n-(n-k)}
= \sum_{0\le (n-k)\le n} q^k.
\]
Nun besteht aber $0\le n-k\le n$ aus den beiden Ungleichungen
\[0\le n-k\quad\text{und}\quad n-k\le n.\]
Multipliziert man beide Seiten einer Ungleichung mit $-1$, so dreht
sich das Relationszeichen um:
\[0\ge -(n-k)\quad\text{und}\quad -(n-k)\ge -n.\]
Somit ergibt sich:
\[0\ge k-n\quad\text{und}\quad k-n\ge -n.\]
Addiere jetzt $n$ auf beiden Seiten der jeweiligen Ungleichung:
\[n\ge k\quad\text{und}\quad k\ge 0.\]
Somit ergibt sich $0\le k\le n$ und daher
\[\sum_{k=0}^n q^{n-k} = \sum_{k=0}^n q^k.\]
Einfach ausgedrückt heißt das, dass die Reihenfolge egal ist:
\[\sum_{k=0}^3 q^{3-k} = q^3+q^2+q^1+q^0 = q^0+q^1+q^2+q^3 = \sum_{k=0}^3 q^k.\]
Voraussetzung ist, dass das Kommutativgesetz gilt. Bei unendlichen
Reihen darf man nur endliche Partialsummen umordnen, es sei denn
die Reihe ist absolut konvergent.

\strong{Lösung.} Sei
\[s_b := \sum_{k=a}^{b-1} q^k.\]
Nun gilt:
\[qs_b = q\sum_{k=a}^{b-1} q^k = \sum_{k=a}^{b-1} q^{k+1}
\quad\stackrel{k:=k-1}=\quad\sum_{k=a+1}^b q^k.\]
Es ergibt sich:
\[qs_b-s_b = (q^{a+1}+q^{a+2}+\ldots+q^{b})-(q^a+q^{a+1}+\ldots+q^{b-1}) = q^b-q^a.\]
D.\,h. alle Summanden $q^{a+1}$ bis $q^{b-1}$ kommen sowohl im Minuend als auch im Subtrahend vor und
entfallen somit.

Mit $qs_b-s_b=(q-1)s_b$ ergibt sich nun
\[\sum_{k=a}^{b-1} q^k = \frac{q^b-q^a}{q-1}.\;\Box\]
Bemerkung. Hinter diesem \emph{Trick} verbirgt sich ein mathematischer
Formalismus. Was eben beschrieben wurde, nennt sich
\emph{Teleskopsumme}. \emph{Teleskopieren} nennt man die Rechenregel:
\[\sum_{k=a}^{b-1} f_{k+1} - \sum_{k=a}^{b-1} f_k
= \sum_{k=a}^{b-1} (f_{k+1}-f_k) = f_b-f_a,\]
welche für eine beliebige Folge $f_k$ gilt. In diesem Fall ist
$f_k=q^k$. Man muss bestimmte Eigenschaften einer Partialsummen-Folge
ausnutzen, um sie in Teleskopform bringen zu können. Das ist aber nicht
immer möglich.

Hinter Teleskopsummen verbigt sich nun ein kleiner mathematischer
Formalimus. Zunächst definiere die \emph{Vorwärts-Differenz}:
\[\Delta f_k\equiv (\Delta f)_k := f_{k+1}-f_k.\]
Nun gilt:
\[\sum_{k=a}^{b-1} (\Delta f)_k = f_b-f_a.\]
In dieser Form ist die Teleskopsummen-Regel völlig analog zu
\[\int_a^b \frac{\mathrm df(x)}{\mathrm dx}\,\mathrm dx
= \int_a^b \mathrm df(x) = f(b)-f(a).\]
Es gibt weitere Rechenregeln. Man spricht von \emph{Differenzenrechnung}
(engl. \emph{finite calculus}). Dieser Kalkül ist unter anderem
im Buch »Concrete Mathematics« beschrieben.

\strong{Homogene Koordinaten.}
Ein alternatives Verfahren zur Lösung der Aufgabe zeigen.
Was im Gegensatz zu Aufgabe \ref{qPotenzen}
jetzt stört, ist der Summand $r$. Es gibt nun ein Verfahren, um
Additionen in Multiplikationen umzuwandeln, das allgemein für die
Addition von Vektoren funktioniert.

Zunächst führt man auf folgede Weise homogene Koordinaten ein:
\[ x\entspricht\begin{bmatrix}x\\ 1\end{bmatrix}.\]
Es ergibt sich nun
\[ qx\entspricht\begin{bmatrix}qx\\ 1\end{bmatrix}
= \begin{bmatrix}
q & 0\\
0 & 1
\end{bmatrix}
\begin{bmatrix}x\\ 1\end{bmatrix}
\quad\text{und}\quad
x+r\entspricht\begin{bmatrix}x+r\\ 1\end{bmatrix}
= \begin{bmatrix}
1 & r\\
0 & 1
\end{bmatrix}
\begin{bmatrix}x\\ 1\end{bmatrix}.\]
Beide Operationen zusammen:
\[\begin{bmatrix}qx+r\\ 1\end{bmatrix}
= \begin{bmatrix}
1 & r\\
0 & 1
\end{bmatrix}
\begin{bmatrix}
q & 0\\
0 & 1
\end{bmatrix}
\begin{bmatrix}x\\ 1\end{bmatrix}
= \begin{bmatrix}
q & r\\
0 & 1
\end{bmatrix}
\begin{bmatrix}x\\ 1\end{bmatrix}.\]
Die Aufgabe lässt sich nun in der Form
$\underline a_{n+1} = Q\underline a_n$
mit
\[ Q:=\begin{bmatrix}
q & r\\
0 & 1
\end{bmatrix},\quad
\underline a_n := \begin{bmatrix}a_n\\ 1\end{bmatrix}\]
formulieren, was aber Aufgabe~\ref{qPotenzen} entspricht. Die
Lösung ist demnach
$\underline a_n = Q^n\underline a_0.$
Jetzt muss man einen Weg finden, die Matrixpotenz $Q^n$ zu berechnen.
Dazu wird eine Diagonalzerlegung $Q = TDT^{-1}$ vorgenommen.
Bei
\[Q^n = QQQ\ldots Q = TDT^{-1} TDT^{-1} TDT^{-1} \ldots TDT^{-1}\]
können die Faktoren $T^{-1}T$ nämlich gekürzt werden. Man erhält
somit
\[Q^n = TD^n T^{-1}.\]
Zunächst bestimmt man die Eigenwerte von $Q$. Die Eigenwerte
sind die Lösungen der Gleichung
\[P(\lambda) = \det(Q-\lambda E)=0.\]
Man nennt $P(\lambda)$ das \emph{charakteristische Polynom}.

In diesem Fall ist
\[\begin{split}
P(\lambda) &= \det\left(\begin{bmatrix}
q & r\\
0 & 1
\end{bmatrix}-\lambda\begin{bmatrix}
1 & 0\\
0 & 1
\end{bmatrix}\right)
= \det\left(\begin{bmatrix}
q-\lambda & r\\
0 & 1-\lambda
\end{bmatrix}\right)\\
&= (q-\lambda)(1-\lambda)
= \lambda^2 -(q+1)\lambda+q.\end{split}
\]
Die Lösungen dieser quadratischen Gleichung sind
\[\lambda = \frac{1}{2}(q+1\pm\sqrt{(q+1)^2-4q})
= \frac{1}{2}(q+1\pm\sqrt{(q-1)^2}),\]
also $\lambda_1 = q$ und $\lambda_2=1.$

Nun ergeben sich aus dem Eigenwertproblem $Qv = \lambda v$ zwei linear
unabhängige Eigenvektoren, die den Eigenraum aufspannen. Diese beiden
Eigenvektoren sind die Spaltenvektoren der Transformationsmatrix $T$.

Aus dem Eigenwertproblem ergibt sich das Gleichungssystem
\[\left|
\begin{array}{rcl}
qx+ry &=& \lambda x\\
y &=& \lambda y
\end{array}\right|.\]
Die untere Gleichung lässt sich umformulieren:
\[y=\lambda y \iff y=0\lor \lambda=1.\]
Gehen wir nun von $y=0$ aus, so haben wir den Fall $\lambda_1=q$.
Für $x$ können wir uns etwas aussuchen und nehmen sinnvollerweise
$x=1$. Natürlich wäre $x=0$ noch schöner, aber das darf nicht sein,
weil beim Eigenwertproblem der Nullvektor verboten ist. Für
den zweiten Eigenvektor soll betrachten wir nun den Fall $\lambda_2=1$.
Hier ergibt sich die Gleichung $qx+ry=x$. Wählt man nun $y=1$, so
ergibt sich $x=r/(1-q)$. Somit ist
\[
Q = TDT^{-1}
= T\begin{bmatrix}
\lambda_1 & 0\\
0 & \lambda_2
\end{bmatrix}T^{-1}
= \begin{bmatrix}
1 & \frac{r}{1-q}\\
0 & 1
\end{bmatrix}\begin{bmatrix}
q & 0\\
0 & 1
\end{bmatrix}\begin{bmatrix}
1 & \frac{r}{1-q}\\
0 & 1
\end{bmatrix}^{-1}.
\]
Zur Matrix-Inversion einer $2{\times}2$-Matrix verwendet man nun noch
die Formel
\[
\begin{bmatrix}
a_{11} & a_{12}\\
a_{21} & a_{22}
\end{bmatrix}^{-1}
= \frac{1}{a_{11}a_{22}-a_{12}a_{21}}
\begin{bmatrix}
a_{22} & -a_{12}\\
-a_{21} & a_{11}
\end{bmatrix}.
\]
Es ergibt sich nun
\[Q^n = TD^nT^{-1}
= \begin{bmatrix}
1 & \frac{r}{1-q}\\
0 & 1
\end{bmatrix}\begin{bmatrix}
q^n & 0\\
0 & 1
\end{bmatrix}\begin{bmatrix}
1 & \frac{r}{q-1}\\
0 & 1
\end{bmatrix}
= \begin{bmatrix}
q^n & \frac{rq^n-r}{q-1}\\
0 & 1
\end{bmatrix}.
\]
Es ergibt sich
\[\underline a_n = Q^n\underline a_0
= \begin{bmatrix}
q^n & \frac{rq^n-r}{q-1}\\
0 & 1
\end{bmatrix}\begin{bmatrix} A\\ 1\end{bmatrix}
= \begin{bmatrix}
Aq^n + \frac{rq^n-r}{q-1}\\
1\end{bmatrix}.\]
Die Lösung ist somit
\[a_n = Aq^n + \frac{rq^n-r}{q-1}.\]
Jetzt muss man noch die pathologischen Fälle untersuchen und entsprechende
Fallunterscheidungen dazu vornehmen. In diesem Fall ist nur $q=1$
problematisch. $\Box$

Das wesentliche Vorgehen besteht hier also aus zwei Schritten:

1. Formulierung des Problems bezüglich homogenen Koordinaten.

2. Berechnung von Matrixpotenzen via Eigenzerlegung.

\strong{Erzeugende Funktionen.} Jetzt kommt noch ein Verfahren.
Für eine Folge $a_n$ definiert man die \emph{erzeugende Funktion}
\[G\{a_n\}(x) := \sum_{k=0}^\infty a_k x^k.\]
Man definiert außerdem den Translationsoperator
\[T^h\{a_n\} := a_{n+h}.\]
Der Operator $G$ ist linear:
\begin{align*}
G\{a_n+b_n\} &= G\{a_n\}+G\{b_n\},\\
G\{ra_n\} &= rG\{a_n\}.
\end{align*}
Es gilt außerdem
\[G\{T^h\{a_n\}\}(x) = G\{a_{n+h}\}(x)
= \sum_{k=0}^\infty a_{k+h} x^k.\]
Somit gilt
\[x^h G\{a_{n+h}\}(x) = \sum_{k=0}^\infty a_{k+h} x^{k+h}
= G\{a_n\}(x) - \sum_{k=0}^{h-1} a_k x^k.\]
Speziell gilt
\[xG\{a_{n+1}\}(x) = G\{a_n\}(x) - a_0.\]
Durch Polynomdivision findet man zunächst die grundlegende erzeugende Funktion
\[ G\{q^n\}(x) = \frac{1}{1-qx} = \sum_{k=0}^\infty q^k x^k\]
mit Spezialfall
\[ G\{1\}(x) = \frac{1}{1-x} = \sum_{k=0}^\infty x^k.\]
Jetzt betrachten wir die Rekursionsgleichung
\[ a_{n+1} = qa_n+r. \]
Auf beiden Seiten der Gleichung wendet man den Operator $G$ an:
\[ G\{a_{n+1}\}(x) = qG\{a_n\}(x) + rG\{1\}(x).\]
Auf beiden Seiten multipliziert man nun noch mit $x$ und erhält
\[ xG\{a_{n+1}\}(x) = qxG\{a_n\}(x) + rxG\{1\}(x).\]
Mit $y=G\{a_n\}(x)$ gilt nun
\[ y-a_0 = qxy+\frac{rx}{1-x}.\]
Umformen nach $y$ bringt
\[ y = \frac{a_0}{1-qx} + \frac{rx}{(1-x)(1-qx)}.\]
Jetzt appliziert man den Umkehroperator $G^{-1}$ auf beiden Seiten
der Gleichung. Es ergibt sich
\[ a_n = a_0 G^{-1}\bigg\{\frac{1}{1-qx}\bigg\}_n
+ rG^{-1}\bigg\{\frac{x}{(1-x)(1-qx)}\bigg\}_n.\]
Beachte nun die Regel
\[ G^{-1}\{xf(x)\}_n = T^{-1} G^{-1}\{f(x)\}_n = G^{-1}\{f(x)\}_{n-1}.\]
Für den übrigen Ausdruck muss eine Partialbruchzerlegung vorgenommen
werden. Der Ansatz ist
\[ \frac{1}{(1-x)(1-qx)} = \frac{A}{1-x} + \frac{B}{1-qx}.\]
Damit ist
\[ 1 = A(1-qx) + B(1-x) = A+B-Aqx-Bx = A+B-(Aq+B)x.\]
Koeffizientenvergleich von linker und rechter Seite bringt
$A+B=1$ und $Aq+B=0$. Beachte dabei $1=0x^0+1x^1$.

Die Lösungen dieses linearen Gleichungssystems
sind $A=1/(1-q)$ und $B=q/(q-1)$. Nun ergibt sich
\[ a_n = a_0q^n + rT^{-1} \underbrace{G^{-1}\bigg\{\frac{A}{1-x} + \frac{B}{1-qx}\bigg\}}_{A+Bq^n}.\]
Hierbei ist
\[ A+Bq^n = \frac{1}{1-q}+\frac{q}{q-1}q^n = \frac{q^{n+1}-1}{q-1}.\]
Insgesamt ergibt sich
\[ a_n = a_0q^n + r\frac{q^n-1}{q-1}.\;\Box\]

\subsection{Kombinatorische Probleme}
\begin{Aufgabe}
In einem euklidischen Raum gibt es zwischen zwei Punkten genau einen
kürzesten Weg. Wie viele kürzeste Wege von Knoten $(0,0)$ zu Knoten
$(m,n)$ gibt es auf einem diskreten Gitter mit Manhatten-Metrik?
\end{Aufgabe}

\vfill\noindent
\texttt{Dieses Heft steht unter der Creative-Commons-Lizenz CC0.}

\end{document}


