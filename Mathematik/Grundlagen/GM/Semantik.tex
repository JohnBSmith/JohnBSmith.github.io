
\chapter{Semantik}

\section{Die klassische Semantik der Aussagenlogik}

\subsection{Die Erfüllungsrelation}

Bislang trat die Logik in der Form eines formalen Systems in
Erscheinung. Gegenstand eines solchen Systems sind im Allgemeinen
\emph{Wörter} einer formalen Sprache; im natürlichen Schließen sind das
die Sequenzen. Einige Wörter, die \emph{Axiome}, werden als gegeben
vorausgesetzt. Unter Anwendung von \emph{Ableitungsregeln}, auch
\emph{Inferenzregeln} genannt, das sind die Schlussregeln, leitet man
aus bereits abgeleiteten Wörtern weitere Wörter der Sprache ab.
In diesem Sinne handelt es sich um ein rein syntaktisches System.

Zum tieferen Verständnis muss man sich im Fortgang damit beschäftigen,
welche inhaltliche Bedeutung den logischen Aussagen beigemessen
wird. Der hierfür wesentliche Schritt besteht in der Definition
einer passenden \emph{Semantik}\index{Semantik}.

Gegenstand der Semantik der Logik ist der Wahrheitsgehalt von Aussagen.
Man hat gefunden, dass es sich mit der Frage nach dem Wesen der Wahrheit
schwierig verhält. Wir wollen daher an dieser Stelle gar nicht erst
versuchen, sie zu ergründen. Stattdessen tritt Wahrheit für uns zunächst
lediglich im leicht fassbaren Rahmen der zweiwertigen booleschen
Algebra auf.

In der klassischen Semantik der Aussagenlogik herrscht das
\emph{Bivalenzprinzip}\index{Bivalenzprinzip}, das besagt, dass jede
Aussage entweder \emph{wahr} oder \emph{falsch} sein muss, also einen
von zwei Wahrheitswerten\index{Wahrheitswert} haben muss. Eine Aussage
kann nicht \emph{ein wenig wahr} oder \emph{halbwegs wahr} sein, noch
kann sie eine von mehreren unterschiedlichen gleichwertigen Wahrheiten
haben. Wir schreiben kurz $0$ für falsch und $1$ für wahr. Enthält eine
Formel logische Variablen, kommt ihr ein Wahrheitswert zu, sobald alle
Variablen durch eine Interpretation\index{Interpretation} mit
einem Wahrheitswert belegt wurden.

Die Art und Weise, wie einer Formel ein Wahrheitswert zukommt,
präzisiert die Erfüllungsrelation. Sie wird als Rekursion über den
Formelaufbau definiert. Der Wahrheitswert einer Formel ist hierbei
einzig und allein durch die Wahrheitswerte ihrer Teilformeln bestimmt.

\begin{Definition}[Erfüllungsrelation]%
\label{def:sat}\newlinefirst
Eine \emph{Interpretation} $I$ ist eine Funktion, die jede atomare
logische Variable $P$ mit einem Wahrheitswert $I(P)\in\{0,1\}$ belegt.
Man definiert $I\models A$, sprich »$I$ erfüllt $A$«, rekursiv als
\begin{align*}
(I\models\bot) &:\Leftrightarrow 0,
& (I\models A\land B) &:\Leftrightarrow ((I\models A)\land (I\models B)),\\
(I\models\top) &:\Leftrightarrow 1,
& (I\models A\lor B) &:\Leftrightarrow ((I\models A)\lor (I\models B)),\\
(I\models P) &:\Leftrightarrow I(P),
& (I\models A\cond B) &:\Leftrightarrow ((I\models A)\cond (I\models B)),\\
(I\models\lnot A) &:\Leftrightarrow \lnot (I\models A),
& (I\models A\bicond B) &:\Leftrightarrow ((I\models A)\bicond (I\models B)).
\end{align*}
\end{Definition}
Die rechte Seite der jeweiligen Festsetzung ist metalogisch zu verstehen
und per Wahrheitstafel definiert, siehe Tabelle \ref{tab:Junktoren}.
Die Schreibweise $I\nvDash A$ ist gleichbedeutend mit
$\lnot (I\models A)$. Eine Interpretation wird auch als \emph{Modell}
bezeichnet. Man nennt sie \emph{Modell} einer Formel, falls sie die
Formel erfüllt. Andernfalls spricht man von einem \emph{Kontramodell}
oder \emph{Gegenmodell} der Formel.

\begin{table}
\caption{Wahrheitstafel der Junktoren}
\label{tab:Junktoren}
\centering
\begin{tabular}{cc@{\qquad}c@{\qquad}c@{\qquad}c@{\qquad}c@{\qquad}c}
\toprule
$A$ & $B$ & $\lnot A$ & $A\land B$ & $A\lor B$ & $A\cond B$ & $A\bicond B$\\
\midrule[\heavyrulewidth]
$0$ & $0$ & $1$ & $0$ & $0$ & $1$ & $1$\\
$1$ & $0$ & $0$ & $0$ & $1$ & $0$ & $0$\\
$0$ & $1$ & $1$ & $0$ & $1$ & $1$ & $0$\\
$1$ & $1$ & $0$ & $1$ & $1$ & $1$ & $1$\\
\bottomrule
\end{tabular}
\end{table}

\begin{Definition}\label{def:sat-context}
Für einen Kontext $\Gamma = \{A_1,\ldots,A_n\}$ setzt man
\[(I\models\Gamma)\,:\bicond\, (I\models A_1)\land\ldots\land (I\models A_n).\]
\end{Definition}

\subsection{Gültigkeit einer Formel}

Eine wichtige Rolle spielen \emph{allgemeingültige} Formeln, die man
in der Aussagenlogik auch als \emph{Tautologien}\index{Tautologie}
bezeichnet. Sie sind immer wahr, unabhängig davon, mit welchem
Wahrheitswert ihre logischen Variablen belegt werden.

Als allgemeinere Begrifflichkeit wollen wir auf einen Kontext $\Gamma$
bezogen gültige Formeln $A$ betrachten. Die Idee hierbei ist,
dass wenn die Formeln des Kontextes als wahr angenommen werden, die
Formel $A$ ebenfalls wahr sein muss. Trifft dies auf $A$ zu,
schreibt man $\Gamma\models A$, gelesen »im Kontext $\Gamma$ ist
$A$ gültig«, oder auch »$\Gamma$ zieht $A$ nach sich«. Die Bezeichnung
\emph{logische Folgerung} oder \emph{logische Konsequenz} ist
ebenfalls verbreitet.

\begin{Definition}[Gültige Formel]\label{def:valid}\newlinefirst
Eine Formel $A$ heißt \emph{gültig} im Kontext $\Gamma$,
wenn jede Interpretation, die sämtliche Formeln von $\Gamma$ erfüllt,
auch $A$ erfüllt. In metalogischer Symbolik,
\[(\Gamma\models A)\,:\bicond\,\forall I\colon (I\models\Gamma)\cond (I\models A).\]
\end{Definition}
Eine im leeren Kontext gültige aussagenlogische Formel $A$ nennt man
wie gesagt Tautologie. Statt $\emptyset\models A$ schreibt man auch
kurz $\models A$. Wie bei Sequenzen schreibt man auch $\Gamma,A,B\models C$
statt $\Gamma\cup\{A,B\}\models C$.

\subsection{Wahrheitstafeln}

Obgleich der Variablenvorrat unendlich groß sein darf, enthält eine
Formel von den Variablen nur endlich viele. Insofern sind für eine
Formel in einem Kontext auch nur endlich viele Interpretationen relevant.
Sind insgesamt $n$ Variablen vorhanden, sind es $2^n$ Interpretationen.

Eine Interpretation $I$ mit der Auswertung $I\models A$ ist nichts
anderes als eine Zeile der Wahrheitstafel\index{Wahrheitstafel} der
Formel $A$. Eine Formel ist genau dann tautologisch, wenn in der
Ergebnisspalte in jeder Zeile eine~1 steht.

Ein Beispiel. Die Wahrheitstafel \ref{tab:Tautologie-zur-Kontraposition}
bestätigt
\[\models (a\cond b)\bicond (\lnot b\cond\lnot a).\]

\begin{table}
\caption{Wahrheitstafel der Tautologie zur Kontraposition}
\label{tab:Tautologie-zur-Kontraposition}
\centering
\begin{tabular}{cc@{\quad\;\;}c@{\quad\;\;}c@{\quad\;\;}c@{\quad\;\;}c@{\quad\;\;}c}
\toprule
$a$ & $b$ & $\lnot b$ & $\lnot a$ & $a\cond b$ & $\lnot b\cond\lnot a$
& $(a\cond b)\bicond (\lnot b\cond\lnot a)$\\
\midrule[\heavyrulewidth]
$0$ & $0$ & $1$ & $1$ & $1$ & $1$ & $1$ \\
$1$ & $0$ & $1$ & $0$ & $0$ & $0$ & $1$ \\
$0$ & $1$ & $0$ & $1$ & $1$ & $1$ & $1$ \\
$1$ & $1$ & $0$ & $0$ & $1$ & $1$ & $1$ \\
\bottomrule
\end{tabular}
\end{table}

\noindent
Die Tafel führt zusätzlich die Teilformeln auf, was bei längeren
Formeln recht mühselig erscheinen mag. Eine geschickte Methode zur
Reduzierung des Schreibaufwands erspart die Teilformeln, und setzt ihre
Wahrheitswerte dafür schlicht unter die Junktoren, denn Ziffern
benötigen nicht viel Platz.

Die Prüfung einer logischen Folgerung per Wahrheitstafel
wird ermöglicht durch die metalogische Beziehung
\[(A_1,\ldots,A_n\models A)\,\bicond\, (\models A_1\land\ldots\land A_n\cond A).\]
Nämlich findet sich die äquivalente Umformung
\begin{align*}
(A_1,\ldots,A_n\models A)
&\;\Leftrightarrow_{\text{(1)}}\;
(\forall I\colon (I\models A_1)\land\ldots\land (I\models A_n)\cond (I\models A))\\
&\;\Leftrightarrow_{\text{(2)}}\;
(\forall I\colon (I\models A_1\land\ldots\land A_n)\cond (I\models A))\\
&\;\Leftrightarrow_{\text{(3)}}\;
(\forall I\colon I\models A_1\land\ldots\land A_n\cond A)\\
&\;\Leftrightarrow_{\text{(4)}}\;
(\models A_1\land\ldots\land A_n\cond A).
\end{align*}
Hierbei gilt (1), (4) gemäß Def. \ref{def:valid}, \ref{def:sat-context}
und (2), (3) gemäß Def. \ref{def:sat}.

\subsection{Korrektheit des natürlichen Schließens}

Jede Schlussregel und jedes Axiom besitzt eine semantische Entsprechung.
Die Beweise dafür werden nun auf metalogischer Ebene mittels natürlichem
Schließen selbst erbracht, was wie eine Art Zirkelschluss erscheinen
mag.

Zu den Grundsequenzen und zur Abschwächungsregel findet sich:
\[
\begin{array}{@{}l@{\qquad}l}
\begin{prooftree}[center = false, separation = 1em]
        \infer0[1]{I\models\Gamma\cup\{A\}}
      \infer1[Def. \ref{def:sat-context}]{(I\models\Gamma)\land (I\models A)}
    \infer1{I\models A}
  \infer1[$\sim$1]{(I\models \Gamma\cup\{A\})\cond (I\models A)}
\infer1[Def. \ref{def:valid}]{\Gamma\cup\{A\}\models A}
\end{prooftree}
&
\begin{prooftree}[center = false, separation = 1em]
        \hypo{\Gamma\models A}
      \infer1[Def. \ref{def:valid}]{(I\models\Gamma)\cond (I\models A)}
        \infer0[1]{I\models\Gamma\cup\Gamma'}
      \infer1[Def. \ref{def:sat-context}]{I\models\Gamma}
    \infer2{I\models A}
  \infer1[$\sim$1]{(I\models\Gamma\cup\Gamma')\cond (I\models A)}
\infer1[Def. \ref{def:valid}]{\Gamma\cup\Gamma'\models A}
\end{prooftree}
\end{array}
\]
Die Prüfung der restlichen Entsprechungen sei dem Leser überlassen.

\begin{Satz}[Korrektheit des natürlichen Schließens]\newlinefirst
Ist die Sequenz $\Gamma\vdash A$ ableitbar, so muss auch
$\Gamma\models A$ gelten.
\end{Satz}
\begin{Beweis}
Strukturelle Induktion über die Konstruktion von Beweisbäumen.
Induktionsanfänge sind die semantischen Entsprechungen
der Grundsequenzen. Induktionsschritte sind die semantischen
Entsprechungen der Schlussregeln. Die Beweise der Entsprechungen
wurden bereits diskutiert.\,\qedsymbol
\end{Beweis}

% #todo
% Korrektheit verschafft noch mehr. In Kontraposition,
% wenn ein Kontramodell $\Gamma\models A$ widerlegt,
% ist die Sequenz $\Gamma\vdash A$ nicht ableitbar.
% Solche Negativresultate sind ohne Semantik schwieriger
% zu erbringen.

\newpage
\subsection{Logische Äquivalenz}
\begin{Definition}[Äquivalente Formeln]\newlinefirst
Die Äquivalenz zweier Formeln $A,B$ ist definiert als
\[(A\equiv B)\,:\bicond\, (\models A\bicond B).\]
\end{Definition}

\noindent
Eine Äquivalenz besteht genau dann, wenn jede der beiden Formeln
eine logische Folgerung der anderen ist. Das heißt, es besteht die
metalogische Beziehung
\[(\models A\bicond B)\,\bicond\, (A\models B)\land (B\models A).\]
Mit den semantischen Entsprechungen der Schlussregeln
findet sich nämlich:
\[
\begin{array}{@{}l@{\qquad\quad}l}
\begin{prooftree}[center = false]
    \hypo{\models A\bicond B}
  \infer1{\models A\cond B}
  \infer0{A\models A}
\infer2{A\models B}
\end{prooftree}
&
\begin{prooftree}[center = false]
    \hypo{A\models B}
  \infer1{\models A\cond B}
    \hypo{B\models A}
  \infer1{\models B\cond A}
\infer2{\models A\bicond B}
\end{prooftree}
\end{array}
\]
\begin{Satz}\label{log-Aeq-ist-Aeqrel}
Es ist $A\equiv B$ eine Äquivalenzrelation. Das heißt, es gilt
\begin{align*}
& A\equiv A, &&\text{(Reflexivität)}\\
& (A\equiv B)\cond (B\equiv A), &&\text{(Symmetrie)}\\
& (A\equiv B)\land (B\equiv C)\cond (A\equiv C). &&\text{(Transitivität)}
\end{align*}
\end{Satz}
Der Beweis sei dem Leser als kleine Übung überlassen.

Der Satz \ref{log-Aeq-ist-Aeqrel} vermittelt, dass Formeln mit
Äquivalenzen so umgeformt werden dürfen, wie Terme mit Termumformungen.
Es finden sich im Fortgang eine Reihe von grundlegenden Äquivalenzen,
die Regeln der \emph{booleschen Algebra}\index{boolesche Algebra}. Sie
wurde erstmals in der Mitte des 19. Jahrhunders vom britischen
Mathematiker George Boole in seiner Abfassung \emph{The Mathematical
Analysis of Logic} und seinem späteren Buch \emph{An Investigation of
The Laws of Thought} beschrieben. Boole beschreibt allerdings, anders
als heute üblich, eine Einbettung der logischen Operationen in die
gewöhnliche Algebra, siehe Tabelle \ref{tab:Boole}.

\begin{table}
\centering
\caption{Einbettung in die gewöhnliche Algebra}
\label{tab:Boole}
\begin{tabular}{ccccc}
\toprule
\strong{Modern} & $\lnot a$ & $a\land b$ & $a\lor b$ & $a\cond b$\\
\strong{Boole} & $1-a$ & $ab$ & $a+b(1-a)$ & $1-a+ab$\\
\bottomrule
\end{tabular}
\end{table}

Logische Äquivalenz im absoluten Sinne ist nicht unter allen Umständen
der Weisheit letzter Schluss. In der Schaltalgebra tun sich
Problemstellungen auf, wo der Wahrheitswert einer Formel $A$ in
einzelnen Zeilen der Wahrheitstafel keine Rolle spielt, man spricht von
\emph{Don't-Care"=Zellen}. Es sei $X$ eine Formel, die genau in diesen
Zeilen wahr ist, in allen anderen falsch. Man möchte $A$ nun
beispielsweise zu $B$ vereinfachen. Unter normalen Umständen sollte
diese Vereinfachung die Äquivalenz $A\equiv B$ einhalten. Bei
Vorhandensein der irrelevanten Zellen genügt jedoch die weniger strenge
Forderung
\[\lnot X\models A\bicond B.\]
Wir haben es hier mit einer relativen Äquivalenz zu tun. Auch bei ihr
handelt es sich um eine Äquivalenzrelation, wobei $X$ beliebig ist,
aber fest sein muss.

\begin{table}
\begin{center}
\caption{Die Regeln der booleschen Algebra.}
\label{tab:boolesche-Algebra}
\begin{tabular}{@{}c@{\qquad}c@{\qquad}l@{}}
\toprule
\strong{Konjunktion}&
\strong{Disjunktion}&
\strong{Bezeichnung}\\
\midrule[\heavyrulewidth]
$A\land 0\equiv 0$ &
$A\lor 1\equiv 1$ &
Extremalgesetze\\

$A\land\lnot A\equiv 0$ &
$A\lor\lnot A\equiv 1$ &
Komplementärgesetze\\

$A\land A\equiv A$ &
$A\lor A\equiv A$ &
Idempotenzgesetze\\

$A\land 1\equiv A$ &
$A\lor 0\equiv A$ &
Neutralitätsgesetze\\
\midrule
$A\land B\equiv B\land A$ &
$A\lor B\equiv B\lor A$ &
Kommutativgesetze\\

$A{\land}(B{\land}C)\equiv (A{\land}B){\land}C$ &
$A{\lor}(B{\lor}C)\equiv (A{\lor}B){\lor}C$ &
Assoziativgesetze\\

$\lnot (A\land B)\equiv\lnot A\lor\lnot B$ &
$\lnot (A\lor B)\equiv\lnot A\land\lnot B$ &
De morgansche Gesetze\\

$A\land (A\lor B)\equiv A$ &
$A\lor (A\land B)\equiv A$ &
Absorptionsgesetze\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

\subsection{Die Einsetzungsregel}

\begin{Satz}[Einsetzungsregel]\newlinefirst
Ist die Formel $A$ allgemeingültig, so führt die simultane Ersetzung
einiger atomarer Variablen durch Formeln bei ihr zu einer weiteren
allgemeingültigen Formel. Metalogisch
\[(\models A)\cond (\models A[P_1:=B_1,\ldots,P_n:=B_n]).\]
\end{Satz}
\begin{Beweis}
Die Bestimmung von $I\models A[\ldots]$ läuft in
derselben Weise ab wie die von $I\models A$, außer dass $I(P_k)$ durch
$I\models B_k$ zu ersetzen ist. Sofern $A$ allgemeingültig ist, gilt
$I\models A$ unabhängig davon, ob $I(P_k)$ wahr oder falsch ist.
Ergo muss $I\models A[\ldots]$ unabhängig davon gelten, ob $I\models B_k$
wahr oder falsch ist.\,\qedsymbol
\end{Beweis}

\noindent
Ich mag daran erinnern, dass bei der Substitution \emph{jedes}
Vorkommen der Variable durch dieselbe Formel zu ersetzen ist.

Zum Beispiel erhält man zu der simultanen Ersetzung
$a:=A$ und $b:=B$ aus
\[\models (a\cond b)\bicond (\lnot b\cond\lnot a)\;\;\text{das Schema}\;\;
\models (A\cond B)\bicond (\lnot B\cond\lnot A).\]
Mit dem Vollständigkeitssatz infolge das Theoremschema
\[\vdash (A\cond B)\bicond (\lnot B\cond\lnot A).\]
Hiermit gewinnt man kurzum die Regeln
\[\dfrac{\Gamma\vdash A\cond B}{\Gamma\vdash\lnot B\cond\lnot A},\qquad
\dfrac{\Gamma\vdash\lnot B\cond\lnot A}{\Gamma\vdash A\cond B}.\]
Die Vorgehensweise ermöglicht summa summarum die Auffindung von
zulässigen Schlussregeln durch geistloses Ausfüllen von Wahrheitstafeln,
was allerdings auf die klassische Aussagenlogik beschränkt bleibt.

\subsection{Wahrheitsfunktionen}

Mit der Bindung ihrer atomaren Variablen gehen aus den Formeln der
Aussagenlogik Wahrheitsfunktionen\index{Wahrheitsfunktion} hervor.
Die Disjunktion zweier Aussagen wird zum Beispiel vermittelt durch die Funktion%
\[f\colon\{0,1\}\times\{0,1\}\to\{0,1\},\quad f(a,b):=(a\lor b).\]
Jede Wahrheitsfunktion in $n$ Variablen ist durch ihre Wahrheitstafel
charakterisiert, die aus $2^n$ Zeilen besteht, da der Definitionsbereich
so viele unterschiedliche Tupel enthält. Ein Tupel von Wahrheitswerten
wird auch als Bitfolge betrachtet.

Zwei Formeln $A,B$ sind genau dann äquivalent, wenn sie durch dieselben
Interpretationen erfüllt werden, sich also in der Wahrheitstafel gleich
verhalten. Man überzeugt sich davon unschwer mit der metalogischen
Umformung%
\begin{align*}
(A\equiv B) &\iff (\models A\bicond B)
\iff (\forall I\colon I\models A\bicond B)\\
&\iff (\forall I\colon (I\models A)\bicond (I\models B)).
\end{align*}
Demnach charakterisieren äquivalente Formeln dieselbe
Wahrheitsfunktion. Man kann dies auch so betrachten, dass die
Wahrheitsfunktion die Äquivalenzklasse all ihrer Formeln repräsentiert.
Unter den Formeln gibt es nun einen besonderen Vertreter, die
\emph{disjunktive Normalform}\index{disjunktive Normalform}, kurz DNF,
die eigentlich nichts anderes als eine direkte Kodierung der
Wahrheitstafel ist. Insofern ließt sich an der Wahrheitstafel
unmittelbar die DNF der Formel ab.

Die Normalform einer Formel lässt sich unter Umständen
vereinfachen. Bei der DNF der Disjunktion ist bereits klar, welche
Formel Resultat der Vereinfachung sein müsste. Es findet sich
\begin{gather*}
(a\land\lnot b)\lor (\lnot a\land b)\lor (a\land b)
\equiv (a\land\lnot b)\lor ((\lnot a\lor a)\land b)\\
\equiv (a\land\lnot b)\lor (1\land b)
\equiv (a\land\lnot b)\lor b
\equiv (a\lor b)\land (\lnot b\lor b)\\
\equiv (a\lor b)\land 1 \equiv a\lor b.
\end{gather*}
In der Schaltalgebra ist die Vereinfachung der DNF von großer
Wichtigkeit, da sie den maßgeblichen Schritt zur Ermittelung von
Schaltungen mit einer minimalen Zahl von Gattern darstellt.
Aus dieser Anforderung heraus wurden systematische Verfahren
zur Vereinfachung entwickelt. Für wenige Variablen stellt das
sogenannte Karnaugh"=Veitch"=Diagramm ein geschicktes
Hilfsmittel dar.

Mit dem Verfahren nach Quine und McCluskey lassen sich Formeln mit
beliebig vielen Variablen mit einem Computer automatisch vereinfachen.
Der Algorithmus ist allerdings von exponentieller Laufzeit, dessen
Ausführung also von einer kombinatorischen Explosion
überschattet. Eine wesentliche Verbesserung darf man auch nicht erwarten,
da die Problemstellung der Vereinfachung als NP"=vollständig befunden
wurde. Für die Formeln mit sehr vielen Variablen liegt das Wissen über
die beste Vereinfachung somit im Schleier der Dunkelheit.

\subsection{Logisches Schließen vermittels boolescher Algebra}

Boole gelang es, vermittels seiner Algebra Schlussfolgerungen zu führen.
Es stellt sich hierbei die Frage, wie dies vonstattengeht, genauer,
in welcher Verbindung die boolesche Algebra zum natürlichen Schließen
steht. Die Herleitung ihrer Regeln stellt mehr eine kleine Übung dar,
als dass sie Schwierigkeiten bereitet. Uns interessiert daher die
Umkehrung, also ob und wie natürliches Schließen aus der booleschen
Algebra heraus gewonnen werden kann. Den Übergang schafft die folgende
Überlegung.

Insofern wir uns mit der booleschen Algebra auf der semantischen Ebene
bewegen, werden wir uns auf die semantische Folgerung statt der
syntaktischen Herleitbarkeit beziehen. Wir stellen $\models A$ hierbei
in der Form $A\equiv\top$ dar. Hierzu will ich unbedingt noch ein paar
Bemerkungen machen. Die semantische Folgerung $A\models B$ mag als
eine Art Ordnung gedeutet werden, wonach $A$ als kleiner oder gleich groß
$B$ angesehen wird. Allerdings handelt es sich lediglich um eine
Quasiordnung, nicht aber um eine Halbordnung, weil zwei Formeln nicht
gleich sein müssen, nur weil sie semantisch gegenseitig auseinander
folgen. Da $\equiv$ aber eine Äquivalenzrelation ist, kann die
Quotientenmenge bezüglich dieser gebildet werden.
Zwei äquivalente Formeln werden dahingehend als gleich
angesehen, wobei dies in gewisser Weise seltsam erscheinen mag, da
die Formeln durch diesen Schritt immerhin ihre eigentliche Bedeutung
verlieren. Die als gleichbedeutend mit $A\models B$ definierte
Ordnung $[A]\le [B]$ stellt nun wirklich eine Halbordnung dar,
wonach $[A]=[B]$, also $A\equiv B$, bereits aus $[A]\le [B]$ zusammen
mit $[B]\le [A]$ folgt. Mit $1:=[\top]$ ist $[A]\le 1$ allgemeingültig,
also $1$ das größte Element, wonach $[A]=1$ und $1\le [A]$ äquivalent sind.
Außerdem nimmt die Quotientenmenge die Gestalt einer algebraischen
Struktur an, indem%
\[\lnot [A] := [\lnot A],\quad [A]\land [B] := [A\land B]\]
usw. erklärt wird. Laut der Ersetzungsregel sind diese wohldefiniert,
womit $\equiv$ die Rolle einer Kongruenzrelation einnimmt.

Besteht über die Semantik noch Unklarheit, kann man die gerade aufgezeigte
Konstruktion auch über die Ableitbarkeitsrelation statt der semantischen
Folgerung vornehmen. Hierbei spricht man, sofern sie aufgeht, von der
\emph{Lindenbaum"=Tarski"=Algebra}\index{Lindenbaum-Tarski-Algebra} des
jeweiligen logischen Systems. Während bei der klassischen Aussagenlogik
tatsächlich eine boolesche Algebra herauskommt, führt die intuitionistische
zu einer Heyting"=Algebra.

Es spielt keine wesentliche Rolle, ob man bezüglich $\equiv$ mit den
Formeln, oder bezüglich $=$ mit den Klassen rechnet. Es bleibt trotzdem
von Bedeutung, auf welche Formeln wir uns beziehen. Zwei unterschiedliche
äquivalente Formeln entsprechen dabei direkt zwei unterschiedlichen
Darstellungen derselben Klasse. Beim üblichen Rechnen mit Termen
werden zwei unterschiedliche Darstellungen desselben Elements ja auch
auseinandergehalten.

Der Modus ponens nimmt nun bzgl. $a:=[A]$ und $b:=[B]$ die Form%
\[\dfrac{(a\cond b)=1\quad\;\; a=1}{b=1}\]
an. Gesucht ist eine Herleitung der Konklusion aus den beiden Prämissen,
bei der ausschließlich boolesche Algebra zur Anwendung kommt. Keine
schwierige Aufgabe. Mit $a=1$ gilt die Umformung%
\[1 = (a\cond b) = (\lnot a\lor b) = (\lnot 1\lor b) = (0\lor b) = b.\]
Die Konklusion $b=1$ konnte also tatsächlich \emph{ausgerechnet} werden.
Diese Vorgehensweise müssen wir noch auf die allgemeine Form des Modus
ponens und der restlichen Schlussregeln übertragen.

Die Abhängigkeit von Annahmen lässt sich folgendermaßen beschreiben.
Wir fassen die Annahmen $H_1,\ldots,H_n$ zunächst zur Hypothese
$H:=(H_1\land\ldots\land H_n)$ zusammen. Die Folgerung
$H_1,\ldots,H_n\models A$ ist daraufhin bzgl. $h:=[H]$ mit $h\le a$
gleichbedeutend. Die allgemeine Form des Modus ponens nimmt
diesbezüglich die Gestalt
\[\dfrac{h\le (a\cond b)\quad\;\; h\le a}{h\le b}\]
an. Mit der Einsicht, dass $h\le a$ zu $(h\land a)=h$ äquivalent ist,
findet sich zunächst die Umformung%
\[(h\land\lnot a) = (h\land a\land\lnot a) = (h\land 0) = 0.\]
Weil auch $h\le (a\cond b)$ zu $(h\land (a\cond b))=h$ äquivalent ist,
gelingt daraufhin die Umformung%
\begin{align*}
h &= (h\land (a\cond b)) = (h\land (\lnot a\lor b))
= ((h\land\lnot a)\lor (h\land b))\\
&= (0\lor (h\land b)) = (h\land b).
\end{align*}
Und die Gleichung $h = (h\land b)$ ist schließlich wieder zur
gesuchten Konklusion $h\le b$ äquivalent.

Die Subjunktionseinführung nimmt die Gestalt
\[\dfrac{(h\land a)\le b}{h\le (a\cond b)}\]
an. Zu ihrer Bestätigung wendet man dieses Mal die allgemeine Äquivalenz
von $x\le y$ und $(x\lor y) = y$ auf die Prämisse an, was zu
$((h\land a)\lor b) = b$ führt. Hiermit findet sich die
Umformung%
\begin{align*}
(h\land (a\cond b)) &= (h\land (\lnot a\lor b))
= (h\land (\lnot a\lor (h\land a)\lor b))\\
&= ((h\land\lnot a)\lor (h\land h\land a)\lor (h\land b))\\
&= (h\land (\lnot a\lor a)\lor (h\land b))
= (h\lor (h\land b)) = h.
\end{align*}
Und diese Gleichung ist zur Konklusion äquivalent. Ich denke, die Bestätigung
der restlichen Schlussregeln brauche ich nicht weiter ausführen, -- dies
stellt nunmehr eine Übung dar. Bemerkt werden darf aber noch, dass $h\le a$
auch zu $(\lnot h\lor a)=1$ äquivalent ist. Anders als bei $h\land a=h$
tauchen $h,a$ darin nur einmal auf. Jedenfalls lassen sich alle Prämissen
und Konklusionen auch immer als Gleichungen darstellen. Und so ergibt sich,
dass das natürliche Schließen unter den gemachten Beziehungen allein aus
dem Rechnen mit Gleichungen vermittels der Gesetze der booleschen
Algebra entspringt.

\newpage
\subsection{Vollständigkeit des natürlichen Schließens}

Der Beweis der Korrektheit eines vorgelegten Kalküls versichert,
dass jede Schlussregel und jedes Axiom die inhaltliche Wahrheit
bewahrt. Eine Aussage als wahr zu befinden bezieht sich aber immer
auf eine bestimmte, zuvor festgelete Semantik. Woher wissen wir denn
eigentlich, dass diese Semantik die Logik adäquat beschreibt? Es wäre
eine Semantik denkbar, die viel mehr Aussagen als wahr befindet, als
aus den Regeln und Axiomen folgen, was Zweifel an der Semantik sähte.
Was verschafft uns also die Sicherheit, die »richtige« Semantik in den
Händen zu halten? Oder aber die Semantik erscheint nur zu weitgehend,
weil nicht bemerkt wurde, dass der Kalkül schlicht zu schwach ist.
Tappen wir im Dunkeln?

Idealerweise sollte jede wahre Aussage auch ableitbar sein, was als
\emph{Vollständigkeit} des Kalküls bezeichnet wird. Das heißt, aus
$\Gamma\models A$ sollte $\Gamma\vdash_S A$ folgen. Zusammen mit der
Korrektheit stellt sich damit nämlich eine Charakterisierung des
Kalküls bzw. der Logik her, dergestalt dass $\Gamma\vdash_S A$ als zu
$\Gamma\models A$ äquivalent befunden wird. Zumindest weiß man dann,
dass ein bestimmter Kalkül und eine bestimmte Semantik zusammen gehören
bzw. einander entsprechen. Man mag daraufhin weiter argwöhnisch fragen,
ob das gefundene Duo aus Kalkül und Semantik die wirklichen Umstände
adäquat erfasst, wie auch immer diese Wirklichkeit genau beschaffen
sei. In der Tat existieren unterschiedliche Logiken, und welche davon
geeignet ist, wird letztlich Gegenstand von pragmatischen, über
beweistheoretische, bishin zu epistemiologischen Erwägungen, siehe bspw.
\cite{George}.

Im Folgenden wird die Vollständigkeit des natürlichen Schließens für
die klassische Aussagenlogik bezüglich der klassischen Semantik gezeigt.
Wir benötigen ein paar Hilfssätze.

Eine Formel $A$ wollen wir \emph{erfüllbar} nennen, wenn eine
Interpretation $I$ mit $I\models A$ existiert, andernfalls
\emph{unerfüllbar}. Entsprechend heiße eine Formelmenge $\Gamma$
\emph{erfüllbar}, wenn $I$ mit $I\models\Gamma$ existiert.

\begin{Satz}\label{gueltig-unerf}
Gilt $\Gamma\models A$, so ist $\Gamma\cup\{\lnot A\}$ unerfüllbar.
\end{Satz}
\begin{Beweis}
Es gelte $\Gamma\models A$. Also folgt $I\models A$ aus $I\models\Gamma$
für jede Interpretation $I$. Angenommen, es existierte eine
Interpretation $J$ mit $J\models\Gamma\cup\{\lnot A\}$, also
$J\models\Gamma$ und $J\models\lnot A$. Mit der Spezialisierung $I:=J$
folgern wir $J\models A$ aus $J\models\Gamma$. Nun bedeutet
$J\models\lnot A$ definitionsgemäß $\lnot(J\models A)$, was im
Widerspruch zu $J\models A$ steht.\,\qedsymbol
\end{Beweis}

\noindent
Die Umkehrung dieses Sachverhaltes bestätigt sich ebenfalls leicht,
wird im Weiteren aber nicht benötigt.

Das syntaktische Analogon der Erfüllbarkeit ist die Konsistenz.
Eine Formelmenge $\Gamma$ heiße \emph{inkonsistent}, wenn
$\Gamma\vdash_S\bot$, andernfalls \emph{konsistent}. Zumindest sollte
speziell $\Gamma:=\emptyset$ konsistent sein, was nichts anderes als die
Widerspruchsfreiheit des Kalküls bedeutet. Andernfalls ließe sich
vermittels ex falso quodlibet jede beliebige Aussage ableiten, was den
Kalkül sinnlos machte.

\begin{Satz}\label{inkon-ableitbar}
Ist $\Gamma\cup\{\lnot A\}$ inkonsistent, so gilt $\Gamma\vdash_{\mathrm C} A$.
\end{Satz}
\begin{Beweis}
Es gelte $\Gamma\cup\{\lnot A\}\vdash_{\mathrm C}\bot$. Somit folgt
$\Gamma\vdash_{\mathrm C}\lnot\lnot A$ via Implikationseinführung beim
natürlichen Schließen bzw. Deduktionstheorem beim Hilbertkalkül. Mit der
Beseitigung der Doppelnegation ergibt sich daraufhin
$\Gamma\vdash_{\mathrm C} A$.\,\qedsymbol
\end{Beweis}

\noindent
Man beachte, dass der Beweis die klassische Logik als Gegenstand
voraussetzt. Zur intuitionistischen Logik ist dieser Beweis nicht
durchführbar.

Der nächste Satz stellt eher ein allgemeines Resultat der Mengenlehre
dar. Der Leser mag den Beweis gerne zunächst überspringen, und
nach Bewältigung des Kapitels über Mengenlehre hierher zurückkommen.

\begin{Satz}\label{endliche-Teilmenge-von-lim-sup}
Die Mengenfolge $(\Gamma_i)_{i\in\N}$ sei monoton steigend.
Sei $\Gamma':=\bigcup_{i\in\N}\Gamma_i$. Ist $\Delta\subseteq\Gamma'$
endlich, dann existiert $j\in\N$ mit $\Delta\subseteq\Gamma_j$.
\end{Satz}
\begin{Beweis}
Für $\Delta=\emptyset$ ist der Beweis trivial. Wir setzen im Weiteren
also $\Delta\ne\emptyset$ voraus. Aufgrund der Endlichkeit
besitzt $\Delta$ die Form $\Delta = \{A_1,\ldots,A_n\}$. Wegen
$\Delta\subseteq\Gamma'$ gilt $A_k\in\Gamma'$ zu jedem der $k$. Folglich
existiert jeweils ein Index $i(k)$ mit $A_k\in\Gamma_{i(k)}$, denn
andernfalls läge $A_k$ nicht in der Vereinigung $\Gamma'$. Sei $j$ das
Maximum der Indizes $i(1)$ bis $i(n)$. Sei nun $A\in\Delta$ fest,
aber beliebig. Also ist $A=A_k$ für ein $k$, und somit
$A\in\Gamma_{i(k)}$. Wir haben $i(k)\le j$, daher $\Gamma_{i(k)}\subseteq\Gamma_j$
aufgrund der Monotonie, womit $A\in\Gamma_j$. Ergo haben wir ein $j$
mit $\Delta\subseteq\Gamma_j$ konstruiert.\,\qedsymbol
\end{Beweis}

\begin{Satz}\label{Formeln-abzaehlbar}
Die Menge der logischen Formeln ist abzählbar.
\end{Satz}
\begin{Beweis}
Jede Formel lässt sich auf die übliche Art als endliche Zeichenkette
darstellen. Wir ordnen daher die Zeichenketten nach ihrer Länge. Zu
jeder Länge gibt es nur endlich viele Zeichenketten, aus denen die
wohlgeformten Formeln extrahiert und lexikographisch geordnet werden.
Somit erhält man eine Abzählung aller Formeln, die darüber hinaus
bijektiv ist.\,\qedsymbol
\end{Beweis}

\begin{Definition}
Eine Formelmenge $\Gamma$ heißt \emph{maximalkonsistent}, wenn sie
konsistent ist, aber $\Gamma\cup\{A\}$ inkonsistent für jede Formel
$A\notin\Gamma$.
\end{Definition}

\noindent
Der nächste Satz versichert, dass sich eine konsistente Formelmenge
stets zu einer maximalkonsistenten erweitern lässt.

\begin{Satz}[Lemma von Lindenbaum]\label{Lemma-Lindenbaum}\newlinefirst
Zu jedem konsistenten $\Gamma$ existiert ein maximalkonsitentes
$\Gamma'$ mit $\Gamma\subseteq\Gamma'$.
\end{Satz}
\begin{Beweis}
Laut Satz \ref{Formeln-abzaehlbar} ist die Menge sämtlicher Formeln
abzählbar. Somit liegt eine Abzählung $(A_i)_{i\in\N}$ vor, die jede
Formel mindestens einmal aufzählt. Die Folge $(\Gamma_i)_{i\in\N}$
legen wir rekursiv fest als
\[\Gamma_0 := \Gamma,\qquad \Gamma_{i+1} := \begin{cases}
\Gamma_i\cup\{A_i\}, & \text{falls konsistent},\\
\Gamma_i, & \text{sonst}.
\end{cases}\]
Sei nun $\Gamma':=\bigcup_{i\in\N}\Gamma_i$. Zunächst ist jedes
$\Gamma_i$ konsistent, weil die Folge genau auf diese Weise erklärt
wurde. Angenommen, $\Gamma'$ wäre inkonsistent, dann existierte aufgrund
der Kompaktheit eine endliche Teilmenge $\Delta\subseteq\Gamma'$, die
bereits inkonsistent ist. Zu dieser existiert laut Satz
\ref{endliche-Teilmenge-von-lim-sup} ein $j$ mit $\Delta\subseteq\Gamma_j$,
was aber absurd ist, weil folglich $\Gamma_j$ erst recht inkonsistent wäre.
Ergo muss $\Gamma'$ konsistent sein.

Nun zur Maximalität von $\Gamma'$. Es gelte $A\notin\Gamma'$. Da
mindestens ein $i$ mit $A=A_i$ existiert, muss $A\notin\Gamma_{i+1}$
gelten, denn $\Gamma_{i+1}\subseteq\Gamma'$. Das geht aber nur, wenn
$\Gamma_{i+1}=\Gamma_i$, also wenn $\Gamma_i\cup\{A\}$ inkonsistent ist.
Wegen $\Gamma_i\cup\{A\}\subseteq\Gamma'\cup\{A\}$ ist dann
$\Gamma'\cup\{A\}$ erst recht inkonsistent.\,\qedsymbol
\end{Beweis}

\begin{Satz}\label{maxkon-abgeschlossen}
Eine maximalkonsistente Menge $\Gamma$ ist deduktiv abgeschlossen.
Das heißt, es gilt $\Cn(\Gamma)=\Gamma$, also
\[(\Gamma\vdash_{\mathrm C} A)\cond A\in\Gamma.\]
\end{Satz}
\begin{Beweis}
Es gelte $\Gamma\vdash_{\mathrm C} A$. Angenommen, $\Gamma\cup\{A\}$
wäre inkonsistent. Dann gölte $\Gamma\vdash_{\mathrm C}\lnot A$
via Negationseinführung, ergo $\Gamma\vdash_{\mathrm C}\bot$ via
Negationsbeseitigung. Also wäre $\Gamma$ inkonsistent, was aber der
Konsistenz von $\Gamma$ widerspricht. Ergo muss $\Gamma\cup\{A\}$
konsistent sein. Wäre $A\notin\Gamma$, wäre $\Gamma\cup\{A\}$
inkonsistent aufgrund der Maximalkonsistenz von $\Gamma$, was der
gerade gemachten Feststellung widerspricht.
Ergo gilt $A\in\Gamma$.\,\qedsymbol
\end{Beweis}

\noindent
Der nächste Satz zeigt auf, dass eine maximalkonsistente Formelmenge
die Rekursionsschritte in der Erklärung der Erfüllungsrelation
reflektiert.

\begin{Satz}\label{maxkon-refl-sat}
Eine maximalkonsistente Menge $\Gamma$ besitzt die Eigenschaften:
\[\begin{array}{@{}ll}
1. & \bot\notin\Gamma.\\
2. & (\lnot A)\in\Gamma\bicond A\notin\Gamma,\\
3. & (A\cond B)\in\Gamma\bicond A\notin\Gamma\lor B\in\Gamma,\\
4. & (A\land B)\in\Gamma\bicond A\in\Gamma\land B\in\Gamma,\\
5. & (A\lor B)\in\Gamma\bicond A\in\Gamma\lor B\in\Gamma,\\
6. & (A\bicond B)\in\Gamma\bicond
  (A\cond B)\in\Gamma\land (B\cond A)\in\Gamma.
\end{array}\]
\end{Satz}
\begin{Beweis}
Zu 1. Dies gilt, weil $\Gamma$ konsistent ist.

Zu 2. Es gelte $\lnot A\in\Gamma$, ergo $\Gamma_{\mathrm C} A$.
Angenommen, $A\in\Gamma$. Dann $\Gamma_{\mathrm C} A$, also
$\Gamma_{\mathrm C}\bot$ via Negationsbeseitigung, was aber der
Konsistenz von $\Gamma$ widerspricht. Ergo $A\notin\Gamma$.
Umgekehrt gelte $A\notin\Gamma$. Aufgrund der Maximalkonsistenz
von $\Gamma$ bedeutet dies $\Gamma\cup\{A\}\vdash_{\mathrm C}\bot$,
also $\Gamma\vdash_{\mathrm C}\lnot A$ via Negationseinführung,
ergo $\lnot A\in\Gamma$ vermittels Satz \ref{maxkon-abgeschlossen}.

Zu 3. Es gelte $A\cond B\in\Gamma$, ergo $\Gamma\vdash_{\mathrm C}A\cond B$.
Fallunterscheidung. Im Fall $A\notin\Gamma$ folgt die Disjunktion
unmittelbar. Im Fall $A\in\Gamma$ gilt $\Gamma\vdash_{\mathrm C} A$,
also $\Gamma\vdash_{\mathrm C}B$ via Implikationsbeseitigung.
Und somit $B\in\Gamma$ vermittels Satz \ref{maxkon-abgeschlossen}.
Ergo die Disjunktion. Umgekehrt gelte $A\notin\Gamma\lor B\in\Gamma$.
Fallunterscheidung. Im Fall $A\notin\Gamma$ gilt $(\lnot A)\in\Gamma$
gemäß 2. Ergo $\Gamma\vdash_{\mathrm C}\lnot A$. Zusammen mit
$A\vdash_{\mathrm C} A$ folgt $\Gamma,A\vdash_{\mathrm C}\bot$
via Negationsbeseitigung, also $\Gamma,A\vdash_{\mathrm C}B$ via
ex falso quodlibet. Im Fall $B\in\Gamma$ gilt $\Gamma\vdash_{\mathrm C}B$,
womit man via Abschwächung zu $\Gamma,A\vdash_{\mathrm C} B$ gelangt.
Es folgt $\Gamma\vdash_{\mathrm C}A\cond B$ via Implikationseinführung,
ergo $(A\cond B)\in\Gamma$ vermittels Satz \ref{maxkon-abgeschlossen}.

Zu 4. Es gelte $(A\land B)\in\Gamma$, ergo $\Gamma\vdash_{\mathrm C}A\land B$.
Via Konjunktionsbeseitigung folgt $\Gamma\vdash_{\mathrm C}A$ sowie
$\Gamma\vdash_{\mathrm C}B$. Vermittels Satz \ref{maxkon-abgeschlossen}
folgt daraus $A\in\Gamma$ sowie $B\in\Gamma$. Umgekehrt gelte
$A\in\Gamma$ und $B\in\Gamma$, ergo $\Gamma\vdash_{\mathrm C}A$
und $\Gamma\vdash_{\mathrm C}B$, also $\Gamma\vdash_{\mathrm C}A\land B$
via Konjunktionseinführung. Ergo $A\land B\in\Gamma$ vermittels Satz
\ref{maxkon-abgeschlossen}. Ergo folgt die Disjunktion. Umgekehrt
gelte diese Disjunktion $A\in\Gamma\lor B\in\Gamma$. Fallunterscheidung.
Im Fall $A\in\Gamma$ gilt $\Gamma\vdash_{\mathrm C} A$, also
$\Gamma\vdash_{\mathrm C} A\lor B$ via Disjunktionseinführung.
Im Fall $B\in\Gamma$ gelangt man analog zu $\Gamma\vdash_{\mathrm C} A\lor B$.
Ergo folgt $(A\lor B)\in\Gamma$ vermittels Satz \ref{maxkon-abgeschlossen}.

Zu 5. Es gelte $(A\lor B)\in\Gamma$, ergo
$\Gamma\vdash_{\mathrm C}A\lor B$. Fallunterscheidung. Im Fall
$A\in\Gamma$ folgt die Disjunktion unmittelbar. Im Fall $A\notin\Gamma$
ist $\Gamma\cup\{A\}$ inkonsistent, ergo $\Gamma\cup\{A\}\vdash_{\mathrm C} B$
via ex falso quodlibet. Weiterhin folgt $\Gamma\cup\{B\}\vdash_{\mathrm C} B$
via Abschwächung aus $B\vdash_{\mathrm C} B$. Via Disjunktionsbeseitigung
erhält man somit $\Gamma\vdash_{\mathrm C} B$, ergo $B\in\Gamma$
vermittels Satz \ref{maxkon-abgeschlossen}.

Der Beweis von 6. verläuft analog zu dem von 4.\,\qedsymbol
\end{Beweis}

\begin{Satz}\label{maxkon-sat}
Eine maximalkonsistente Formelmenge ist stets erfüllbar.
\end{Satz}
\begin{Beweis}
Sei $\Gamma$ maximalkonsistent. Die Interpretation $I$ sei definiert
als $I(P):=1$, wenn $P\in\Gamma$, sonst $I(P):=0$. Es gelte $F\in\Gamma$.
Zu zeigen ist $I\models F$. Induktion über den Aufbau von $F$. Ist $F$
atomar, gilt die gemäß der gerade gemachten Definition. In allen anderen
Fällen wird der jeweilige Bestandteil von Satz \ref{maxkon-refl-sat}
verwendet. Beispiel $F=(A\land B)$. Die Induktionsannahmen sind
Mit $A\land B\in\Gamma$ haben wir $A\in\Gamma$ sowie $B\in\Gamma$
gemäß Sat \ref{maxkon-refl-sat}. Daraus folgt $I\models A$ sowie
$I\models B$ vermittels den Induktionsannahmen. Also
$I\models A\land B$ laut Definition der Erfüllbarkeit. Die anderen
Fälle verlaufen analog.\,\qedsymbol
\end{Beweis}

Im Abschluss des Beweisen kommen nun die Hilfssätze der Reihe nach
zur Anwendung.

\begin{Satz}\label{kon-sat}
Eine konsistente Formelmenge ist stets erfüllbar.
\end{Satz}
\begin{Beweis}
Sei $\Gamma$ konsistent. Laut Satz \ref{Lemma-Lindenbaum} existiert ein
maximalkonsistentes $\Gamma'$ mit $\Gamma\subseteq\Gamma'$. Laut Satz
\ref{maxkon-sat} ist $\Gamma'$ erfüllbar, folglich $\Gamma$ als
Teilmenge erst recht erfüllbar.\,\qedsymbol
\end{Beweis}

\begin{Satz}[Vollständigkeit des natürlichen Schließens]\newlinefirst
Aus $\Gamma\models A$ folgt $\Gamma\vdash_{\mathrm C} A$.
\end{Satz}
\begin{Beweis}
Es gelte $\Gamma\models A$. Laut Satz \ref{gueltig-unerf} ist
$\Gamma\cup\{\lnot A\}$ also unerfüllbar, laut Kontraposition von Satz
\ref{kon-sat} somit inkonsistent. Laut Satz \ref{inkon-ableitbar} folgt
daher $\Gamma\vdash_{\mathrm C} A$.\,\qedsymbol
\end{Beweis}

\noindent
Gleichwohl wurden nur die ersten Schritte unternommen. Die Argumentation
wäre im Weiteren auf die Logik erster Stufe zu übertragen; das Resultat
ist als der \emph{gödelsche Vollständigkeitssatz} bekannt. Zudem besteht
der Wunsch, auch die Vollständigkeit der jeweiligen Kalküle zu anderen
Logiken -- wie bspw. der intuitionistischen Logik -- zu versichern.

\newpage
\section{Die klassische Semantik der Logik erster Stufe}

\subsection{Strukturen}

Wie in der Aussagenlogik soll den Formeln eine Bedeutung zukommen.
Eine Formel der Prädikatenlogik ist allerdings komplizierter als eine
Formel der Aussagenlogik. Statt nur atomare Variablen mit
Wahrheitswerten zu belegen, sind nun unterschiedliche Arten von
Symbolen vorhanden, die mit einer Bedeutung versehen werden müssen.

Es gibt erstens die logischen Verknüpfungen, denen eine für die
Logik spezifische feste Funktion zukommt. Ebenso ist die Gleichheit
zweier Terme fest definiert. Zweitens können in einer Formel Symbole
für Funktionen und Relationen vorkommen, darunter fallen auch
Konstanten. Sie werden je nach gewählter Struktur anders mit
Funktionen und Relationen belegt. Drittens darf eine Formel
freie Variablen enthalten. Sie werden durch eine extra definierte
Belegungsfunktion mit Werten belegt. Bei der Interpretation einer
quantifizierten Teilformel wird die Belegungsfunktion modifiziert.

Je nach Festlegung des logisch"=mathematischen Systems und dessen
inhaltlicher Deutung haben die mathematischen Terme Werte
in einer bestimmten Menge $U$, die wir \emph{Universum},
\emph{Domäne}, \emph{Träger}, \emph{Grundbereich} oder
\emph{Diskursuniversum} nennen.  Die Elemente von $U$ nennen wir
\emph{Individuen} oder \emph{Objekte}. Ich möchte noch einmal daran
erinnern, dass der beschriebene Kalkül der Prädikatenlogik die
Menge $U$ als nichtleer fordert.

Eine \emph{Struktur} $M$ sei das Universum $U$ zusammen mit einer
Interpretationsfunktion, die jedem Funktionssymbol $f$ von $n$ Argumenten
eine Funktion $f^M\colon U^n \to U$ und jedem Relationssymbol $R$ von
$n$ Argumenten eine Relation $R^M\colon U^n\to\{0,1\}$ zuordnet.
Konstanten deuten wir als Funktionen von null Argumenten.

Man kann eine Struktur auf unterschiedliche Art kodieren, wobei
unter Umständen die Hilfsbegriffe \emph{Signatur} und
\emph{Ariätsfunktion} gebraucht werden. Die Signatur beschreibt hierbei
die Menge der Funktionssymbole und die Menge Relationssymbole. Die
Aritätsfunktion ordnet jedem Funktionssymbol und jedem Relationssymbol
seine Stelligkeit zu, das ist die Anzahl der Argumente.

\strong{Beispiel 1. Ein Kalkül für Halbordnungen.} Zusätzlich zu
den Regeln und Axiomen der Prädikatenlogik sollen als mathematische Axiome
demnach noch die Axiome für Halbordnungen gelten. Die Signatur enthalte
dazu lediglich das Relationssymbol $\le$. Eine mögliche Struktur $M$
ist die Menge $U:=\mathcal P(G)$ zu irgendeiner Grundmenge $G$, zusammen
mit der Setzung ${\le^M} := {\subseteq}$, so dass je zwei Mengen $A,B\in U$
ein Wahrheitswert $A\subseteq B$ zugeordnet wird. Man notiert so
eine Struktur üblicherweise einfach schludrig als $(U,\le^M)$,
konkret $(\mathcal P(G),\subseteq)$.

\strong{Beispiel 2. Ein Kalkül für Gruppen.} Zusätzlich
zu den Regeln und Axiomen der Prädikatenlogik sollen als mathematische Axiome
demnach noch die Axiome für Gruppen gelten. Die Signatur enthalte
dazu ein Konstantensymbol für das neutrale Element, die Verknüpfung von
Elementen als zweistelliges Funktionssymbol und die Invertierungsfunktion
als einstelliges Funktionssymbol. Eine Struktur notiert man dann als
$(G,\cdot,e,\mathrm{inv})$. Eine mögliche Struktur ist $(\R,+,0,\mathrm{inv})$
mit $\mathrm{inv}(x):=-x$, die Gruppe der reellen Zahlen bezüglich
Addition. Eine andere mögliche Struktur ist $(S(X),\circ,\id,\mathrm{inv})$
mit $\mathrm{inv}(f):=f^{-1}$, die Gruppe der bijektiven Selbstabbildungen
auf der Menge $X$ bezüglich der Verkettung, auch symmetrische Gruppe
genannt. Es ist hier $\id$ die identische Abbildung und $f^{-1}$
die Umkehrabbildung von $f$.

\strong{Beispiel 3. Ein Kalkül für die Mengenlehre.} Der unerfahrene Leser mag
diesbezüglich zunächst das Kapitel über Mengenlehre studieren und später
hierher zurückkommen. Das Diskursuniversum soll das Mengenuniversum sein.
Nun verhält es sich allerdings so, dass die Zusammenfassung aller denkbaren
Mengen eine echte Klasse bildet, die keine Menge mehr sein kann. Man
könnte die Definition des Diskursuniversums so modifizieren, dass es eine
beliebige Klasse sein darf, was aber dazu führen würde, dass dieses
nicht mehr ohne Ausnahme als Element eines Mengensystems auftreten darf.
Wir gehen dieser Komplikation durch die Betrachtung des
Grothendieckuniversums $U=V_\kappa$ für ZFC oder $U=V_{\kappa+1}$ für
die Morse"=Kelly"=Mengenlehre aus dem Weg, wobei mit den $V_\alpha$ die
kumulative Hierarchie und mit $\kappa$ eine als Ordinalzahl betrachtete
unerreichbare Kardinalzahl gemeint ist. Die Einzelheiten erläutert
Shulman \cite{Shulman}. Einziges Relationssymbol ist nun  ${\in}$ für
die Elementrelation, und Funktionssymbole gibt es gar keine. Das mag
verwirrend erscheinen, wo die Mengenlehre doch von Relationen und
Funktionen durchdrungen ist. Diese stellen bei näherer Betrachtung aber
Objekte des Universums dar.

Aber ist die leere Menge nicht ein Konstantensymbol, die Inklusion
${\subseteq}$ nicht ein weiteres Relationssymbol und Operatoren wie
$\cap$ und $\cup$ Funktionssymbole? An sich stimmt das. Das
formale System der Mengenlehre kann um diese Symbole erweitert werden,
die minimalistische Fassung des Systems kommt jedoch allein mit
${\in}$ aus. Alle weiteren Symbole werden durch ihre Definition
ersetzt, obgleich dadurch unter Umständen exorbitant lange Formeln
entstehen. Zum Beispiel wird die Formel $A\cap B\subseteq A\cup B$
expandiert zu
\[\forall x\colon x\in A\land x\in B\cond x\in A\lor x\in B.\]

\subsection{Interpretationen}

Zur Interpretation eines Terms $t$ mit freien Variablen betrachtet
man außerdem noch eine \emph{Belegung} $\beta$, die jeder Variablen $x$
einen Wert $\beta(x)\in U$ zuordnet. Geläufig ist ebenfalls die
Bezeichnung \emph{Zuweisung}.

Man nennt nun $I=(M,\beta)$ eine \emph{Interpretation} der Formel $A$.
Wir definieren $I(t)$ für einen Term $t$ rekursiv über den Termaufbau
als%
\begin{gather*}
I(x) := \beta(x),\\
I(f(t_1,\ldots,t_n)) := f^M(I(t_1),\ldots,I(t_n)),
\end{gather*}
wobei $x$ eine Variable und $f$ ein $n$-stelliges Funktionssymbol
ist. Die Belegung mit einer modifiziert belegten Variable wird
diesbezüglich definiert als%
\begin{gather*}
\beta[y{:=}u](x) := \begin{cases}
u, & \text{wenn}\;x=y,\\
\beta(x), & \text{sonst}.
\end{cases}
\end{gather*}
Für $I=(M,\beta)$ sei $I[y{:=}u] := (M,\beta[y{:=}u])$.

Um Missverständnissen aus dem Weg zu gehen, sollte ich erwähnen, dass
die Begriffe \emph{Variable} und \emph{Atom} in der Prädikatenlogik
anders verstanden werden als in der Aussagenlogik. Die atomaren
Variablen der Aussagenlogik entsprechen nullstelligen Relationssymbolen,
denen bei einer Interpretation Relationen von null Argumenten zukommt,
das sind schlicht die konstanten Wahrheitswerte. Dagegen meint Variable
in der Prädikatenlogik üblicherweise eine Individuenvariable. Eine
atomare Formel ist in der Prädikatenlogik nicht nur ein nullstelliges
Relationssymbol, sondern jede Applikation eines Relationssymbols und
jede Gleichung.

Die Erfüllungsrelation definiert man analog zur Aussagenlogik, also
\[(I\models A\land B)\,:\bicond\,(I\models A)\land (I\models B)\]
und so weiter. Zusätzlich setzt man%
\begin{gather*}
(I\models t_1 = t_2) :\Leftrightarrow I(t_1) = I(t_2),\\
(I\models R(t_1,\ldots,t_n)):\Leftrightarrow R^M(I(t_1),\ldots,I(t_n)),\\
(I\models\forall x\colon A) :\Leftrightarrow\forall u\in U\colon I[x{:=}u]\models A,\\
(I\models\exists x\colon A) :\Leftrightarrow\exists u\in U\colon I[x{:=}u]\models A.
\end{gather*}
Man definiert hiermit die semantische Folgerung analog zur Aussagenlogik als
\[(\Gamma\models A)\,:\bicond\,\forall I\colon (I\models\Gamma)\cond (I\models A).\]
Wir nennen $A$ \emph{allgemeingültig}, falls $\emptyset\models A$, was
wir wieder durch $\models A$ abkürzen wollen.

Sofern die Formel $A$ geschlossen ist, das heißt, keine freien
Variablen besitzt, spielt die Belegung der Variablen noch keine Rolle, sie
entsteht eigentlich erst bei der rekursiven Bestimmung von $I\models A$
mit dem Einstieg in eine quantifizierte Formel. Bei einer einer
geschlossenen Formel $A$ darf man insofern $M\models A$ statt
$M,\beta\models A$ schreiben. Gilt $M\models A$, nennt man $M$ ein
\emph{Modell für} $A$.

Ich will erklären, warum die Interpretation der Quantoren so durchgeführt
wurde wie beschrieben. Intuitiv erfüllt $I$ die Formel
$\forall x\colon A$ genau dann, wenn $I$ die Formel $A[x:=u]$ für jedes
$u\in U$ erfüllt. Allerdings ist $u$ kein Term der logischen Sprache,
womit $A[x:=u]$ keine Formel mehr wäre. Wir könnten nicht einmal für
jedes $u$ eine Konstante zur Sprache hinzufügen, weil $U$ überabzählbar
sein darf, während eine gewöhnliche Sprache nur abzählbar viele
Symbole in Form von Zeichenketten umfassen kann. Die gewählte Ausweg
aus der Problematik besteht darin, dass die Belegung $x:=u$ erst einmal
in der Interpretation gespeichert wird, statt sie direkt
als Substitution auf die Formel anzuwenden.

\subsection{Korrektheit des natürlichen Schließens}

Wir müssen nun wieder aufzeigen, dass der Kalkül des natürlichen
Schließens bezüglich der definierten Semantik korrekt ist. Dies
geschieht wieder per struktureller Induktion über den Aufbau des
Beweises. Für die bereits in der Aussagenlogik vorhandenen Regeln
können wir die dort gemachte Argumentation unverändert übernehmen.
Zu bestätigen verbleibt die Korrektheit der Regeln zur Einführung und
Beseitigung der Quantoren, und ggf. noch die Korrektheit der Regeln zum
Umgang mit Gleichheiten.

\begin{Satz}\label{interpretation-lemma}
Es ist $I[x:=I(t)]\models A$ äquivalent zu $I\models A[x:=t]$.
\end{Satz}
\begin{Beweis}
Man unternimmt hierzu eine strukturelle Induktion über den Formelaufbau
von $A$. Die Induktionsvoraussetzungen sind jeweils unschwer zu verarbeiten.
Im Wesentlichen verbleibt nun%
\[I[x:=I(t)](v) = I(v[x:=t])\]
für jede Individuenvariable $v$ zu zeigen. Man nimmt dazu die
Fallunterscheidung zwischen $x=v$ und $x\ne v$ vor. Im ersten Fall gilt%
\[I[x:=I(t)](v) = I(t) = I(x[x:=t]) = I(v[x:=t]),\]
und im zweiten Fall gilt
\[I[x:=I(t)](v) = I(v) = I(v[x:=t]).\,\qedsymbol\]
\end{Beweis}

\begin{Satz}
Aus $\Gamma\models\forall x\colon A$ folgt $\Gamma\models A[x:=t]$.
\end{Satz}
\begin{Beweis}
Laut der Prämisse muss zu jedem $I$ mit $I\models\Gamma$
auch $I[x:=u]\models A$ für jedes $u\in U$ gelten. Weitere Prämisse
ist ein $I$ mit $I\models\Gamma$. Die Allaussage wird mit diesem $I$
und mit $u:=I(t)$ spezialisiert. Zu zeigen verbleibt%
\[(I[x:=I(t)]\models A)\cond (I\models A[x:=t]).\]
Diese gilt gemäß Satz \ref{interpretation-lemma}.\,\qedsymbol
\end{Beweis}

\begin{Satz}
Aus $\Gamma\models A[x:=t]$ folgt $\Gamma\models\exists x\colon A$.
\end{Satz}
\begin{Beweis}
Laut der Prämisse muss zu jedem $I$ mit $I\models\Gamma$ auch
$I\models A[x:=t]$ gelten. Weitere Prämisse ist ein $I$ mit
$I\models\Gamma$. Die Allaussage wird mit diesem $I$ spezialisiert.
Zu zeigen verbleibt%
\[(I\models A[x:=t])\cond \exists u\in U\colon (I[x:=u]\models A).\]
Gewählt wird $u:=I(t)$. Nun greift wieder Satz
\ref{interpretation-lemma}.\,\qedsymbol
\end{Beweis}

\begin{Satz}
Aus $\Gamma\models A$ und $x\notin\mathrm{FV}(\Gamma)$
folgt $\Gamma\models\forall x\colon A$.
\end{Satz}
\begin{Beweis}
Laut der Prämisse muss zu jedem $I$ mit $I\models\Gamma$ auch
$I\models A$ gelten. Weitere Prämisse ist ein $I$ mit
$I\models\Gamma$. Wegen $x\notin\mathrm{FV}(\Gamma)$ ist
$I\models\Gamma$ äquivalent zu $I[x:=u]\models\Gamma$. Demnach
lässt sich die Allaussage mit $I[x:=u]$ spezialisieren, womit
man $I[x:=u]\models A$ erhält. Ergo gilt%
\[\forall u\in U\colon (I[x:=u]\models A),\;\text{also}\;
I\models\forall x\colon A.\,\qedsymbol\]
\end{Beweis}

\begin{Satz}
Aus $\Gamma\models\exists x\colon A$ und $\Gamma\cup\{A\}\models B$
mit $x\notin\mathrm{FV}(\Gamma\cup\{B\})$ folgt $\Gamma\models B$.
\end{Satz}
\begin{Beweis}
Laut der ersten Prämisse existiert zu jedem $I$ mit $I\models\Gamma$
ein $u\in U$ mit $I[x:=u]\models A$. Laut der zweiten Prämisse muss
zu jedem $I$ mit $I\models\Gamma$ und $I\models A$ auch $I\models B$
gelten. Wegen $x\notin\mathrm{FV}(\Gamma\cup\{B\})$ ist $I\models\Gamma$
zu $I[x:=u]\models\Gamma$ sowie $I\models B$ zu $I[x:=u]\models B$
äquivalent. Dritte Prämisse ist ein $I$ mit $I\models\Gamma$. Die erste
Allaussage wird mit $I$ spezialisiert, die zweite mit $I[x:=u]$. 
Mit den vorliegenden Aussagen gelingt der Schluss auf $I[x:=u]\models B$.
Ergo gilt $I\models B$, wie gewünscht.\,\qedsymbol
\end{Beweis}

\section{Semantik der Modallogik}

\subsection{Die relationale Semantik der Modallogik}

Mit der Entwicklung der Modallogiken ging die Frage einher, wie
modallogische Formeln semantisch interpretiert werden können.
Besonders wichtig sind die nach Saul Kripke benannten
\emph{Kripke"=Semantiken}, auch \emph{relationale Semantiken} genannt.
Die Interpretation der atomaren Aussagen wird hierbei durch eine Welt
parametrisiert. Eine Aussage kann also in einer bestimmten Welt wahr
sein, während sie in einer anderen falsch ist. Als Logik der Metasprache
soll dabei die klassische Prädikatenlogik dienen.

Eine \emph{Kripke"=Struktur} sei ein Tripel $M=(W,R,V)$. Hierbei
ist $W$ eine Menge von Welten, $R$ eine zweistellige Relation auf
$W$, und $V$ eine Wertung, die jeder atomaren Variable $a$
parametrisiert durch die Welt $w\in W$ einen Wahrheitswert
$V(w,a)\in\{0,1\}$ zuordnet. Man nennt $R$ die
\emph{Zugänglichkeitsrelation}, wobei $R(w,w')$ gedeutet wird als
»$w'$ ist von $w$ aus zugänglich«. Die Relation muss nicht unbedingt
symmetrisch sein, womit man unter Umständen nicht mehr von
$w'$ aus in die ursprüngliche Welt $w$ zurückgelangt.

Das Paar $I=(M,w)$, bestehend aus einer Struktur und einer Welt, betrachten
wir als Interpretation. Man legt die Erfüllung einer atomaren Variable
$a$ bezüglich einer Interpretation fest als%
\[(M,w\models a) :\bicond V(w,a).\]
Die Erfüllung der Junktoren wird analog zur klassischen Semantik
definiert, also%
\[(I\models A\land B) :\bicond (I\models A)\land (I\models B)\]
und so weiter, wobei die rechte Seite gemäß den herkömmlichen
Wahrheitstafeln ausgewertet wird. Für die beiden modalen Junktoren legt
man nun fest%
\begin{align*}
(M,w\models\lnec A) &:\bicond\forall w'\in W\colon R(w,w')\cond (M,w'\models A),\\
(M,w\models\lpos A) &:\bicond\exists w'\in W\colon R(w,w')\land (M,w'\models A). 
\end{align*}
In Worten ist die Aussage $\lnec A$ genau dann wahr in der Welt $w$, wenn
$A$ in jeder von $w$ aus zugänglichen möglichen Welt wahr ist.
Es ist $\lpos A$ genau dann wahr in der Welt $w$, wenn $A$ in mindestens einer
von $w$ aus zugänglichen möglichen Welt wahr ist.

Die semantische Folgerung wird wieder in der herkömmlichen Form%
\[(\Gamma\models A)\,:\bicond\,\forall I\colon (I\models\Gamma)\cond (I\models A)\]
definiert. Ausgeschrieben lautet sie demnach
\[(\Gamma\models A)\,:\bicond\,\forall M\colon\forall w\in W(M)\colon
(M,w\models\Gamma)\cond (M,w\models A).\]
Man spricht gelegentlich auch von der \emph{lokalen} semantischen Folgerung,
um sie von einer weiteren, der selten diskutierten \emph{globalen} semantischen
Folgerung abgrenzen zu können. Zur Unterscheidung will ich die globale
Folgerung als $\models^g$ notieren. Man definiert sie als%
\[(\Gamma\models^g A)\,:\bicond\,\forall M\colon (M\models\Gamma)\cond (M\models A),\]
wobei $M\models A$ für $\forall w\in W(M)\colon (M,w\models A)$ stehen soll.

Ist $\Gamma$ die leere Menge, koinzidieren die lokale und die globale
Folgerung. Das heißt, $\emptyset\models A$ gilt genau dann, wenn
$\emptyset\models^g A$. Man schreibt wieder $\models A$ als Kurzform
von $\emptyset\models A$ und sagt dazu, die Formel $A$ sei
\emph{allgemeingültig}.

Bei der tieferen Untersuchung, welche Beziehungen zwischen Kalkül und
Semantik bestehen, zerlegt man eine Kripke"=Struktur $M=(W,R,V)$ in
die zwei Teile $F=(W,R)$ und $V$. Man nennt $F$ den \emph{Rahmen}.

Gezeigt werden muss nun die Korrektheit des natürlichen Schließens
für die Modallogik. Dies geschieht wieder per struktureller Induktion
über den Formelaufbau. Bei den herkömmlichen Schlussregeln verläuft der
Beweis identisch wie in der klassischen Semantik der Aussagenlogik.
Zu bestätigen verbleibt insofern lediglich noch die Korrektheit der
Nezessisierungsregel und die Allgemeingültigkeit des Axiomenschemas K.

\begin{Satz}
Aus $\models A$ folgt $\models\lnec A$.
\end{Satz}
\begin{Beweis}
Gemäß der Prämisse gilt $M,w'\models A$ für jedes $w'$. Demnach gilt
erst recht $R(w,w')\cond (M,w'\models A)$. Ergo gilt
$\models\lnec A$. Quod erat demonstrandum.\,\qedsymbol
\end{Beweis}

\begin{Satz}
Das Schema $\lnec(A\cond B)\cond (\lnec A\cond\lnec B)$ ist allgemeingültig.
\end{Satz}
\begin{Beweis}
Seien $M,w$ fest, aber beliebig. Zu zeigen ist
\[M,w\models\lnec(A\cond B)\cond (\lnec A\cond\lnec B),\]
was gemäß der Definition der Erfüllung äquivalent umgeformt wird zu%
\[(M,w\models\lnec(A\cond B))\cond (M,w\models\lnec A)\cond (M,w\models\lnec B).\]
Zu zeigen ist daher $M,w'\models B$ unter Annahme von $R(w,w')$ und%
\begin{gather*}
\forall w'\colon R(w,w')\cond (M,w'\models A\cond B),\\
\forall w'\colon R(w,w')\cond (M,w'\models A).
\end{gather*}
Die beiden Allaussagen werden mit $w'$ und $R(w,w')$ spezialisiert.
Laut der ersten Aussage $M,w'\models A\cond B$ folgt
$M,w'\models B$ aus $M,w'\models A$. Laut zweiten gilt $M,w'\models A$.
Ergo gilt $M,w'\models B$. Quod erat demonstrandum.\,\qedsymbol
\end{Beweis}

\subsection{Die Standardübersetzung}

Die relationale Semantik der diskutierten Modallogiken deutet bereits
an, dass Modallogik etwas mit der Logik erster Stufe zu tun haben müsste.
Es scheint, dass in gewisser Weise $\lnec A$ der Allquantifizierung,
und $\lpos A$ der Existenzquantifizierung entspricht. Die im Folgenden
beschriebene \emph{Standardübersetzung} modallogischer Formeln in die
Logik erster Stufe präzisiert diesen Gedankengang. Mithin stellen sich
die diskutierten Modallogiken als Spezialfälle der Logik erster Stufe
heraus. Auf diese Weise erhält man eine Möglichkeit, modallogische
Theoreme mit Beweisassistenten zu formulieren, die lediglich die
herkömmliche Logik verstehen.

Die Standardübersetzung ist rekursiv definiert als
\begin{align*}
&\mathrm{ST}_x(a) := P_a(x),
&& \mathrm{ST}_x(A\cond B) := \mathrm{ST}_x(A)\cond\mathrm{ST}_x(B),\\
&\mathrm{ST}_x(\lnot A) := \lnot\mathrm{ST}_x(A),
&& \mathrm{ST}_x(A\bicond B) := \mathrm{ST}_x(A)\bicond\mathrm{ST}_x(B),\\
&\mathrm{ST}_x(A\land B) := \mathrm{ST}_x(A)\land\mathrm{ST}_x(B),
&& \mathrm{ST}_x(\lnec A) := \forall y\colon R(x,y)\cond\mathrm{ST}_y(A),\\
& \mathrm{ST}_x(A\lor B) := \mathrm{ST}_x(A)\lor\mathrm{ST}_x(B),
&& \mathrm{ST}_x(\lpos A) := \forall y\colon R(x,y)\land\mathrm{ST}_y(A).
\end{align*}
Die Formeln $\bot,\top$ bleiben fix, also
$\mathrm{ST}_x(\bot) := \bot$ und $\mathrm{ST}_x(\top) := \top$.

Hierbei ist $R$ ein zweistelliges Prädikatsymbol, und $P_a$ zu
jedem $a$ ein einstelliges Prädikatsymbol. Eine Interpretation
$(M,w)$ mit Kripke"=Struktur $M=(W,R,V)$ und Welt $w\in W$
lässt sich als Interpretation $(M,\beta[x:=w])$ für die übersetzten
Formeln deuten, dergestalt dass das Symbol $P_a$ mit $w\mapsto V(w,a)$
interpretiert wird, und das Symbol $R$ mit der Zugänglichkeitsrelation
$R$. Demzufolge nimmt $W$ die Rolle des Diskursuniversums ein.
Die Belegung $\beta$ spielt keine Rolle, da $x$ die einzige freie
Variable ist. Man gelangt nun zum folgenden Resultat.
\begin{Satz}
Es gilt $M,w\models A$ genau dann, wenn $M,\beta[x:=w]\models\mathrm{ST}_x(A)$.
\end{Satz}
\begin{Beweis}
Per struktureller Induktion über den Formelaufbau von $A$.
Es sei $\beta\tfrac{w}{x}$ Kurzschreibweise für $\beta[x:=w]$. Den
Induktionsanfang liefert die Umformung
\[(M,w\models a) \iff V(w,a) \iff (M,\beta\tfrac{w}{x}\models P_a(x)).\]
Zur Formel $A\land B$ liegt die Äquivalenz von $M,w\models C$
und $M,\beta\tfrac{w}{x}\models\mathrm{ST}_x(C)$ jeweils für $C=A$
und $C=B$ als Induktionsvoraussetzung vor. Es findet sich hiermit
die äquivalente Umformung
\begin{align*}
(M,w\models A\land B) &\iff (M,w\models A)\land (M,w\models B)\\
&\iff (M,\beta\tfrac{w}{x}\models\mathrm{ST}_x(A))\land
(M,\beta\tfrac{w}{x}\models\mathrm{ST}_x(B))\\
&\iff M,\beta\tfrac{w}{x}\models\mathrm{ST}_x(A)\land\mathrm{ST}_x(B)\\
&\iff M,\beta\tfrac{w}{x}\models\mathrm{ST}_x(A\land B).
\end{align*}
Bei den restlichen herkömmlichen Junktoren verläuft die Argumentation
analog. Zur Formel $\lnec A$ liegt die Äquivalenz von $M,w'\models A$
und $M,\beta\tfrac{w'}{y}\models\mathrm{ST}_y(A)$ als
Induktionsvoraussetzung vor. Es findet sich hiermit die äquivalente
Umformung
\begin{align*}
(M,w\models\lnec A) &\iff \forall w'\colon R(w,w')\cond (M,w'\models A)\\
&\iff\forall w'\colon R(w,w')\cond (M,\beta\tfrac{w'}{y}\models\mathrm{ST}_y(A))\\
&\iff\forall w'\colon (M,\beta\tfrac{w}{x}\tfrac{w'}{y}\models R(x,y))
\cond (M,\beta\tfrac{w}{x}\tfrac{w'}{y}\models\mathrm{ST}_y(A))\\
&\iff (M,\beta\tfrac{w}{x}\models\forall y\colon R(x,y)\cond\mathrm{ST}_y(A))\\
&\iff (M,\beta\tfrac{w}{x}\models\mathrm{ST}_x(\lnec A)).
\end{align*}
Bei $\lpos A$ verläuft die Argumentation analog.\,\qedsymbol
\end{Beweis}

\noindent
Mithin gilt in unmittelbarer Konsequenz der
\begin{Satz}
Es gilt $\Gamma\models A$ genau dann, wenn
$\mathrm{ST}_x(\Gamma)\models\mathrm{ST}_x(A)$.
\end{Satz}
Vermittels dieser Äquivalenz erhält man sogleich den
\begin{Satz}
Aus $\vdash\mathrm{ST}_x(A)$ folgt $\models A$.
\end{Satz}
Kraft der Standardübersetzung in die Logik erster Stufe ergibt sich
insofern wie gewünscht ein alternativer korrekter Kalkül für die
diskutierten Modallogiken. Eine tiefergehende Untersuchung zur
Standardübersetzung findet man in \cite{Blackburn}.

\section{Semantik der intuitionistischen Logik}

\subsection{Die relationale Semantik der intuitionistischen Logik}

Wir erinnern uns, dass sich die intuitionistische Logik ergibt, indem
beim natürlichen Schließen auf die Beseitigung der Doppelnegation
verzichtet wird. Dies verdeutlicht, wie ein Beweis eines intuitionistischen
Theorems beschaffen sein muss. Schwierig bleibt jedoch der Nachweis, dass
eine Formel kein solches Theorem sein kann. Hier leistet die Semantik
Aufschluss.

Mit der Zeit fand man recht viele verschiedene Semantiken der
intuitionistischen Logik.\cite{Artemov} Im Rahmen der algebraischen
Semantik wird sie durch Heyting"=Algebren statt boolescher Algebren
beschrieben. Weiterhin gibt es die topologische Semantik, die
Realisierer nach Kleene, die Beth"=Semantik, die Kripke"=Semantik
und die kategorielle Semantik. Streng genommen sollten wir all diese
Semantiken aufführen, und daraufhin mit einem Ringschluss aufzeigen,
dass sie in Bezug auf die Allgemeingültigkeit einer Formel alle äquivalent
sind. Für eine solche Unternehmung bleibt hier aber leider nicht
genügend Zeit und Raum. Ich werde mich insofern auf Grundzüge beschränken.

Zur intuitionistischen Logik gehört eine Kripke"=Semantik,
deren Erfüllung auf eine eigensinnige Art beschaffen ist.\cite{Kripke-IL}
Eine \emph{intuitionistische Kripke"=Struktur} ist ein Tripel $(W,\le,V)$,
wobei $W$ wieder eine Menge von Welten, $\le$ eine Quasiordnung auf ihr und
$V$ eine monotone Wertung ist, das heißt,
\[\forall w\in W\colon\forall w'\in W\colon w\le w'\land V(w,P)\Rightarrow V(w',P),\]
wobei $V$ jeder Welt $w$ und jeder atomaren Variable $P$ einen
Wahrheitswert $V(w,P)\in\{0,1\}$ zuordnet.

Das Paar $I=(M,w)$, bestehen aus einer Struktur und einer Welt, betrachten
wir wieder als Interpretation. Die Erfüllung einer atomaren Variable $P$
ist wieder erklärt als
\[(M,w\models P)\;:\Leftrightarrow\; V(w,P).\]
Die Erfüllung der Junktoren ist daraufhin rekursiv erklärt als
\begin{align*}
(M,w\models A\land B) &\;:\Leftrightarrow\; (M,w\models A)\land (M,w\models B),\\
(M,w\models A\lor B) &\;:\Leftrightarrow\; (M,w\models A)\lor (M,w\models B),\\
(M,w\models A\cond B) &\;:\Leftrightarrow\;
  \forall w'{\in}W\colon w\le w'\land (M,w'\models A)\cond (M,w'\models B).
\end{align*}
Der jeweilige Junktor auf der rechten Seite ist hierbei abermals
als die boolesche Funktion bezüglich ihrer gewöhnlichen Wahrheitstafel
eklärt. Weiterhin setzt man $(M,w\models\bot) :\Leftrightarrow 0$, wie
gewöhnlich. Die Negation $\lnot A$ erhält die Semantik von
$A\cond\bot$. Die Bijunktion $A\bicond B$ erhält die Semantik
von $(A\cond B)\land (B\cond A)$.

Die Gültigkeit von $A$ unter $\Gamma$ ist wieder erklärt als
\[(\Gamma\models A)\;:\Leftrightarrow\; \forall M\colon\forall w\in W(M)\colon
(M,w\models \Gamma)\Rightarrow (M,w\models A).\]
Der Beweis Korrektheit verläuft fast analog wie bei der klassischen
Semantik. Wir müssen lediglich bei der Subjunktion bzw. Negation aufpassen,
die eine veränderte Erfüllung besitzt. Zu bestätigen wäre also die Gültigkeit der
Einführung und Beseitigung der Subjunktion. Zunächst zur Beseitigung
\[(\Gamma\models A\cond B)\land (\Gamma\models A)\Rightarrow (\Gamma\models B).\]
Aus $M,w\models\Gamma$ ist $M,w\models B$ abzuleiten. Vermittels
$\Gamma\models A$ erhält man zunächst $M,w\models A$. Nun entfaltet sich
$\Gamma\models A\cond B$ zu
\[(M,w\models\Gamma)\Rightarrow\forall w'\colon w\le w'\land
(M,w'\models A)\Rightarrow (M,w'\models B).\]
Wir spezialisieren $w':=w$, denn $w\le w$ gilt aufgrund der Reflexivität
von $\le$.

Nun zur Einführung
\[(\Gamma, A\models B)\Rightarrow (\Gamma\models A\cond B).\]
Aus $M,w\models\Gamma$ ist $M,w\models A\cond B$ abzleiten, also
$M,w'\models B$ für jedes $w'$ mit $w\le w'$ und $M,w'\models A$.
Via Spezialisierung von $\Gamma,A\models B$ mit $w'$ erhält man
$M,w'\models B$ aus $M,w'\models\Gamma$ und $M,w'\models A$. Zu zeigen
verbleibt also $M,w'\models\Gamma$. Um den Beweis abzuschließen,
müssen wir $M,w'\models\Gamma$ aus $w\le w'$ und $M,w\models\Gamma$
ableiten. Hierfür ist allerdings ein Hilfssatz erforderlich, laut dem
sich die Monotonie von der Wertung auf die Erfüllung vererbt.

\begin{Satz}
Aus $w\le w'$ und $M,w\models A$ folgt $M,w'\models A$ zu jeder Formel
$A$, jeder intuitionistischen Struktur $M=(W,\le,V)$ und allen Welten $w,w'\in W$.
\end{Satz}
\begin{Beweis}[Beweisskizze]
Strukturelle Induktion über den Aufbau von $A$.

Im Induktionsanfang in der atomaren Variable $P$ gilt dies aufgrund
der Monotonie von $V$. Der Induktionsanfang in $\bot$ ist trivial.

Der jeweilige Induktionsschritt zu $A\land B$, $A\lor B$, $A\cond B$
verläuft unkompliziert unter Anwendung der beiden Induktionsvoraussetzungen,
dass $M,w'\models A$ aus $M,w\models A$ sowie $M,w'\models B$ aus
$M,w\models B$ für $w\le w'$ folgt. Bei $A\cond B$ ist
allerdings zusätzlich die Transitivität von $\le$ erforderlich.\,\qedsymbol
\end{Beweis}

\noindent
Für die Gültigkeit macht es keinen Unterschied, wenn die Erfüllung
lediglich für Halb- statt Quasiordnungen gefordert wird. Dies erklärt,
warum die entsprechend modifizierte Definition der Semantik ebenfalls
verbreitet ist. Wir wollen dies noch kurz verifizieren. Den Hauptteil
übernimmt der folgende Hilfssatz.

\begin{Satz}\label{Modell-quasi-halb}
Zu jedem intuitionistischen Kripke"=Modell $M=(W,R,V)$ existiert ein
intuitionistisches Kripke"=Modell $M' = (W',R',V')$ mit Halbordnung
$R'$, das genau dieselben Formeln erfüllt.
\end{Satz}
\begin{Beweis}
Mit $x\sim y:\Leftrightarrow R(x,y)\land R(y,x)$ ist eine
Äquivalenzrelation festgelegt, wie man unschwer nachrechnet.
Die Quotientenmenge $W' := W/{\sim}$ wird das \emph{Skelett} von $W$
genannt, ihre Elemente heißen \emph{Cluster}. Auf $W'$ definieren wir
\[R'([x],[y]) :\Leftrightarrow R(x,y),\quad\; V'([x],P):\Leftrightarrow V(x,P).\]
Man rechnet unschwer nach, dass $R',V'$ wohldefiniert sind, $R'$ eine
Halbordnung ist, und $V'$ monoton ist. Für jede Formel $A$ gilt nun
\[\forall x\in W\colon (M,x\models A)\bicond (M',[x]\models A),\]
was per struktureller Induktion über den Aufbau von $A$ bestätigt wird.

Zum Induktionsanfang in der atomaren Variable $P$ findet sich die äquivalente Umformung
\[(x\models P)\iff V(x,P)\iff V([x],P)\iff ([x]\models P).\]
Der Induktionsanfang in $\bot$ ist trivial.

Im Induktionsschritt zu $A\land B$ liegen die Induktionsvoraussetzungen
$\forall x\colon (x\models A)\Leftrightarrow ([x]\models A)$ und
$\forall x\colon (x\models B)\Leftrightarrow ([x]\models B)$ vor.
Mit diesen rechnet man
\[(x\models A\land B)\iff (x\models A)\land (x\models B)
\iff ([x]\models A)\land ([x]\models B)
\iff ([x]\models A\land B).\]
Der Schritt zu $A\lor B$ verläuft analog. Im Schritt zu $A\cond B$ rechnet man
\begin{align*}
(x\models A\cond B)&\iff \big(\forall y\in W\colon R(x,y)\land (y\models A)\cond (y\models B)\big)\\
&\iff \big(\forall y\in W\colon R'([x],[y])\land ([y]\models A)\cond ([y]\models B)\big)\\
&\iff \big(\forall y'\in W'\colon R'([x],y')\land (y'\models A)\cond (y'\models B)\big)\\
&\iff ([x]\models A\cond B),
\end{align*}
insofern dank der Surjektivität der kanonischen Projektion $y\mapsto [y]$
zu jedem $y'$ ein $y$ mit $y'=[y]$ existiert.\,\qedsymbol
\end{Beweis}

\noindent
Mit der geleisteten Vorarbeit ergibt sich der

\begin{Satz}\label{Gueltigkeit-halb-quasi}
Aus $\Gamma\models' A$ folgt $\Gamma\models A$, wobei Ersteres die
Gültigkeit in Bezug auf lediglich alle Halb- statt Quasiordnungen meine.
\end{Satz}
\begin{Beweis}
Aus $M,w\models\Gamma$ ist $M,w\models A$ zu folgern. Zu $M$ erhält man
$M'=(W',R',V')$ mit Halbordnung $R'$ vermittels Satz
\ref{Modell-quasi-halb}. Laut der Äquivalenz von Satz \ref{Modell-quasi-halb}
folgt $M',[w]\models\Gamma$ aus $M,w\models\Gamma$. Daraufhin folgt
$M',[w]\models A$ laut Voraussetzung $\Gamma\models' A$. Unter nochmaliger
Anwendung der Äquivalenz folgt schließlich $M,w\models A$.\,\qedsymbol
\end{Beweis}

\noindent
Die Umkehrung von Satz \ref{Gueltigkeit-halb-quasi} stellt natürlich
eine Trivialität dar, weil jede Halb- auch immer eine Quasiordnung ist.

Die Übersetzung nach Gödel-McKinsey-Tarski bettet eine Formel
der intuitionistischen Logik in die Modallogik S4 ein. Sie ist
rekursiv erklärt als
\begin{align*}
T(P) &:= \lnec P, & T(A\land B) &:= T(A)\land T(B), & T(A\cond B) &:= \lnec T(A\cond B),\\
T(\bot) &:= \bot, & T(A\lor B) &:= T(A)\lor T(B), & T(\lnot A) &:= \lnec\lnot T(A).
\end{align*}
Es soll $A$ genau dann ein Theorem der intuitionistischen Logik sein,
wenn $T(A)$ ein Theorem der Modallogik S4 ist. Im Folgen wollen wir
dies als Übung semantisch bestätigen.

Bei Kripke"=Semantiken ist für die Erfüllung auch die Schreibweise
$w\Vdash A$ statt $w\models A$ geläufig. Zur Unterscheidung notieren wir
-- von dieser Freiheit pragmatisch Gebrauch machend -- im Folgenden
$w\Vdash A$ für die Erfüllung in der intuitionistischen Logik und
$w\models T(A)$ für die Erfüllung in der S4, jeweils im Bezug auf die
jeweilige Kripke"=Semantik.

Der Beweis umfasst die Nutzung zweier Hilfssätze.

\begin{Satz}\label{Erf-Modell-S4-aus-Int}
Es liege ein inutitionistisches Kripke"=Modell $(W,\le,V)$ vor.
Dieses bietet sich unverändert als S4"=Kripke"=Modell an. Zu jeder Formel $A$
und jeder Welt $w$ ist dann $w\Vdash A$ zu $w\models T(A)$ äquivalent.
\end{Satz}
\begin{Beweis}[Beweisskizze]
Strukturelle Induktion über den Aufbau von $A$.

Zum Induktionsanfang in der atomaren Variable $P$. Es gelte $w\Vdash P$,
also $V(w,P)$. Zu zeigen ist $w\models\lnec P$, also $V(w',P)$
für jedes $w'$ mit $w\le w'$, was aber mit $V(w,P)$ aus der Monotonie
von $V$ folgt. Umgekehrt gelte $w\models\lnec P$. Zu zeigen ist
$V(w,P)$, was sofort aus $w\models\lnec P$ mit $w\le w$ folgt,
denn $\le$ ist reflexiv.

Der Induktionsanfang in $\bot$ ist trivial.

Die Induktionsschritte zu $A\land B$, $A\lor B$ und $A\cond B$ verlaufen
geradlinig unter Anwendung der beiden Induktionsannahmen, dass $w\Vdash A$
zu $w\models T(A)$ sowie $w\Vdash B$ zu $w\models T(B)$ äquivalent ist.
Der Umstand $T(A\cond B)=\lnec(A\cond B)$ schafft dabei
erstaunlicherweise keine sonderliche Komplikation, die den Gebrauch einer
der anderen Voraussetzungen erfordern würde.\,\qedsymbol
\end{Beweis}

\begin{Satz}\label{Erf-Modell-Int-aus-S4}
Es liege ein S4"=Kripke"=Modell $(W,\le,V)$ vor. Zu diesem ist
$(W,\le,V_i)$ mit $V_i(w,P):\Leftrightarrow (w\models\lnec P)$ ein
intuitionistisches Kripke"=Modell, so dass zu jeder Formel $A$ und jeder
Welt $w$ die Erfüllung $w\Vdash A$ zu $w\models T(A)$ äquivalent ist.
\end{Satz}
\begin{Beweis}[Beweisskizze]
Zunächst ist die Monotonie von $V_i$ zu bestätigen. Es seien $x,y,P$
beliebig, und es gelte $x\le y$ und $V_i(x,P)$. Zu zeigen ist
$V_i(y,P)$, also $V(z,P)$ für jedes $z$ mit $y\le z$. Zunächst
folgt $x\le z$, da $\le$ transitiv ist. Entfaltung von $V_i(x,P)$
bringt $x\models\lnec P$, also $V(w,P)$ für jedes $w$ mit $x\le w$.
Ergo erhält man $V(z,P)$ mit $w:=z$.

Nun wieder strukturelle Induktion über den Aufbau von $A$.

Der Beweis des Induktionsanfangs in der atomaren Variable $P$ verläuft
unkompliziert.

Der Beweis des Induktionsanfangs in $\bot$ ist trivial.

Die Induktionsschritte zu $A\land B$, $A\lor B$ und $A\cond B$ verlaufen
abermals geradlinig, jeweils unter Anwendung der beiden
Induktionsannahmen.\,\qedsymbol
\end{Beweis}

\begin{Satz}
Es gilt genau dann $\models_\text{Int} A$, wenn $\models_\text{S4} T(A)$.
Das heißt, eine Formel $A$ ist genau dann bezüglich intuitionistischer
Kripke"=Semantik gültig, wenn $T(A)$ bezüglich der Kripke"=Semantik von
S4 gültig ist.
\end{Satz}
\begin{Beweis}
Es gelte $\models_\text{Int} A$. Es sei $M=(W,\le,V)$ ein beliebiges
S4"=Kripke"=Modell. Es sei $w$ eine beliebige Welt. Nach Satz
\ref{Erf-Modell-Int-aus-S4}
hat man ein intuitionistisches Modell $M_i:=(W,\le,V_i)$, so dass
$M_i,w\Vdash A$ laut Prämisse, und somit $M,w\models T(A)$. Und dies
bedeutet $\models_\text{S4} T(A)$, da $M,w$ beliebig sind.

Umgekehrt gelte $\models_\text{S4} T(A)$. Es sei $M_i=(W,\le,V)$ ein
beliebiges intuitionistisches Kripke"=Modell. Nach Satz
\ref{Erf-Modell-S4-aus-Int} hat man
ein S4"=Kripke"=Modell $M:=M_i$, so dass $M,w\models T(A)$ laut
Prämisse, und somit $M,w\Vdash A$. Und dies bedeutet
$\models_\text{Int} A$, da $M_i,w$ beliebig sind.\,\qedsymbol
\end{Beweis}

\noindent
Infolge muss $A$ genau dann ein intuitionistisches Theorem sein,
wenn $T(A)$ ein Theorem in S4 ist. Die Brücke dazu ergibt sich
unter Hinzuziehung von Korrektheit und Vollständigkeit des jeweiligen
Kalküls. Die Übersetzung $T$ leistet also wirklich, was postuliert
wurde.

\subsection{Zur Auffindung von Kontramodellen}

Mit der Widerlegung der Allgemeingültigkeit einer Formel verhält es sich
in der intuitionistischen Logik komplizierter als in der klassischen,
da ein Gefüge von Welten gefunden werden muss, auf denen die Wertung
unterschiedlich ausfällt. Zurück zur klassischen Logik bzw.
Semantik kommt man bei Begrenzung dieses Gefüges auf eine einzige Welt.
Damit ist auch schon klar, wie eine Formel widerlegt wird, die bereits
in der klassischen Logik nicht allgemeingültig ist. Im Folgenden
interessieren uns also ausschließlich klassische Tautologien, die
vermutlich keine intuitionistischen sind.

Wir notieren kurz $w\refutes A$ für $\lnot (w\models A$).
Definitionsgemäß gilt $w\models A\land B$ genau dann, wenn
$w\models A$ und $w\models B$. Als Kontraposition ergibt sich also,
dass $w\refutes A\land B$ genau dann, wenn $w\refutes A$ oder
$w\refutes B$. Demnach erhalten wir die beiden Regeln
\[\dfrac{w\refutes A}{w\refutes A\land B},\quad \dfrac{w\refutes B}{w\refutes A\land B}.\]
Analog findet sich zur Widerlegung der Disjunktion die Regel
\[\dfrac{w\refutes A\quad\; w\refutes B}{w\refutes A\lor B}.\]
Bei der Subjunktion verhält es sich wieder ein wenig komplizierter.
Definitionsgemäß gilt $w\models A\cond B$ genau dann, wenn
$\forall w'\ge w\colon (w'\models A)\Rightarrow (w'\models B)$. In
Kontraposition gilt $w\refutes A\cond B$ genau dann,
wenn $\exists w'\ge w\colon (w'\models A)\land (w'\refutes B)$. Dies
führt uns also zur Regel
\[\frac{w\le w'\quad\; w'\models A\quad\; w'\refutes B}{w\refutes A\cond B}.\]
Die Negation $\lnot A$ ist hier als Spezialfall $B:=\bot$ enthalten.
Beachtet man, dass $w\refutes\bot$ allgemeingültig ist, vereinfacht sich
die Regel zu
\[\frac{w\le w'\quad\; w'\models A}{w\refutes\lnot A}.\]
Die Regeln erleichtern die Auffindung zielführender Welten und
Wertung.

\strong{Beispiel 1.} Die Allgemeingültigkeit von $A\lor\lnot A$, dem
Satz vom ausgeschlossenen Dritten, ist zu widerlegen. Wir machen dies
bei der Instanz zu $A:=p$. Unter Rückwärtsschließen vermittels der Regeln
ergibt sich die Ableitung:
\[\begin{prooftree}
    \hypo{V(w,p)=0}
  \infer1{w\refutes p}
    \hypo{w\le w'}
      \hypo{V(w',p)=1}
    \infer1{w'\models p}
  \infer2{w\refutes\lnot p}
\infer2{w\refutes p\lor\lnot p}
\end{prooftree}\]
Zu den drei Hypothesen findet sich das Kontramodell
\[W:=\{w,w'\},\;R := \{(w,w),(w,w'),(w',w')\},\;V(w,p):=0,\;V(w',p):=1\]
mit $w\le w'$ als Notation für $R(w,w')$. Dieses widerspricht nicht der
Monotonieforderung an $V$, die besagt, dass zu je zwei Welten $w,w'$
mit $w\le w'$ und $V(w,p)$ auch $V(w',p)$ gilt, bzw. $\lnot V(w,p)$
oder $V(w',p)$ gelten muss.

\strong{Beispiel 2.} Die Allgemeingültigkeit von $\lnot\lnot A\cond A$,
der Beseitigung der Doppelnegation, ist zu widerlegen. Hierfür genügt die
Instanz zu $A:=p$. Kunstloses Rückwärtsschließen führt uns zur Ableitung:
\[\begin{prooftree}
  \hypo{w_1\le w_2}
      \hypo{w_2\le x}
        \hypo{x\le w_3}
          \hypo{V(w_3,p)=1}
        \infer1{w_3\models p}
      \infer2{x\refutes\lnot p}
    \infer2{\forall x\ge w_2\colon x\refutes\lnot p}
  \infer1{w_2\models\lnot\lnot p}
    \hypo{V(w_2,p)=0}
  \infer1{w_2\refutes p}
\infer3{w_1\refutes\lnot\lnot p\cond p}
\end{prooftree}\]
Zu den fünf Hypothesen findet sich nochmals das Kontramodell
\[W:=\{w,w'\},\;R := \{(w,w),(w,w'),(w',w')\},\;V(w,p):=0,\;V(w',p):=1\]
bei Vornahme der Setzungen $w_1:=w$, $w_2:=w$, $w_3:=w'$.

Die Auffindung eines Kontramodells braucht man bei diesen kleinen
Formeln nicht unbedingt händisch rechnen. Insofern die Modelle selbst
klein sind, schafft es der Computer Brute"=Force durch kombinatorische
Aufzählung der Modelle, wenngleich die kombinatorische Komplexität
rasch zunimmt. Da $W$ endlich ist, werden die ominösen
Allquantifizierungen bei der Berechnung der Erfüllung selbst endlich.
In der obigen Ableitung ist bspw. $x\in W$, womit nach Festlegung von $W$
nur noch $x=w$ und $x=w'$ übrig bleiben. Dass jede widerlegbare Formel
ein endliches Kontramodell besitzt, engl. \emph{finite model property},
müsste man streng genommen beweisen. Gerne würde man auch eine Schranke
zur Komplexität in Bezug auf die, noch zu definierende, Komplexität der
Formel haben.

\strong{Beispiel 3.}
Die Allgemeingültigkeit von $(A\cond B\lor C)\cond (A\cond B)\lor (A\cond C)$
ist zu widerlegen. Hierfür genügt die Instanz $A:=p$, $B:=q$, $C:=r$.
Es findet sich die Ableitung:
\[\begin{prooftree}
  \hypo{w_1\le w_2}
    \hypo{\forall x\ge w_2\colon (x\models p)\Rightarrow (x\models q\lor r)}
  \infer1{w_2\models p\cond q\lor r}
  \hypo{w_2\refutes (p\cond q)\lor (p\cond r)}
\infer3{w_1\refutes (p\cond q\lor r)\cond (p\cond q)\lor (p\cond r)}
\end{prooftree}\]
mit dem Teilbaum
\[\begin{prooftree}
    \hypo{w_2\le w_3}
    \hypo{w_3\models p}
    \hypo{w_3\refutes q}
  \infer3{w_2\refutes (p\cond q)}
    \hypo{w_2\le w_4}
    \hypo{w_4\models p}
    \hypo{w_4\refutes r}
  \infer3{w_2\refutes (p\cond r)}
\infer2{w_2\refutes (p\cond q)\lor (p\cond r)}
\end{prooftree}\]
Man beachte hier nun die Allaussage. Näher betrachtet schließt diese
den Umstand $w_3=w_4$ aus, denn wegen $w_3\models p$ zieht sie
$w_3\models q\lor r$ nach sich, aber wir hätten sowohl $w_3\refutes p$
als auch $w_3\refutes r$. Die Lösung besteht darin, die Wertung
bezüglich $q,r$ wechselhaft erfüllt zu haben. Dies erfordert insgesamt
drei unterschiedliche Welten. Zur Verkürzung notieren wir $w\in V(P)$
statt $V(w,P)=1$. Es findet sich das Kontramodell
\begin{gather*}
W:=\{w,w',w''\},\; R := \{(w,w'),(w,w'')\}\cup\text{Reflexivität}(W),\\
V(p):=\{w',w''\},\; V(q):=\{w'\},\; V(r):=\{w''\}
\end{gather*}
bei Vornahme der Setzungen $w_1:=w$, $w_2:=w$, $w_3:=w''$, $w_4:=w'$.

Weitere widerlegbare klassische Tautologien sind
\begin{align*}
& ((A\cond B)\cond A)\cond A, && \text{(Peirce's law)}\\
& (\lnot A\cond A)\cond A, && \text{(Consequentia mirabilis)}\\
& A\lor (A\cond B), && \text{(LEM bei $B:=\bot$)}\\
& (A\cond B)\cond B\lor\lnot A, && \text{(LEM bei $B:=A$)}\\
& \lnot A\lor\lnot\lnot A, && \text{(weak LEM)}\\
& (A\cond B)\lor (B\cond A), && \text{(DPG: Dirk Gently's Principle)}\\
& (\lnot B\cond\lnot A)\cond (A\cond B), && \text{(klassische Kontraposition)}\\
& (\lnot B\cond A)\cond (\lnot A\cond B),\\
& \lnot (A\land B)\cond\lnot A\lor\lnot B.
\end{align*}
