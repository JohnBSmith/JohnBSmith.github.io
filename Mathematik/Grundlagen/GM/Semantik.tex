
\chapter{Semantik}

\section{Die klassische Semantik der Aussagenlogik}

\subsection{Die Erfüllungsrelation}

Bislang trat die Logik in der Form eines formalen Systems in
Erscheinung. Gegenstand eines solchen Systems sind im Allgemeinen
\emph{Wörter} einer formalen Sprache; im natürlichen Schließen sind das
die Sequenzen. Einige Wörter, die \emph{Axiome}, werden als gegeben
vorausgesetzt. Unter Anwendung von \emph{Ableitungsregeln}, auch
\emph{Inferenzregeln} genannt, das sind die Schlussregeln, leitet man
aus bereits abgeleiteten Wörtern weitere Wörter der Sprache ab.
In diesem Sinne handelt es sich um ein rein syntaktisches System.

Zum tieferen Verständnis muss man sich im Fortgang damit beschäftigen,
welche inhaltliche Bedeutung den logischen Aussagen beigemessen
wird. Der hierfür wesentliche Schritt besteht in der Definition
einer passenden \emph{Semantik}\index{Semantik}.

Gegenstand der Semantik der Logik ist der Wahrheitsgehalt von Aussagen.
Man hat gefunden, dass es sich mit der Frage nach dem Wesen der Wahrheit
schwierig verhält. Wir wollen daher an dieser Stelle gar nicht erst
versuchen, sie zu ergründen. Stattdessen tritt Wahrheit für uns zunächst
lediglich im leicht fassbaren Rahmen der zweiwertigen booleschen
Algebra auf.

In der klassischen Semantik der Aussagenlogik herrscht das
\emph{Bivalenzprinzip}\index{Bivalenzprinzip}, das besagt, dass jede
Aussage entweder \emph{wahr} oder \emph{falsch} sein muss, also einen
von zwei Wahrheitswerten\index{Wahrheitswert} haben muss. Eine Aussage
kann nicht \emph{ein wenig wahr} oder \emph{halbwegs wahr} sein, noch
kann sie eine von mehreren unterschiedlichen gleichwertigen Wahrheiten
haben. Wir schreiben kurz $0$ für falsch und $1$ für wahr. Enthält eine
Formel logische Variablen, kommt ihr ein Wahrheitswert zu, sobald alle
Variablen durch eine Interpretation\index{Interpretation} mit
einem Wahrheitswert belegt wurden.

Die Art und Weise, wie einer Formel ein Wahrheitswert zukommt,
präzisiert die Erfüllungsrelation. Sie wird als Rekursion über den
Formelaufbau definiert. Der Wahrheitswert einer Formel ist hierbei
einzig und allein durch die Wahrheitswerte ihrer Teilformeln bestimmt.

\begin{Definition}[Erfüllungsrelation]\label{def:sat}\newlinefirst
Eine \emph{Interpretation} $I$ ist eine Funktion, die jede atomare
logische Variable $P$ mit einem Wahrheitswert $I(P)\in\{0,1\}$ belegt.
Man definiert $I\models A$, sprich »$I$ erfüllt $A$«, rekursiv als
\begin{align*}
(I\models\bot) &:\Leftrightarrow 0,
& (I\models A\land B) &:\Leftrightarrow ((I\models A)\land (I\models B)),\\
(I\models\top) &:\Leftrightarrow 1,
& (I\models A\lor B) &:\Leftrightarrow ((I\models A)\lor (I\models B)),\\
(I\models P) &:\Leftrightarrow I(P),
& (I\models A\cond B) &:\Leftrightarrow ((I\models A)\cond (I\models B)),\\
(I\models\lnot A) &:\Leftrightarrow \lnot (I\models A),
& (I\models A\bicond B) &:\Leftrightarrow ((I\models A)\bicond (I\models B)).
\end{align*}
\end{Definition}
Die rechte Seite der jeweiligen Festsetzung ist metalogisch zu verstehen
und per Wahrheitstafel definiert, siehe Tabelle \ref{tab:Junktoren}.
Die Schreibweise $I\nvDash A$ ist gleichbedeutend mit
$\lnot (I\models A)$. Eine Interpretation wird auch als \emph{Modell}
bezeichnet. Man nennt sie \emph{Modell} einer Formel, falls sie die
Formel erfüllt. Andernfalls spricht man von einem \emph{Kontramodell}
oder \emph{Gegenmodell} der Formel.

\begin{table}
\caption{Wahrheitstafel der Junktoren}
\label{tab:Junktoren}
\centering
\begin{tabular}{cc@{\qquad}c@{\qquad}c@{\qquad}c@{\qquad}c@{\qquad}c}
\toprule
$A$ & $B$ & $\lnot A$ & $A\land B$ & $A\lor B$ & $A\cond B$ & $A\bicond B$\\
\midrule[\heavyrulewidth]
$0$ & $0$ & $1$ & $0$ & $0$ & $1$ & $1$\\
$1$ & $0$ & $0$ & $0$ & $1$ & $0$ & $0$\\
$0$ & $1$ & $1$ & $0$ & $1$ & $1$ & $0$\\
$1$ & $1$ & $0$ & $1$ & $1$ & $1$ & $1$\\
\bottomrule
\end{tabular}
\end{table}

\begin{Definition}\label{def:sat-context}
Für einen Kontext $\Gamma = \{A_1,\ldots,A_n\}$ setzt man
\[(I\models\Gamma)\,:\bicond\, (I\models A_1)\land\ldots\land (I\models A_n).\]
\end{Definition}

\subsection{Gültigkeit einer Formel}

Eine wichtige Rolle spielen \emph{allgemeingültige} Formeln, die man
in der Aussagenlogik auch als \emph{Tautologien}\index{Tautologie}
bezeichnet. Sie sind immer wahr, unabhängig davon, mit welchem
Wahrheitswert ihre logischen Variablen belegt werden.

Als allgemeinere Begrifflichkeit wollen wir auf einen Kontext $\Gamma$
bezogen gültige Formeln $A$ betrachten. Die Idee hierbei ist,
dass wenn die Formeln des Kontextes als wahr angenommen werden, die
Formel $A$ ebenfalls wahr sein muss. Trifft dies auf $A$ zu,
schreibt man $\Gamma\models A$, gelesen »im Kontext $\Gamma$ ist
$A$ gültig«, oder auch »$\Gamma$ zieht $A$ nach sich«. Die Bezeichnung
\emph{logische Folgerung} oder \emph{logische Konsequenz} ist
ebenfalls verbreitet.

\begin{Definition}[Gültige Formel]\label{def:valid}\newlinefirst
Eine Formel $A$ heißt \emph{gültig} im Kontext $\Gamma$,
wenn jede Interpretation, die sämtliche Formeln von $\Gamma$ erfüllt,
auch $A$ erfüllt. Metalogisch
\[(\Gamma\models A)\,:\bicond\,\forall I\colon (I\models\Gamma)\cond (I\models A).\]
\end{Definition}
Eine im leeren Kontext gültige aussagenlogische Formel $A$ nennt man
wie gesagt Tautologie. Statt $\emptyset\models A$ schreibt man auch
kurz $\models A$. Wie bei Sequenzen schreibt man auch $\Gamma,A,B\models C$
statt $\Gamma\cup\{A,B\}\models C$.

\subsection{Wahrheitstafeln}

Obgleich der Variablenvorrat unendlich groß sein darf, enthält eine
Formel von den Variablen nur endlich viele. Insofern sind für eine
Formel in einem Kontext auch nur endlich viele Interpretationen relevant.
Sind insgesamt $n$ Variablen vorhanden, sind es $2^n$ Interpretationen.

Eine Interpretation $I$ mit der Auswertung $I\models A$ ist nichts
anderes als eine Zeile der Wahrheitstafel\index{Wahrheitstafel} der
Formel $A$. Eine Formel ist genau dann tautologisch, wenn in der
Ergebnisspalte in jeder Zeile eine~1 steht.

Ein Beispiel. Die Wahrheitstafel \ref{tab:Tautologie-zur-Kontraposition}
bestätigt
\[\models (a\cond b)\bicond (\lnot b\cond\lnot a).\]

\begin{table}
\caption{Wahrheitstafel der Tautologie zur Kontraposition}
\label{tab:Tautologie-zur-Kontraposition}
\centering
\begin{tabular}{cc@{\quad\;\;}c@{\quad\;\;}c@{\quad\;\;}c@{\quad\;\;}c@{\quad\;\;}c}
\toprule
$a$ & $b$ & $\lnot b$ & $\lnot a$ & $a\cond b$ & $\lnot b\cond\lnot a$
& $(a\cond b)\bicond (\lnot b\cond\lnot a)$\\
\midrule[\heavyrulewidth]
$0$ & $0$ & $1$ & $1$ & $1$ & $1$ & $1$ \\
$1$ & $0$ & $1$ & $0$ & $0$ & $0$ & $1$ \\
$0$ & $1$ & $0$ & $1$ & $1$ & $1$ & $1$ \\
$1$ & $1$ & $0$ & $0$ & $1$ & $1$ & $1$ \\
\bottomrule
\end{tabular}
\end{table}

\noindent
Die Tafel führt zusätzlich die Teilformeln auf, was bei längeren
Formeln recht mühselig erscheinen mag. Eine geschickte Methode zur
Reduzierung des Schreibaufwands erspart die Teilformeln, und setzt ihre
Wahrheitswerte dafür schlicht unter die Junktoren, denn Ziffern
benötigen nicht viel Platz.

Die Prüfung einer logischen Folgerung per Wahrheitstafel
wird ermöglicht durch die metalogische Beziehung
\[(A_1,\ldots,A_n\models A)\,\bicond\, (\models A_1\land\ldots\land A_n\cond A).\]
Nämlich findet sich die äquivalente Umformung
\begin{align*}
(A_1,\ldots,A_n\models A)
&\;\Longleftrightarrow_{\text{(1)}}\;
(\forall I\colon (I\models A_1)\land\ldots\land (I\models A_n)\cond (I\models A))\\
&\;\Longleftrightarrow_{\text{(2)}}\;
(\forall I\colon (I\models A_1\land\ldots\land A_n)\cond (I\models A))\\
&\;\Longleftrightarrow_{\text{(3)}}\;
(\forall I\colon I\models A_1\land\ldots\land A_n\cond A)\\
&\;\Longleftrightarrow_{\text{(4)}}\;
(\models A_1\land\ldots\land A_n\cond A).
\end{align*}
Hierbei gilt (1), (4) gemäß Def. \ref{def:valid}, \ref{def:sat-context}
und (2), (3) gemäß Def. \ref{def:sat}.

\subsection{Korrektheit des natürlichen Schließens}

Jede Schlussregel und jedes Axiom besitzt eine semantische Entsprechung.
Die Beweise dafür werden nun auf metalogischer Ebene mittels natürlichem
Schließen selbst erbracht, was wie eine Art Zirkelschluss erscheinen
mag.

Zu den Grundsequenzen und zur Abschwächungsregel findet sich:
\[
\begin{array}{@{}l@{\qquad}l}
\begin{prooftree}[center = false, separation = 1em]
        \infer0[1]{I\models\Gamma\cup\{A\}}
      \infer1[Def. \ref{def:sat-context}]{(I\models\Gamma)\land (I\models A)}
    \infer1{I\models A}
  \infer1[$\sim$1]{(I\models \Gamma\cup\{A\})\cond (I\models A)}
\infer1[Def. \ref{def:valid}]{\Gamma\cup\{A\}\models A}
\end{prooftree}
&
\begin{prooftree}[center = false, separation = 1em]
        \hypo{\Gamma\models A}
      \infer1[Def. \ref{def:valid}]{(I\models\Gamma)\cond (I\models A)}
        \infer0[1]{I\models\Gamma\cup\Gamma'}
      \infer1[Def. \ref{def:sat-context}]{I\models\Gamma}
    \infer2{I\models A}
  \infer1[$\sim$1]{(I\models\Gamma\cup\Gamma')\cond (I\models A)}
\infer1[Def. \ref{def:valid}]{\Gamma\cup\Gamma'\models A}
\end{prooftree}
\end{array}
\]
Die Prüfung der restlichen Entsprechungen sei dem Leser überlassen.

\begin{Satz}[Korrektheit des natürlichen Schließens]\newlinefirst
Ist die Sequenz $\Gamma\vdash A$ ableitbar, so muss auch
$\Gamma\models A$ gelten.
\end{Satz}
\begin{Beweis}
Strukturelle Induktion über die Konstruktion von Beweisbäumen.
Induktionsanfänge sind die semantischen Entsprechungen
der Grundsequenzen. Induktionsschritte sind die semantischen
Entsprechungen der Schlussregeln. Die Beweise der Entsprechungen
wurden bereits diskutiert.\,\qedsymbol
\end{Beweis}

% [todo]
% Korrektheit verschafft noch mehr. In Kontraposition,
% wenn ein Kontramodell $\Gamma\models A$ widerlegt,
% ist die Sequenz $\Gamma\vdash A$ nicht ableitbar.
% Solche Negativresultate sind ohne Semantik schwieriger
% zu erbringen.

\newpage
\subsection{Logische Äquivalenz}
\begin{Definition}[Äquivalente Formeln]\newlinefirst
Die Äquivalenz zweier Formeln $A,B$ ist definiert als
\[(A\equiv B)\,:\bicond\, (\models A\bicond B).\]
\end{Definition}

\noindent
Eine Äquivalenz besteht genau dann, wenn jede der beiden Formeln
eine logische Folgerung der anderen ist. Das heißt, es besteht die
metalogische Beziehung
\[(\models A\bicond B)\,\bicond\, (A\models B)\land (B\models A).\]
Mit den semantischen Entsprechungen der Schlussregeln
findet sich nämlich:
\[
\begin{array}{@{}l@{\qquad\quad}l}
\begin{prooftree}[center = false]
    \hypo{\models A\bicond B}
  \infer1{\models A\cond B}
  \infer0{A\models A}
\infer2{A\models B}
\end{prooftree}
&
\begin{prooftree}[center = false]
    \hypo{A\models B}
  \infer1{\models A\cond B}
    \hypo{B\models A}
  \infer1{\models B\cond A}
\infer2{\models A\bicond B}
\end{prooftree}
\end{array}
\]
\begin{Satz}\label{log-Aeq-ist-Aeqrel}
Es ist $A\equiv B$ eine Äquivalenzrelation. Das heißt, es gilt
\begin{align*}
& A\equiv A, &&\text{(Reflexivität)}\\
& (A\equiv B)\cond (B\equiv A), &&\text{(Symmetrie)}\\
& (A\equiv B)\land (B\equiv C)\cond (A\equiv C). &&\text{(Transitivität)}
\end{align*}
\end{Satz}
Der Beweis sei dem Leser als kleine Übung überlassen.

Der Satz \ref{log-Aeq-ist-Aeqrel} vermittelt, dass Formeln mit
Äquivalenzen so umgeformt werden dürfen, wie Terme mit Termumformungen.
Es finden sich im Fortgang eine Reihe von grundlegenden Äquivalenzen,
die Regeln der \emph{booleschen Algebra}\index{boolesche Algebra}. Sie
wurde erstmals in der Mitte des 19. Jahrhunders vom britischen
Mathematiker George Boole in seiner Abfassung \emph{The Mathematical
Analysis of Logic} und seinem späteren Buch \emph{An Investigation of
The Laws of Thought} beschrieben. Boole beschreibt allerdings, anders
als heute üblich, eine Einbettung der logischen Operationen in die
gewöhnliche Algebra, siehe Tabelle \ref{tab:Boole}.

\begin{table}
\centering
\caption{Einbettung in die gewöhnliche Algebra}
\label{tab:Boole}
\begin{tabular}{ccccc}
\toprule
\strong{Modern} & $\lnot a$ & $a\land b$ & $a\lor b$ & $a\cond b$\\
\strong{Boole} & $1-a$ & $ab$ & $a+b(1-a)$ & $1-a+ab$\\
\bottomrule
\end{tabular}
\end{table}

Logische Äquivalenz im absoluten Sinne ist nicht unter allen Umständen
der Weisheit letzter Schluss. In der Schaltalgebra tun sich
Problemstellungen auf, wo der Wahrheitswert einer Formel $A$ in
einzelnen Zeilen der Wahrheitstafel keine Rolle spielt, man spricht von
\emph{Don't-Care"=Zellen}. Es sei $X$ eine Formel, die genau in diesen
Zeilen wahr ist, in allen anderen falsch. Man möchte $A$ nun
beispielsweise zu $B$ vereinfachen. Unter normalen Umständen sollte
diese Vereinfachung die Äquivalenz $A\equiv B$ einhalten. Bei
Vorhandensein der irrelevanten Zellen genügt jedoch die weniger strenge
Forderung
\[\lnot X\models A\bicond B.\]
Wir haben es hier mit einer relativen Äquivalenz zu tun. Auch bei ihr
handelt es sich um eine Äquivalenzrelation, wobei $X$ beliebig ist,
aber fest sein muss.

\begin{table}
\begin{center}
\caption{Die Regeln der booleschen Algebra.}
\label{tab:boolesche-Algebra}
\begin{tabular}{@{}c@{\qquad}c@{\qquad}l@{}}
\toprule
\strong{Konjunktion}&
\strong{Disjunktion}&
\strong{Bezeichnung}\\
\midrule[\heavyrulewidth]
$A\land 0\equiv 0$ &
$A\lor 1\equiv 1$ &
Extremalgesetze\\

$A\land\lnot A\equiv 0$ &
$A\lor\lnot A\equiv 1$ &
Komplementärgesetze\\

$A\land A\equiv A$ &
$A\lor A\equiv A$ &
Idempotenzgesetze\\

$A\land 1\equiv A$ &
$A\lor 0\equiv A$ &
Neutralitätsgesetze\\
\midrule
$A\land B\equiv B\land A$ &
$A\lor B\equiv B\lor A$ &
Kommutativgesetze\\

$A{\land}(B{\land}C)\equiv (A{\land}B){\land}C$ &
$A{\lor}(B{\lor}C)\equiv (A{\lor}B){\lor}C$ &
Assoziativgesetze\\

$\lnot (A\land B)\equiv\lnot A\lor\lnot B$ &
$\lnot (A\lor B)\equiv\lnot A\land\lnot B$ &
De morgansche Gesetze\\

$A\land (A\lor B)\equiv A$ &
$A\lor (A\land B)\equiv A$ &
Absorptionsgesetze\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

\subsection{Die Einsetzungsregel}

\begin{Satz}[Einsetzungsregel]\newlinefirst
Ist die Formel $A$ allgemeingültig, so führt die simultane Ersetzung
einiger atomarer Variablen durch Formeln bei ihr zu einer weiteren
allgemeingültigen Formel. Metalogisch
\[(\models A)\cond (\models A[P_1:=B_1,\ldots,P_n:=B_n]).\]
\end{Satz}
\begin{Beweis}
Die Bestimmung von $I\models A[\ldots]$ läuft in
derselben Weise ab wie die von $I\models A$, außer dass $I(P_k)$ durch
$I\models B_k$ zu ersetzen ist. Sofern $A$ allgemeingültig ist, gilt
$I\models A$ unabhängig davon, ob $I(P_k)$ wahr oder falsch ist.
Ergo muss $I\models A[\ldots]$ unabhängig davon gelten, ob $I\models B_k$
wahr oder falsch ist.\,\qedsymbol
\end{Beweis}

\noindent
Ich mag daran erinnern, dass bei der Substitution \emph{jedes}
Vorkommen der Variable durch dieselbe Formel zu ersetzen ist.

Zum Beispiel erhält man zu der simultanen Ersetzung
$a:=A$ und $b:=B$ aus
\[\models (a\cond b)\bicond (\lnot b\cond\lnot a)\;\;\text{das Schema}\;\;
\models (A\cond B)\bicond (\lnot B\cond\lnot A).\]
Mit dem Vollständigkeitssatz infolge das Theoremschema
\[\vdash (A\cond B)\bicond (\lnot B\cond\lnot A).\]
Hiermit gewinnt man kurzum die Regeln
\[\dfrac{\Gamma\vdash A\cond B}{\Gamma\vdash\lnot B\cond\lnot A},\qquad
\dfrac{\Gamma\vdash\lnot B\cond\lnot A}{\Gamma\vdash A\cond B}.\]
Die Vorgehensweise ermöglicht summa summarum die Auffindung von
zulässigen Schlussregeln durch geistloses Ausfüllen von Wahrheitstafeln,
was allerdings auf die klassische Aussagenlogik beschränkt bleibt.

\subsection{Wahrheitsfunktionen}

Mit der Bindung ihrer atomaren Variablen gehen aus den Formeln der
Aussagenlogik Wahrheitsfunktionen\index{Wahrheitsfunktion} hervor.
Die Disjunktion zweier Aussagen wird zum Beispiel vermittelt durch die Funktion%
\[f\colon\{0,1\}\times\{0,1\}\to\{0,1\},\quad f(a,b):=(a\lor b).\]
Jede Wahrheitsfunktion in $n$ Variablen ist durch ihre Wahrheitstafel
charakterisiert, die aus $2^n$ Zeilen besteht, da der Definitionsbereich
so viele unterschiedliche Tupel enthält. Ein Tupel von Wahrheitswerten
wird auch als Bitfolge betrachtet.

Zwei Formeln $A,B$ sind genau dann äquivalent, wenn sie durch dieselben
Interpretationen erfüllt werden, sich also in der Wahrheitstafel gleich
verhalten. Man überzeugt sich davon unschwer mit der metalogischen
Umformung%
\begin{align*}
(A\equiv B) &\iff (\models A\bicond B)
\iff (\forall I\colon I\models A\bicond B)\\
&\iff (\forall I\colon (I\models A)\bicond (I\models B)).
\end{align*}
Demnach charakterisieren äquivalente Formeln dieselbe
Wahrheitsfunktion. Man kann dies auch so betrachten, dass die
Wahrheitsfunktion die Äquivalenzklasse all ihrer Formeln repräsentiert.
Unter den Formeln gibt es nun einen besonderen Vertreter, die
\emph{disjunktive Normalform}\index{disjunktive Normalform}, kurz DNF,
die eigentlich nichts anderes als eine direkte Kodierung der
Wahrheitstafel ist. Insofern ließt sich an der Wahrheitstafel
unmittelbar die DNF der Formel ab.

Die Normalform einer Formel lässt sich unter Umständen
vereinfachen. Bei der DNF der Disjunktion ist bereits klar, welche
Formel Resultat der Vereinfachung sein müsste. Es findet sich
\begin{gather*}
(a\land\lnot b)\lor (\lnot a\land b)\lor (a\land b)
\equiv (a\land\lnot b)\lor ((\lnot a\lor a)\land b)\\
\equiv (a\land\lnot b)\lor (1\land b)
\equiv (a\land\lnot b)\lor b
\equiv (a\lor b)\land (\lnot b\lor b)\\
\equiv (a\lor b)\land 1 \equiv a\lor b.
\end{gather*}
In der Schaltalgebra ist die Vereinfachung der DNF von großer
Wichtigkeit, da sie den maßgeblichen Schritt zur Ermittelung von
Schaltungen mit einer minimalen Zahl von Gattern darstellt.
Aus dieser Anforderung heraus wurden systematische Verfahren
zur Vereinfachung entwickelt. Für wenige Variablen stellt das
sogenannte Karnaugh"=Veitch"=Diagramm ein geschicktes
Hilfsmittel dar.

Mit dem Verfahren nach Quine und McCluskey lassen sich Formeln mit
beliebig vielen Variablen mit einem Computer automatisch vereinfachen.
Der Algorithmus ist allerdings von exponentieller Laufzeit, dessen
Ausführung also von einer kombinatorischen Explosion
überschattet. Eine wesentliche Verbesserung darf man auch nicht erwarten,
da die Problemstellung der Vereinfachung als NP"=vollständig befunden
wurde. Für die Formeln mit sehr vielen Variablen liegt das Wissen über
die beste Vereinfachung somit im Schleier der Dunkelheit.

\section{Die klassische Semantik der Logik erster Stufe}

\subsection{Strukturen}

Wie in der Aussagenlogik soll den Formeln eine Bedeutung zukommen.
Eine Formel der Prädikatenlogik ist allerdings komplizierter als eine
Formel der Aussagenlogik. Statt nur atomare Variablen mit
Wahrheitswerten zu belegen, sind nun unterschiedliche Arten von
Symbolen vorhanden, die mit einer Bedeutung versehen werden müssen.

Es gibt erstens die logischen Verknüpfungen, denen eine für die
Logik spezifische feste Funktion zukommt. Ebenso ist die Gleichheit
zweier Terme fest definiert. Zweitens können in einer Formel Symbole
für Funktionen und Relationen vorkommen, darunter fallen auch
Konstanten. Sie werden je nach gewählter Struktur anders mit
Funktionen und Relationen belegt. Drittens darf eine Formel
freie Variablen enthalten. Sie werden durch eine extra definierte
Belegungsfunktion mit Werten belegt. Bei der Interpretation einer
quantifizierten Teilformel wird die Belegungsfunktion modifiziert.

Je nach Festlegung des logisch"=mathematischen Systems und dessen
inhaltlicher Deutung haben die mathematischen Terme Werte
in einer bestimmten Menge $U$, die wir \emph{Universum},
\emph{Domäne}, \emph{Träger}, \emph{Grundbereich} oder
\emph{Diskursuniversum} nennen.  Die Elemente von $U$ nennen wir
\emph{Individuen} oder \emph{Objekte}. Ich möchte noch einmal daran
erinnern, dass der beschriebene Kalkül der Prädikatenlogik die
Menge $U$ als nichtleer fordert.

Eine \emph{Struktur} $M$ sei das Universum $U$ zusammen mit einer
Interpretationsfunktion, die jedem Funktionssymbol $f$ von $n$ Argumenten
eine Funktion $f^M\colon U^n \to U$ und jedem Relationssymbol $R$ von
$n$ Argumenten eine Relation $R^M\colon U^n\to\{0,1\}$ zuordnet.
Konstanten deuten wir als Funktionen von null Argumenten.

Man kann eine Struktur auf unterschiedliche Art kodieren, wobei
unter Umständen die Hilfsbegriffe \emph{Signatur} und
\emph{Ariätsfunktion} gebraucht werden. Die Signatur beschreibt hierbei
die Menge der Funktionssymbole und die Menge Relationssymbole. Die
Aritätsfunktion ordnet jedem Funktionssymbol und jedem Relationssymbol
seine Stelligkeit zu, das ist die Anzahl der Argumente.

\strong{Beispiel 1. Ein Kalkül für Halbordnungen.} Zusätzlich zu
den Regeln und Axiomen der Prädikatenlogik sollen als mathematische Axiome
demnach noch die Axiome für Halbordnungen gelten. Die Signatur enthalte
dazu lediglich das Relationssymbol $\le$. Eine mögliche Struktur $M$
ist die Menge $U:=\mathcal P(G)$ zu irgendeiner Grundmenge $G$, zusammen
mit der Setzung ${\le^M} := {\subseteq}$, so dass je zwei Mengen $A,B\in U$
ein Wahrheitswert $A\subseteq B$ zugeordnet wird. Man notiert so
eine Struktur üblicherweise einfach schludrig als $(U,\le^M)$,
konkret $(\mathcal P(G),\subseteq)$.

\strong{Beispiel 2. Ein Kalkül für Gruppen.} Zusätzlich
zu den Regeln und Axiomen der Prädikatenlogik sollen als mathematische Axiome
demnach noch die Axiome für Gruppen gelten. Die Signatur enthalte
dazu ein Konstantensymbol für das neutrale Element, die Verknüpfung von
Elementen als zweistelliges Funktionssymbol und die Invertierungsfunktion
als einstelliges Funktionssymbol. Eine Struktur notiert man dann als
$(G,\cdot,e,\mathrm{inv})$. Eine mögliche Struktur ist $(\R,+,0,\mathrm{inv})$
mit $\mathrm{inv}(x):=-x$, die Gruppe der reellen Zahlen bezüglich
Addition. Eine andere mögliche Struktur ist $(S(X),\circ,\id,\mathrm{inv})$
mit $\mathrm{inv}(f):=f^{-1}$, die Gruppe der bijektiven Selbstabbildungen
auf der Menge $X$ bezüglich der Verkettung, auch symmetrische Gruppe
genannt. Es ist hier $\id$ die identische Abbildung und $f^{-1}$
die Umkehrabbildung von $f$.

\strong{Beispiel 3. Ein Kalkül für die Mengenlehre.} Der unerfahrene Leser mag
diesbezüglich zunächst das Kapitel über Mengenlehre studieren und später
hierher zurückkommen. Das Diskursuniversum soll das Mengenuniversum sein.
Nun verhält es sich allerdings so, dass die Zusammenfassung aller denkbaren
Mengen eine echte Klasse bildet, die keine Menge mehr sein kann. Man
könnte die Definition des Diskursuniversums so modifizieren, dass es eine
beliebige Klasse sein darf, was aber dazu führen würde, dass dieses
nicht mehr ohne Ausnahme als Element eines Mengensystems auftreten darf.
Wir gehen dieser Komplikation durch die Betrachtung des
Grothendieckuniversums $U=V_\kappa$ für ZFC oder $U=V_{\kappa+1}$ für
die Morse"=Kelly"=Mengenlehre aus dem Weg, wobei mit den $V_\alpha$ die
kumulative Hierarchie und mit $\kappa$ eine als Ordinalzahl betrachtete
unerreichbare Kardinalzahl gemeint ist. Die Einzelheiten erläutert
Shulman \cite{Shulman}. Einziges Relationssymbol ist nun  ${\in}$ für
die Elementrelation, und Funktionssymbole gibt es gar keine. Das mag
verwirrend erscheinen, wo die Mengenlehre doch von Relationen und
Funktionen durchdrungen ist. Diese stellen bei näherer Betrachtung aber
Objekte des Universums dar.

Aber ist die leere Menge nicht ein Konstantensymbol, die Inklusion
${\subseteq}$ nicht ein weiteres Relationssymbol und Operatoren wie
$\cap$ und $\cup$ Funktionssymbole? An sich stimmt das. Das
formale System der Mengenlehre kann um diese Symbole erweitert werden,
die minimalistische Fassung des Systems kommt jedoch allein mit
${\in}$ aus. Alle weiteren Symbole werden durch ihre Definition
ersetzt, obgleich dadurch unter Umständen exorbitant lange Formeln
entstehen. Zum Beispiel wird die Formel $A\cap B\subseteq A\cup B$
expandiert zu
\[\forall x\colon x\in A\land x\in B\cond x\in A\lor x\in B.\]

\subsection{Interpretationen}

Zur Interpretation eines Terms $t$ mit freien Variablen betrachtet
man außerdem noch eine \emph{Belegung} $\beta$, die jeder Variablen $x$
einen Wert $\beta(x)\in U$ zuordnet. Geläufig ist ebenfalls die
Bezeichnung \emph{Zuweisung}.

Man nennt nun $I=(M,\beta)$ eine \emph{Interpretation} der Formel $A$.
Wir definieren $I(t)$ für einen Term $t$ rekursiv über den Termaufbau
als%
\begin{gather*}
I(x) := \beta(x),\\
I(f(t_1,\ldots,t_n)) := f^M(I(t_1),\ldots,I(t_n)),
\end{gather*}
wobei $x$ eine Variable und $f$ ein $n$-stelliges Funktionssymbol
ist. Die Belegung mit einer modifiziert belegten Variable wird
diesbezüglich definiert als%
\begin{gather*}
\beta[y{:=}u](x) := \begin{cases}
u, & \text{wenn}\;x=y,\\
\beta(x), & \text{sonst}.
\end{cases}
\end{gather*}
Für $I=(M,\beta)$ sei $I[y{:=}u] := (M,\beta[y{:=}u])$.

Um Missverständnissen aus dem Weg zu gehen, sollte ich erwähnen, dass
die Begriffe \emph{Variable} und \emph{Atom} in der Prädikatenlogik
anders verstanden werden als in der Aussagenlogik. Die atomaren
Variablen der Aussagenlogik entsprechen nullstelligen Relationssymbolen,
denen bei einer Interpretation Relationen von null Argumenten zukommt,
das sind schlicht die konstanten Wahrheitswerte. Dagegen meint Variable
in der Prädikatenlogik üblicherweise eine Individuenvariable. Eine
atomare Formel ist in der Prädikatenlogik nicht nur ein nullstelliges
Relationssymbol, sondern jede Applikation eines Relationssymbols und
jede Gleichung.

Die Erfüllungsrelation definiert man analog zur Aussagenlogik, also
\[(I\models A\land B)\,:\bicond\,(I\models A)\land (I\models B)\]
und so weiter. Zusätzlich setzt man%
\begin{gather*}
(I\models t_1 = t_2) :\Leftrightarrow I(t_1) = I(t_2),\\
(I\models R(t_1,\ldots,t_n)):\Leftrightarrow R^M(I(t_1),\ldots,I(t_n)),\\
(I\models\forall x\colon A) :\Leftrightarrow\forall u\in U\colon I[x{:=}u]\models A,\\
(I\models\exists x\colon A) :\Leftrightarrow\exists u\in U\colon I[x{:=}u]\models A.
\end{gather*}
Man definiert hiermit die semantische Folgerung analog zur Aussagenlogik als
\[(\Gamma\models A)\,:\bicond\,\forall I\colon (I\models\Gamma)\cond (I\models A).\]
Wir nennen $A$ \emph{allgemeingültig}, falls $\emptyset\models A$, was
wir wieder durch $\models A$ abkürzen wollen.

Sofern die Formel $A$ geschlossen ist, das heißt, keine freien
Variablen besitzt, spielt die Belegung der Variablen noch keine Rolle, sie
entsteht eigentlich erst bei der rekursiven Bestimmung von $I\models A$
mit dem Einstieg in eine quantifizierte Formel. Bei einer einer
geschlossenen Formel $A$ darf man insofern $M\models A$ statt
$M,\beta\models A$ schreiben. Gilt $M\models A$, nennt man $M$ ein
\emph{Modell für} $A$.

Ich will erklären, warum die Interpretation der Quantoren so durchgeführt
wurde wie beschrieben. Intuitiv erfüllt $I$ die Formel
$\forall x\colon A$ genau dann, wenn $I$ die Formel $A[x:=u]$ für jedes
$u\in U$ erfüllt. Allerdings ist $u$ kein Term der logischen Sprache,
womit $A[x:=u]$ keine Formel mehr wäre. Wir könnten nicht einmal für
jedes $u$ eine Konstante zur Sprache hinzufügen, weil $U$ überabzählbar
sein darf, während eine gewöhnliche Sprache nur abzählbar viele
Symbole in Form von Zeichenketten umfassen kann. Die gewählte Ausweg
aus der Problematik besteht darin, dass die Belegung $x:=u$ erst einmal
in der Interpretation gespeichert wird, statt sie direkt
als Substitution auf die Formel anzuwenden.

\subsection{Korrektheit des natürlichen Schließens}

Wir müssen nun wieder aufzeigen, dass der Kalkül des natürlichen
Schließens bezüglich der definierten Semantik korrekt ist. Dies
geschieht wieder per struktureller Induktion über den Aufbau des
Beweises. Für die bereits in der Aussagenlogik vorhandenen Regeln
können wir die dort gemachte Argumentation unverändert übernehmen.
Zu bestätigen verbleibt die Korrektheit der Regeln zur Einführung und
Beseitigung der Quantoren, und ggf. noch die Korrektheit der Regeln zum
Umgang mit Gleichheiten.

\begin{Satz}\label{interpretation-lemma}
Es ist $I[x:=I(t)]\models A$ äquivalent zu $I\models A[x:=t]$.
\end{Satz}
\begin{Beweis}
Man unternimmt hierzu eine strukturelle Induktion über den Formelaufbau
von $A$. Die Induktionsvoraussetzungen sind jeweils unschwer zu verarbeiten.
Im Wesentlichen verbleibt nun%
\[I[x:=I(t)](v) = I(v[x:=t])\]
für jede Individuenvariable $v$ zu zeigen. Man nimmt dazu die
Fallunterscheidung zwischen $x=v$ und $x\ne v$ vor. Im ersten Fall gilt%
\[I[x:=I(t)](v) = I(t) = I(x[x:=t]) = I(v[x:=t]),\]
und im zweiten Fall gilt
\[I[x:=I(t)](v) = I(v) = I(v[x:=t]).\,\qedsymbol\]
\end{Beweis}

\begin{Satz}
Aus $\Gamma\models\forall x\colon A$ folgt $\Gamma\models A[x:=t]$.
\end{Satz}
\begin{Beweis}
Laut der Prämisse muss zu jedem $I$ mit $I\models\Gamma$
auch $I[x:=u]\models A$ für jedes $u\in U$ gelten. Weitere Prämisse
ist ein $I$ mit $I\models\Gamma$. Die Allaussage wird mit diesem $I$
und mit $u:=I(t)$ spezialisiert. Zu zeigen verbleibt%
\[(I[x:=I(t)]\models A)\cond (I\models A[x:=t]).\]
Diese gilt gemäß Satz \ref{interpretation-lemma}.\,\qedsymbol
\end{Beweis}

\begin{Satz}
Aus $\Gamma\models A[x:=t]$ folgt $\Gamma\models\exists x\colon A$.
\end{Satz}
\begin{Beweis}
Laut der Prämisse muss zu jedem $I$ mit $I\models\Gamma$ auch
$I\models A[x:=t]$ gelten. Weitere Prämisse ist ein $I$ mit
$I\models\Gamma$. Die Allaussage wird mit diesem $I$ spezialisiert.
Zu zeigen verbleibt%
\[(I\models A[x:=t])\cond \exists u\in U\colon (I[x:=u]\models A).\]
Gewählt wird $u:=I(t)$. Nun greift wieder Satz
\ref{interpretation-lemma}.\,\qedsymbol
\end{Beweis}

\begin{Satz}
Aus $\Gamma\models A$ und $x\notin\mathrm{FV}(\Gamma)$
folgt $\Gamma\models\forall x\colon A$.
\end{Satz}
\begin{Beweis}
Laut der Prämisse muss zu jedem $I$ mit $I\models\Gamma$ auch
$I\models A$ gelten. Weitere Prämisse ist ein $I$ mit
$I\models\Gamma$. Wegen $x\notin\mathrm{FV}(\Gamma)$ ist
$I\models\Gamma$ äquivalent zu $I[x:=u]\models\Gamma$. Demnach
lässt sich die Allaussage mit $I[x:=u]$ spezialisieren, womit
man $I[x:=u]\models A$ erhält. Ergo gilt%
\[\forall u\in U\colon (I[x:=u]\models A),\;\text{also}\;
I\models\forall x\colon A.\,\qedsymbol\]
\end{Beweis}

\begin{Satz}
Aus $\Gamma\models\exists x\colon A$ und $\Gamma\cup\{A\}\models B$
mit $x\notin\mathrm{FV}(\Gamma\cup\{B\})$ folgt $\Gamma\models B$.
\end{Satz}
\begin{Beweis}
Laut der ersten Prämisse existiert zu jedem $I$ mit $I\models\Gamma$
ein $u\in U$ mit $I[x:=u]\models A$. Laut der zweiten Prämisse muss
zu jedem $I$ mit $I\models\Gamma$ und $I\models A$ auch $I\models B$
gelten. Wegen $x\notin\mathrm{FV}(\Gamma\cup\{B\})$ ist $I\models\Gamma$
zu $I[x:=u]\models\Gamma$ sowie $I\models B$ zu $I[x:=u]\models B$
äquivalent. Dritte Prämisse ist ein $I$ mit $I\models\Gamma$. Die erste
Allaussage wird mit $I$ spezialisiert, die zweite mit $I[x:=u]$. 
Mit den vorliegenden Aussagen gelingt der Schluss auf $I[x:=u]\models B$.
Ergo gilt $I\models B$, wie gewünscht.\,\qedsymbol
\end{Beweis}

\section{Semantik der Modallogik}

\subsection{Die relationale Semantik der Modallogik}

Mit der Entwicklung der Modallogiken ging die Frage einher, wie
modallogische Formeln semantisch interpretiert werden können.
Besonders wichtig sind die nach Saul Kripke benannten
\emph{Kripke"=Semantiken}, auch \emph{relationale Semantiken} genannt.
Die Interpretation der atomaren Aussagen wird hierbei durch eine Welt
parametrisiert. Eine Aussage kann also in einer bestimmten Welt wahr
sein, während sie in einer anderen falsch ist. Als Logik der Metasprache
soll dabei die klassische Prädikatenlogik dienen.

Eine \emph{Kripke"=Struktur} sei ein Tripel $M=(W,R,V)$. Hierbei
ist $W$ eine Menge von Welten, $R$ eine zweistellige Relation auf
$W$, und $V$ eine Wertung, die jeder atomaren Variable $a$
parametrisiert durch die Welt $w\in W$ einen Wahrheitswert
$V(w,a)\in\{0,1\}$ zuordnet. Man nennt $R$ die
\emph{Zugänglichkeitsrelation}, wobei $R(w,w')$ gedeutet wird als
»$w'$ ist von $w$ aus zugänglich«. Die Relation muss nicht unbedingt
symmetrisch sein, womit man unter Umständen nicht mehr von
$w'$ aus in die ursprüngliche Welt $w$ zurückgelangt.

Das Paar $I=(M,w)$, bestehend aus einer Struktur und einer Welt, betrachten
wir als Interpretation. Man legt die Erfüllung einer atomaren Variable
$a$ bezüglich einer Interpretation fest als%
\[(M,w\models a) :\bicond V(w,a).\]
Die Erfüllung der Junktoren wird analog zur klassischen Semantik
definiert, also%
\[(I\models A\land B) :\bicond (I\models A)\land (I\models B)\]
und so weiter, wobei die rechte Seite gemäß den herkömmlichen
Wahrheitstafeln ausgewertet wird. Für die beiden modalen Junktoren legt
man nun fest%
\begin{align*}
(M,w\models\lnec A) &:\bicond\forall w'\in W\colon R(w,w')\cond (M,w'\models A),\\
(M,w\models\lpos A) &:\bicond\exists w'\in W\colon R(w,w')\land (M,w'\models A). 
\end{align*}
In Worten ist die Aussage $\lnec A$ genau dann wahr in der Welt $w$, wenn
$A$ in jeder von $w$ aus zugänglichen möglichen Welt wahr ist.
Es ist $\lpos A$ genau dann wahr in der Welt $w$, wenn $A$ in mindestens einer
von $w$ aus zugänglichen möglichen Welt wahr ist.

Die semantische Folgerung wird wieder in der herkömmlichen Form%
\[(\Gamma\models A)\,:\bicond\,\forall I\colon (I\models\Gamma)\cond (I\models A)\]
definiert. Ausgeschrieben lautet sie demnach
\[(\Gamma\models A)\,:\bicond\,\forall M\colon\forall w\in W(M)\colon
(M,w\models\Gamma)\cond (M,w\models A).\]
Man spricht gelegentlich auch von der \emph{lokalen} semantischen Folgerung,
um sie von einer weiteren, der selten diskutierten \emph{globalen} semantischen
Folgerung abgrenzen zu können. Zur Unterscheidung will ich die globale
Folgerung als $\models^g$ notieren. Man definiert sie als%
\[(\Gamma\models^g A)\,:\bicond\,\forall M\colon (M\models\Gamma)\cond (M\models A),\]
wobei $M\models A$ für $\forall w\in W(M)\colon (M,w\models A)$ stehen soll.

Ist $\Gamma$ die leere Menge, koinzidieren die lokale und die globale
Folgerung. Das heißt, $\emptyset\models A$ gilt genau dann, wenn
$\emptyset\models^g A$. Man schreibt wieder $\models A$ als Kurzform
von $\emptyset\models A$ und sagt dazu, die Formel $A$ sei
\emph{allgemeingültig}.

Bei der tieferen Untersuchung, welche Beziehungen zwischen Kalkül und
Semantik bestehen, zerlegt man eine Kripke"=Struktur $M=(W,R,V)$ in
die zwei Teile $F=(W,R)$ und $V$. Man nennt $F$ den \emph{Rahmen}.

Gezeigt werden muss nun die Korrektheit des natürlichen Schließens
für die Modallogik. Dies geschieht wieder per struktureller Induktion
über den Formelaufbau. Bei den herkömmlichen Schlussregeln verläuft der
Beweis identisch wie in der klassischen Semantik der Aussagenlogik.
Zu bestätigen verbleibt insofern lediglich noch die Korrektheit der
Nezessisierungsregel und die Allgemeingültigkeit des Axiomenschemas K.

\begin{Satz}
Aus $\models A$ folgt $\models\lnec A$.
\end{Satz}
\begin{Beweis}
Gemäß der Prämisse gilt $M,w'\models A$ für jedes $w'$. Demnach gilt
erst recht $R(w,w')\cond (M,w'\models A)$. Ergo gilt
$\models\lnec A$. Quod erat demonstrandum.\,\qedsymbol
\end{Beweis}

\begin{Satz}
Das Schema $\lnec(A\cond B)\cond (\lnec A\cond\lnec B)$ ist allgemeingültig.
\end{Satz}
\begin{Beweis}
Seien $M,w$ fest, aber beliebig. Zu zeigen ist
\[M,w\models\lnec(A\cond B)\cond (\lnec A\cond\lnec B),\]
was gemäß der Definition der Erfüllung äquivalent umgeformt wird zu%
\[(M,w\models\lnec(A\cond B))\cond (M,w\models\lnec A)\cond (M,w\models\lnec B).\]
Zu zeigen ist daher $M,w'\models B$ unter Annahme von $R(w,w')$ und%
\begin{gather*}
\forall w'\colon R(w,w')\cond (M,w'\models A\cond B),\\
\forall w'\colon R(w,w')\cond (M,w'\models A).
\end{gather*}
Die beiden Allaussagen werden mit $w'$ und $R(w,w')$ spezialisiert.
Laut der ersten Aussage $M,w'\models A\cond B$ folgt
$M,w'\models B$ aus $M,w'\models A$. Laut zweiten gilt $M,w'\models A$.
Ergo gilt $M,w'\models B$. Quod erat demonstrandum.\,\qedsymbol
\end{Beweis}

\subsection{Die Standardübersetzung}

Die relationale Semantik der diskutierten Modallogiken deutet bereits
an, dass Modallogik etwas mit der Logik erster Stufe zu tun haben müsste.
Es scheint, dass in gewisser Weise $\lnec A$ der Allquantifizierung,
und $\lpos A$ der Existenzquantifizierung entspricht. Die im Folgenden
beschriebene \emph{Standardübersetzung} modallogischer Formeln in die
Logik erster Stufe präzisiert diesen Gedankengang. Mithin stellen sich
die diskutierten Modallogiken als Spezialfälle der Logik erster Stufe
heraus. Auf diese Weise erhält man eine Möglichkeit, modallogische
Theoreme mit Beweisassistenten zu formulieren, die lediglich die
herkömmliche Logik verstehen.

Die Standardübersetzung ist rekursiv definiert als
\begin{align*}
&\mathrm{ST}_x(a) := P_a(x),
&& \mathrm{ST}_x(A\cond B) := \mathrm{ST}_x(A)\cond\mathrm{ST}_x(B),\\
&\mathrm{ST}_x(\lnot A) := \lnot\mathrm{ST}_x(A),
&& \mathrm{ST}_x(A\bicond B) := \mathrm{ST}_x(A)\bicond\mathrm{ST}_x(b),\\
&\mathrm{ST}_x(A\land B) := \mathrm{ST}_x(A)\land\mathrm{ST}_x(B),
&& \mathrm{ST}_x(\lnec A) := \forall y\colon R(x,y)\cond\mathrm{ST}_y(A),\\
& \mathrm{ST}_x(A\lor B) := \mathrm{ST}_x(A)\lor\mathrm{ST}_x(B),
&& \mathrm{ST}_x(\lpos A) := \forall y\colon R(x,y)\land\mathrm{ST}_y(A).
\end{align*}
Die Formeln $\bot,\top$ bleiben fix, also
$\mathrm{ST}_x(\bot) := \bot$ und $\mathrm{ST}_x(\top) := \top$.

Hierbei ist $R$ ein zweistelliges Prädikatsymbol, und $P_a$ zu
jedem $a$ ein einstelliges Prädikatsymbol. Eine Interpretation
$(M,w)$ mit Kripke"=Struktur $M=(W,R,V)$ und Welt $w\in W$
lässt sich als Interpretation $(M,\beta[x:=w])$ für die übersetzten
Formeln deuten, dergestalt dass das Symbol $P_a$ mit $w\mapsto V(w,a)$
interpretiert wird, und das Symbol $R$ mit der Zugänglichkeitsrelation
$R$. Demzufolge nimmt $W$ die Rolle des Diskursuniversums ein.
Die Belegung $\beta$ spielt keine Rolle, da $x$ die einzige freie
Variable ist. Man gelangt nun zum folgenden Resultat.
\begin{Satz}
Es gilt $M,w\models A$ genau dann, wenn $M,\beta[x:=w]\models\mathrm{ST}_x(A)$.
\end{Satz}
\begin{Beweis}
Per struktureller Induktion über den Formelaufbau von $A$.
Es sei $\beta\tfrac{w}{x}$ Kurzschreibweise für $\beta[x:=w]$. Den
Induktionsanfang liefert die Umformung
\[(M,w\models a) \iff V(w,a) \iff (M,\beta\tfrac{w}{x}\models P_a(x)).\]
Zur Formel $A\land B$ liegt die Äquivalenz von $M,w\models C$
und $M,\beta\tfrac{w}{x}\models\mathrm{ST}_x(C)$ jeweils für $C=A$
und $C=B$ als Induktionsvoraussetzung vor. Es findet sich hiermit
die äquivalente Umformung
\begin{align*}
(M,w\models A\land B) &\iff (M,w\models A)\land (M,w\models B)\\
&\iff (M,\beta\tfrac{w}{x}\models\mathrm{ST}_x(A))\land
(M,\beta\tfrac{w}{x}\models\mathrm{ST}_x(B))\\
&\iff M,\beta\tfrac{w}{x}\models\mathrm{ST}_x(A)\land\mathrm{ST}_x(B)\\
&\iff M,\beta\tfrac{w}{x}\models\mathrm{ST}_x(A\land B).
\end{align*}
Bei den restlichen herkömmlichen Junktoren verläuft die Argumentation
analog. Zur Formel $\lnec A$ liegt die Äquivalenz von $M,w'\models A$
und $M,\beta\tfrac{w'}{y}\models\mathrm{ST}_y(A)$ als
Induktionsvoraussetzung vor. Es findet sich hiermit die äquivalente
Umformung
\begin{align*}
(M,w\models\lnec A) &\iff \forall w'\colon R(w,w')\cond (M,w'\models A)\\
&\iff\forall w'\colon R(w,w')\cond (M,\beta\tfrac{w'}{y}\models\mathrm{ST}_y(A))\\
&\iff\forall w'\colon (M,\beta\tfrac{w}{x}\tfrac{w'}{y}\models R(x,y))
\cond (M,\beta\tfrac{w}{x}\tfrac{w'}{y}\models\mathrm{ST}_y(A))\\
&\iff (M,\beta\tfrac{w}{x}\models\forall y\colon R(x,y)\cond\mathrm{ST}_y(A))\\
&\iff (M,\beta\tfrac{w}{x}\models\mathrm{ST}_x(\lnec A)).
\end{align*}
Bei $\lpos A$ verläuft die Argumentation analog.\,\qedsymbol
\end{Beweis}

\noindent
Mithin gilt in unmittelbarer Konsequenz der
\begin{Satz}
Es gilt $\Gamma\models A$ genau dann, wenn
$\mathrm{ST}_x(\Gamma)\models\mathrm{ST}_x(A)$.
\end{Satz}
Vermittels dieser Äquivalenz erhält man sogleich den
\begin{Satz}
Aus $\vdash\mathrm{ST}_x(A)$ folgt $\models A$.
\end{Satz}
Kraft der Standardübersetzung in die Logik erster Stufe ergibt sich
insofern wie gewünscht ein alternativer korrekter Kalkül für die
diskutierten Modallogiken. Eine tiefergehende Untersuchung zur
Standardübersetzung findet man in \cite{Blackburn}.
