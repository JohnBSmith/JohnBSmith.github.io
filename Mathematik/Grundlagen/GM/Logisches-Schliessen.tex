
\chapter{Logisches Schließen}

\section{Grundbegriffe}

\subsection{Schlussregeln}

% Alles Schlussregeln und Axiome müssen unmittelbar einsichtig sein,
% müssen unbedenklich sein. Normalerweise will man in der Wissenschaft
% nicht so informell sein, aber hier sind wir am basalen Grund.
% Selbst in der Semantik wird der hier aufgestellte Formalismus
% benötigt. Der Korrektheitsbeweis würde somit zirkulär.

% Am Anfang ist noch nicht allzu viel zu rechnen. Wir müssen uns
% erst um die Schlussregeln und Axiome bemühen, bevor das erste Theorem
% bewiesen werden kann.

% Soll ich den Begriff Junktor nur für das Symbol verwenden,
% oder auch für die logische Verknüpfung/Operation?

% Subjunktion oder Konditional, Bijunktion oder Bikonditional?

Logisches Schließen findet in einzelnen Schritten statt. Ein Schritt
stellt hierbei immer die Ableitung einer Schlussfolgerung aus einer
oder mehreren Voraussetzungen dar. Die Voraussetzungen heißen
\emph{Prämissen}\index{Praemisse@Prämisse}, die Schlussfolgerung
\emph{Konklusion}\index{Konklusion}. Darstellen wollen wir den Schritt
durch eine waagerechte Linie, wobei die Prämissen oberhalb befindlich
sein sollen, und die Konklusion unterhalb. Der Schritt
\[\dfrac{\text{Wenn es regnet, wird die Straße nass}\qquad\text{Es regnet}}
{\text{Die Straße wird nass}}\]
beschreibt beispielsweise, dass aus den Prämissen »Wenn es regnet, wird
die Straße nass« und »Es regnet« die Konklusion »Die Straße wird nass«
gefolgert wird.

Schlüsse wie der Obige treten in der Mathematik ständig auf. Ihnen allen
liegt ein bestimmtes Muster zugrunde, welches sich durch eine als
\emph{Modus ponens}\index{Modus ponens} oder
\emph{Abtrennungsregel}\index{Abtrennungsregel}
bezeichnete schematische \emph{Schlussregel}\index{Schlussregel}
beschreiben lässt. Es bezeichne hierzu $A\cond B$ die Implikation
»wenn $A$, dann $B$«. Es dürfen nun in
\[\dfrac{A\cond B\qquad A}{B}\]
für $A,B$ beliebige Aussagen eingesetzt werden. So darf »Es regnet»
für $A$ und »Die Straße wird nass« für $B$ eingesetzt werden.

\subsection{Sequenzen}

Das Schließen von Aussagen allein genügt nicht. Um freier argumentieren
zu können, würden wir gerne den Umstand beschreiben können, dass eine
Aussage unter bestimmten Annahmen abgeleitet werden konnte. Diese
Annahmen $A_k$ sind selbst Aussagen. Wir fassen sie zu einer endlichen
Ansammlung
\[\Gamma := [A_1,A_2,\ldots,A_n]\]
zusammen, worunter wir eine endliche Liste, oder auch eine endliche
Menge verstehen wollen, denn man soll mit dieser Liste umgehen können
wie mit einer Menge. Das heißt, es ist nicht von Bedeutung, wie
oft eine Aussage vorkommt oder in welcher Reihenfolge die Aussagen
stehen. Man bezeichnet $\Gamma$ als die \emph{Antezedenz}%
\index{Antezedenz} oder die Liste der \emph{Antezedenzen}. Es wird
$\Gamma$ auch der \emph{Kontext}\index{Kontext}
oder die \emph{Umgebung}\index{Umgebung} genannt, das sind auf die
Typentheorie zurückzuführende Sprechweisen, die einen ganz ähnlichen
Formalismus besitzt. Wir bezeichnen die Symbolik \[\Gamma\vdash A\]
als \emph{Sequenz}\index{Sequenz}. Sie drückt das \emph{Urteil}%
\index{Urteil} aus, dass die Aussage $A$ aus den Annahmen
vermittels Schlussregeln ableitbar ist. Der Modus ponens%
\index{Modus ponens} wird nun in der allgemeinen Form
\[\dfrac{\Gamma\vdash A\cond B\qquad\Gamma\vdash A}{\Gamma\vdash B}\]
beschrieben. Wir argumentieren beim Schließen also ab jetzt nicht mehr
mit den Aussagen selbst, sondern mit den Sequenzen. Dies hat einen wichtigen
Grund, nämlich dass die Berücksichtigung der Abhängigkeit von Annahmen
expliziter Teil des Schließens wird.

Ein Kontext kann auch eine leere Liste sein. Besitzt eine vermittels
Schlussregeln ableitbare Sequenz einen leeren Kontext, so bezeichnet
man die Antezedenz als ein \emph{Theorem}\index{Theorem} im engeren
Sinne. Ein Theorem ist also eine Aussage, die für sich allein gilt,
ohne dass dafür irgendwelche Annahmen getroffen werden müssen.

Für Sequenzen gilt die \emph{Abschwächungsregel}%
\index{Abschwaechungsregel@Abschwächungsregel}. Sie besagt, dass
falls die Aussage $A$ bereits aus $\Gamma$ ableitbar ist, diese
Aussage erst recht ableitbar ist, wenn zu $\Gamma$ weitere Annahmen
$\Gamma'$ hinzugefügt werden. Kurzum gilt die Regel
\[\dfrac{\Gamma\vdash A}{\Gamma,\Gamma'\vdash A}.\]
Hierbei bedeutet $\Gamma,\Gamma'$ die Konkatenation der Listen
$\Gamma$ und $\Gamma'$, also im Wesentlichen dasselbe wie die
Vereinigung $\Gamma\cup\Gamma'$, insofern man die Kontexte als
Mengen betrachtet.

\subsection{Zulässige Schlussregeln}

Wiewohl die Regeln des Schließens den Mechanismus zum Beweis
von Aussagen bilden, ist ihre Rolle sogar noch ein wenig tiefgreifender.
Wir können sie nämlich ebenfalls zur Ableitung \emph{weiterer Regeln}
nutzen. Das heißt, wir können sie dazu nutzen, den logischen Kalkül
selbst zu erweitern. Erweiterungen dieser Art nennen wir
\emph{zulässige Schlussregeln}%
\index{zulaessige Schlussregel@zulässige Schlussregel}.

Mit den bisherigen Regeln ist bereits die zulässige Regel
\[\dfrac{\Gamma\vdash A\cond B\qquad\Gamma'\vdash A}
{\Gamma,\Gamma'\vdash B}\]
ableitbar, die eine allgemeinere Form des Modus ponens darstellt. Man
erhält sie kurzerhand, indem den Prämissen des Modus
ponens jeweils die Abschwächungsregel vorgesetzt wird:
\[\infer{\Gamma,\Gamma'\vdash B}{
  \infer{\Gamma,\Gamma'\vdash A\cond B}{\Gamma\vdash A\cond B}
& \infer{\Gamma,\Gamma'\vdash A}{\Gamma'\vdash A}}
\]
Die einfache Form des Modus ponens erhält man mit $\Gamma':=\Gamma$ als
Spezialfall unter Anwendung der Kontraktionsregel.

\subsection{Implikationseinführung}

Ich möchte mich nun der Frage zuwenden, wie eine Implikation $A\cond B$
bewiesen wird. Intuitiv ist hierzu aus der Annahme $A$ die
Aussage $B$ zu folgern. Das heißt, es genügt die Ableitung
der Sequenz $A\vdash B$. Ein weiteres Mal gilt es noch zu
berücksichtigen, dass ein Beweis auch auf einen vorausgesetzten
Kontext $\Gamma$ beschränkt sein dürfen soll. Reflektiert man darüber
eine Weile, dürfte es der Überlegung nach wohl genügen, dass $A$
einfach dem Kontext $\Gamma$ hinzugefügt wird, woraus $B$ zu folgern
ist. Man gelangt zur Regel
\[\dfrac{\Gamma,A\vdash B}{\Gamma\vdash A\cond B}.\]
Wer diese Regel nicht so leicht fassbar findet, insbesondere nicht
direkt plausibel, ob sie bedenkenlos eingesetzt werden darf, der
ist nicht allein. Es gibt auch logische Kalküle, die diese Regel nicht
explizit enthalten. Sie tritt dennoch als \emph{Deduktionstheorem} in
Erscheinung, ein metalogisches Theorem, dessen Beweis erst erbracht
werden muss. Ich möchte diesen Weg allerdings aus einem bestimmten Grund
nicht gehen. Nämlich ist beim Beweis eigentlich natürliches Schließen
auf der metalogischen Ebene zu verwenden, wenn dies auch in informaler
Weise stattfinden mag. Aber nicht jeder Leser weiß zu diesem Zeitpunkt,
wie akkurates logisches Schließen geht. Der Leser benötigt am Anfang
etwas, um sich an den eigenen Haaren aus dem Sumpf zu ziehen.

\subsection{Axiome}

Zur Komplettierung des Kalküls gesellen sich schließlich auch noch
\emph{Axiome}\index{Axiom} hinzu, das sind gemachte Grundannahmen, die
nicht weiter bewiesen werden müssen. Sie sollten daher möglichst
plausibel, oder besser noch zweifelsfrei einsichtig sein. Für die Logik
selbst genügt das Axiom
\[A\vdash A.\]
Der Kalkül funktioniert dergestalt, dass für $A$ eine beliebige Aussage
eingesetzt werden darf, worunter auch zusammengesetzte Aussagen
wie fallen. Eine gern gewählter Weg der Definition des logischen
Kalküls sieht $A$ als eine metasprachliche Variable, für die eine
beliebige Formel eingesetzt werden darf. Unter dieser Sichtweise
spricht man von einem \emph{Axiomenschema}\index{Axiomenschema}. Wie
eine Schablone produziert es für jede Einsetzung einer konkreten
logischen Formel ein eigenes Axiom.

Anstelle $A,B,C$ werden für metasprachliche Variablen zuweilen auch
die griechischen Buchstaben $\varphi,\psi,\chi$ benutzt. Man muss sie
von atomaren logischen Variablen unterscheiden, für die wir in diesem
Buch, um Missverständnissen aus dem Weg zu gehen, kleine Buchstaben
$a,b,c$ oder $p,q,r$ verwenden werden. Sprachlich suggestiv steht
$\varphi$ für \emph{Formel}\index{Formel} oder \emph{formula}, $a$ für
\emph{Aussage} und $p$ für \emph{proposition}.

In diesem Sinne sind auch die Schlussregeln Schemata. Sofern man
Schlussregeln mit null Prämissen gestattet, lässt sich das
Axiomenschema auch als Regel
\[\dfrac{}{A\vdash A}\]
auffassen. In dieser Weise wollen wir die Anwendung von Axiomen in den
Beweisbäumen darstellen.

Axiome in der Form von Sequenzen heißen auch
\emph{Grundsequenzen}\index{Grundsequenz}.

Wir haben nun die Mittel in der Hand, um erste Theoreme beweisen
zu können. Es ist $A\cond A$ ein Theorem. Der Beweisbaum ist:
\[
\infer[\infernote{Implikationseinführung}]{\vdash A\cond A}{
  \infer[\infernote{Axiom}]{A\vdash A}{}}
\]
Unter der Lesung, dass $A$ eine Metavariable ist, handelt es
eigentlich nicht nur um ein Theorem, sondern um ein Schema von
Theoremen. Setzt man für $A$ bspw. die konkrete Formel $p\cond q$
ein, bekommt man das konkrete Theorem
\[\vdash (p\cond q)\cond (p\cond q).\]
% Es ist zu bemerken, dass die Unterscheidung zwischen Metavariablen
% und atomaren logischen Variablen später durch die Einsetzungsregel
% mehr oder weniger hinfällig wird. Hierbei handelt es sich aber um eine
% höhere Überlegung, deren Beweis der Logiker erbringen will. In der
% Wissenschaft, insbesondere in der Logik, will man den Dingen auf den
% Grund gehen, will alles genau auseinandernehmen. Da möchte man bestimmte
% Regeln nicht einfach so als gegeben voraussetzen.

\subsection{Junktoren}

Bisher traten zusammengesetzte Aussagen alleinig in Form einer
Implikation auf. Will man logische Zusammenhänge beschreiben können,
muss die logische Sprache um weitere Junktoren bereichert werden.
Unter einem \emph{Junktor}\index{Junktor} versteht man eine logische
Verknüpfung von Aussagen zu einer zusammengesetzten Aussage.

Wir werden einen Junktor durch \emph{Einführungsregeln}%
\index{Einfuehrungsregel@Einführungsregel} und
\emph{Beseitigungsregeln}\index{Beseitigungsregel}
charakterisieren. Die Regeln der Implikation
wurden bereits beschrieben; die Einführung geschieht per
Implikationseinführung, die Beseitigung per Modus ponens.
Für die restlichen Junktoren der Aussagenlogik lassen sich die Regeln
wahlweise in Form von Axiomenschemata oder in Form von Schlussregeln
darstellen. Ich möchte das per Schemata machen, weil diese ein wenig
kompakter sind, was sie hoffentlich ein wenig leichter einsichtig macht.
Die entsprechenden Schlussregeln leiten wir anschließend als zulässige
Regeln ab.

Die Konjunktion\index{Konjunktion} $A\land B$, auch Und"=Verknüpfung
genannt, sprich »$A$ und $B$«, ist charakterisiert durch die Sequenzen
\[A,B\vdash A\land B;\qquad A\land B\vdash A;\qquad A\land B\vdash B.\]
Aus dem Fall von sowohl Regen als auch Schnee ist der Fall von
Schneeregen ableitbar. Aus dem Fall von Schneeregen ist der Fall
von Regen ableitbar. Aus dem Fall von Schneeregen ist der Fall
von Schnee ableitbar. So sind diese Sequenzen zu verstehen.

Die Einführung der Konjunktion geschieht mit der Regel
\[\dfrac{\Gamma\vdash A\qquad\Gamma'\vdash B}{\Gamma,\Gamma'\vdash A\land B}.\]
Denn es findet sich der Beweisbaum:
\[
\infer[\infernote{MP}]{\Gamma,\Gamma'\vdash A\land B}{
  \infer[\infernote{MP}]{\Gamma\vdash B\cond A\land B}{
    \infer[\infernote{Impl-Einf.}]{\vdash A\cond (B\cond A\land B)}{
      \infer[\infernote{Impl-Einf.}]{A\vdash B\cond A\land B}{
        \infer[\infernote{Axiom}]{A,B\vdash A\land B}{}}}
  & \Gamma\vdash A}
& \Gamma'\vdash B}
\]
Es steht MP als Abkürzung für Modus ponens, und Impl-Einf. für
Implikationseinführung. Man schreibt alternativ auch das Kürzel
$\cond$E anstelle Impl-Einf. und das Kürzel $\cond$B anstelle
von MP. Hierbei steht E offenkundig für \emph{Einführung} und
B für \emph{Beseitigung}. Aber Vorsicht, in der englischsprachigen
Literatur sind das I für \emph{introduction} und E für
\emph{elimination}.

Die beiden Regeln zur Beseitigung der Konjunktion sind
\[\dfrac{\Gamma\vdash A\land B}{\Gamma\vdash A},
\qquad\dfrac{\Gamma\vdash A\land B}{\Gamma\vdash B}.\]
Denn es findet sich:
\[
\infer[\infernote{MP}]{\Gamma\vdash A}{
  \infer[\infernote{Impl-Einf.}]{\vdash A\land B\cond A}{
    \infer[\infernote{Axiom}]{A\land B\vdash A}{}}
& \Gamma\vdash A\land B}
\]
Die Disjunktion\index{Disjunktion} $A\lor B$, auch Oder"=Verknüpfung
genannt, sprich »$A$ oder $B$«, ist charakterisiert durch die Sequenzen
\[A\vdash A\lor B;\qquad B\vdash A\lor B;\qquad
A\lor B, (A\cond C), (B\cond C)\vdash C.\]
So ist »Die Erde des Beetes ist nass« ableitbar aus »Es hat geregnet
oder das Beet wurde gegossen«. Denn sowohl »Es hat geregnet« als auch
»Das Beet wurde gegossen« impliziert »Die Erde des Beetes ist nass«.

Die beiden Regeln zur Einführung der Disjunktion sind
\[\dfrac{\Gamma\vdash A}{\Gamma\vdash A\lor B},\qquad
\dfrac{\Gamma\vdash B}{\Gamma\vdash A\lor B}.\]
Die Regel zur Beseitigung der Disjunktion ist
\[\dfrac{\Gamma\vdash A\lor B\qquad\Gamma',A\vdash C\qquad\Gamma'',B\vdash C}
{\Gamma,\Gamma',\Gamma''\vdash C}.\]
Die Beweise dieser Regeln seien dem Leser überlassen.

Eine Aussage wie »Bertram wird seine Hausaufgaben nicht machen«
formuliert man gern in der Form »Wenn Bertram seine Hausaufgaben macht,
färbt sich der Mond grün«. In gleichartiger Weise lässt sich die
Verneinung auch in der formalen Logik definieren. Hierzu legt man als
Hilfsbegriff zunächst $\bot$ als die \emph{Kontradiktion}%
\index{Kontradiktion} fest, sie steht für eine widersprüchliche Formel.

Die Negation\index{Negation} $\lnot A$, auch Verneinung genannt, sprich
»nicht $A$«, definiert man als identisch mit $A\cond\bot$. Hierdurch
sind die Regeln zu ihrer Einführung und Beseitigung auf die der
Implikation zurückführbar. Es ergibt sich
\[\dfrac{\Gamma,A\vdash\bot}{\Gamma\vdash\lnot A},
\qquad\dfrac{\Gamma\vdash\lnot A\qquad\Gamma'\vdash A}
{\Gamma,\Gamma'\vdash\bot}.\]
Alternativ ließe sich die Negation durch die Sequenzen
\[(A\cond\bot)\vdash\lnot A;\qquad A,\lnot A\vdash\bot\]
charakterisieren. Man überzeuge sich, dass dies aufs selbe hinausläuft.

Die Äquivalenz\index{Aequivalenz@Äquivalenz} $A\bicond B$, sprich
»$A$ genau dann, wenn $B$«, definiert man als identisch mit
$(A\cond B)\land (B\cond A)$. Insofern sind die Regeln zu ihrer
Einführung und Beseitigung auf die der Konjunktion zurückführbar.
Es ergibt sich
\[\dfrac{\Gamma\vdash A\cond B\qquad\Gamma'\vdash B\cond A}
{\Gamma,\Gamma'\vdash A\bicond B},\qquad
\dfrac{\Gamma\vdash A\bicond B}{\Gamma\vdash A\cond B},\qquad
\dfrac{\Gamma\vdash A\bicond B}{\Gamma\vdash B\cond A}.\]
Die entsprechenden charakterisierenden Sequenzen sind
\[(A\cond B),(B\cond A)\vdash A\bicond B;\qquad (A\bicond B),A\vdash B;
\qquad (A\bicond B),B\vdash A.\]

\subsection{Quantoren}

Eine logische Sprache, die der freien Formulierung mathematischer
Zusammenhänge dienlich sein soll, muss hinreichend reichhaltig sein.
Ebenfalls schrieb der Philosoph Ludwig Wittgenstein in seinem
\emph{Tractatus} den ähnlichen Gedanke »Die Grenzen meiner Sprache
bedeuten die Grenzen meiner Welt.« Bislang fehlt das wichtige Konzept
der Quantifizierung, das die Aussagenlogik zur Prädikatenlogik
erweitert.

In der Prädikatenlogik treten \emph{Aussageformen}\index{Aussageform}
auf. Das sind Formeln, die \emph{freie Variablen}\index{freie Variable}
enthalten. Erst wenn jede der freien Variablen mit einem Wert belegt
wird, entsteht eine Aussage. Außerdem treten Quantoren auf. Ein
\emph{Quantor}\index{Quantor} bindet eine freie Variable, und macht
eine Aussageform dabei ebenfalls zu einer bestimmten Aussage.

Es sei $A(x)$ eine Aussageform mit der freien Variable $x$. Anstelle
von $A(x)$ schreibt man auch kurzum $A$. Anstelle von $A(t)$ schreibt
man auch $A[x:=t]$ oder $A[t/x]$, womit die Ersetzung jedes Vorkommens
von $x$ durch den Term $t$ gemeint ist. Genauer gesagt die Ersetzung
jedes \emph{freien} Vorkommens, wobei man außerdem einer möglichen
Überschattung einer der in $t$ enthaltenen Variablen aus dem Weg gehen
muss. Diese Spitzfindigkeiten tauchen allerdings erst auf, wenn man mit
Verschachtelungen von Quantoren hantiert. Ich will später
genauer darauf eingehen.

Die wesentlichen beiden Quantoren sind der \emph{Allquantor}%
\index{Allquantor}\index{Universalquantor} $\forall$ und der
\emph{Existenzquantor}\index{Existenzquantor} $\exists$. Man ließt
$\forall x\colon A(x)$ als »für alle $x$ gilt $A(x)$« oder »jedes $x$
hat die Eigenschaft $A(x)$«. Man ließt $\exists x\colon A(x)$ als »es
gibt mindestens ein $x$, für das $A(x)$ gilt« oder »mindestens ein $x$
hat die Eigenschaft $A(x)$«.

Quantifiziert wird immer über ein bestimmtes \emph{Diskursuniversum}%
\index{Diskursuniversum}. Darunter versteht man die Gesamtheit der
Objekte, auf die sich »für alle« und »es gibt« bezieht. Um bestimmten
Komplikationen aus dem Weg zu gehen, muss es nichtleer sein. Zur
Veranschaulichung des Übergangs von der Aussagenlogik zur Prädikatenlogik
wählen wir ein endliches, das lediglich die Zahlen von eins bis vier
enthält. Die Aussage $\forall x\colon A(x)$ bedeutet nun insofern
dasselbe wie
\[A(1)\land A(2)\land A(3)\land A(4).\]
Diese schlichte Konjunktion gibt Anlass zu der Schlussregel
\[\dfrac{\Gamma\vdash\forall x\colon A(x)}{\Gamma\vdash A(t)}.
\qquad(\text{$t$ muss eine der Zahlen von eins bis vier sein})\]
Die Beseitigung der Allquantifizierung darf insofern als Analogon zur
Beseitigung der Konjunktion verstanden werden.

Im Fortgang soll $\Gamma\vdash A(a)$ bedeuten, dass die Aussageform
$A(a)$ aus dem Kontext $\Gamma$ ableitbar ist, wobei $a$ beliebig
gelassen wird. Man leitet die vier Sequenzen
\[\Gamma\vdash A(1);\quad\Gamma\vdash A(2);\quad\Gamma\vdash A(3);
\quad\Gamma\vdash A(4)\]
sozusagen in einen Zug ab. Es stellt sich nun die Frage
\[\dfrac{\Gamma\vdash A(a)}{\Gamma\vdash\forall x\colon A(x)}?\]
Betrachten wir dazu $a=1\vdash A(a)$. Mit der bedenklichen Regel erhielte
man aus ihr $a=1\vdash\forall x\colon A(x)$. Diese trifft insbesondere
im Fall $a:=1$ zu. Nun braucht man $1=1$ nicht vorauszusetzen, womit
man $\vdash\forall x\colon A(x)$ erhält. Den Quantor beseitigen
wir nun noch mit $x:=a$, und erhalten $\vdash A(a)$. Die Annahme
wurde also aus der Sequenz herausgemogelt. Um dies zu unterbinden,
legen wir fest, dass $a$ keine freie Variable einer der Antezedenzen
sein darf.

Die Regel zur Einführung ist demnach zu formulieren als
\[\dfrac{\Gamma\vdash A(a)}{\Gamma\vdash\forall x\colon A(x)}
(a\notin\mathrm{FV}(\Gamma,\forall x\colon A(x))).\]
Hierbei steht die Symbolik $\mathrm{FV}(\Gamma)$ für die Menge der
freien Variablen von $\Gamma$. Mit elementarer Mengenlehre definiert
man sie präzise als Rekursion über den Formelaufbau. Man legt fest
\begin{gather*}
\mathrm{FV}(A\land B) = \mathrm{FV}(A\lor B)
= \mathrm{FV}(A\cond B) = \mathrm{FV}(A\bicond B)
= \mathrm{FV}(A)\cup\mathrm{FV}(B),\\
\mathrm{FV}(\lnot A) = \mathrm{FV}(A),\quad
\hspace{13pt}\mathrm{FV}(\forall x\colon A) = \mathrm{FV}(\exists x\colon A)
= \mathrm{FV}(A)\setminus\{x\},\\
\mathrm{FV}(\bot) = \mathrm{FV}(\top) = \emptyset,\quad
\mathrm{FV}(P(t_1,\ldots,t_n)) = \mathrm{FV}(t_1)\cup\ldots\cup\mathrm{FV}(t_n).
\end{gather*}
Hierbei steht $P$ für ein $n$-stelliges Prädikat. Und es ist $\mathrm{FV}(t)$
die Menge der Variablen des Terms $t$. Man legt sie abermals
rekursiv fest als
\begin{gather*}
\mathrm{FV}(t_1+t_2) = \mathrm{FV}(t_1-t_2) = \mathrm{FV}(t_1\cdot t_2)
= \mathrm{FV}(t_1)\cup\mathrm{FV}(t_2),\\
\mathrm{FV}(-t)=\mathrm{FV}(t),\quad
\mathrm{FV}(v)=\{v\},\quad\mathrm{FV}(c) = \emptyset,
\end{gather*}
wobei $v$ für eine Variable und $c$ für eine Konstante steht.

Die Aussage $\exists x\colon A(x)$ ist gleichwertig mit
\[A(1)\lor A(2)\lor A(3)\lor A(4).\]
Diese Perspektive gibt Anlass zur Einführungsregel
\[\dfrac{\Gamma\vdash A(t)}{\Gamma\vdash\exists x\colon A(x)}.\quad
(\text{$t$ muss eine der Zahlen von eins bis vier sein})\]
Bei der Beseitigung müssen wir nun gewissermaßen eine Fallunterscheidung
in die vier Fälle vornehmen und bestätigen, dass jeder Fall dieselbe
Aussage $B$ impliziert. Dies soll allerdings parametrisch in einer
einzigen Ableitung stattfinden. Man gelangt zu
\[\dfrac{\Gamma\vdash\exists x\colon A(x)\qquad\Gamma',A(a)\vdash B}
{\Gamma,\Gamma'\vdash B}(a\notin\mathrm{FV}(\Gamma,\Gamma',B,\exists x\colon A(x))).\]
Diese Regel wird wie folgt interpretiert. Mit der Existenzaussage
$\exists x\colon A(x)$ liegt ein Zeuge $a$ mit $A(a)$ vor. Unter
Verwendung von $A(a)$ wird nun eine Aussage $B$ abgeleitet, in der $a$
nicht frei vorkommt. Somit gilt $B$ unabhängig vom gewählten Zeugen,
was notwendig ist, da unbekannt bleibt, welcher der Zahlen von eins
bis vier als Zeuge vorliegt.

Ohne die Bedingung an $a$ ließe sich leicht Schabernack vollführen.
Man könnte beispielsweise kurzerhand eine Existenzaussage zu einer
Allaussage machen:
\[\infer{\vdash\forall x\colon A(x)}{
  \infer{\vdash A(a)}{
    \vdash \exists x\colon A(x)
  & \infer{A(a)\vdash A(a)}{}}}\]
Abschließend verbleibt noch näher zu erläutern, wie Substitution
vonstatten geht. Ersetzt wird nur jedes freie Vorkommen einer
Variablen. Ein durch einen Quantor gebundenes Vorkommen der Variable
bleibt dagegen erhalten. So resultiert die Substitution
\[(A(x)\land\forall x: B(x))[x:=y]\quad\text{in}\quad
A(y)\land\forall x\colon B(x).\]
Außerdem darf es bei einer Substitution nicht zu einer Überschattung
durch eine gebundene Variable kommen. Die Substitution
\[(\forall y\colon A(x)\land B(y))[x:=y]\]
darf beispielsweise nicht direkt ausgeführt werden. Man geht der
Überschattung aus dem Weg, indem die gebundene Variable $y$ zuerst
in eine frische, nehmen wir $z$, umbenannt wird. Das Resultat der
Substitution ist also
\[\forall z\colon A(y)\land B(z),\quad\text{nicht}\quad
\forall y\colon A(y)\land B(y).\]

\subsection{Zur Syntax}

So wie »Punktrechnung vor Strichrechnung« gilt, legt man für jeden
Junktor zur Einsparung von Klammern eine Stufe der Priorität fest. In
absteigender Rangfolge sind dies ${\lnot}, {\land}, {\lor}, {\cond},
{\bicond}$. So wird die Formel
\[\lnot A\land B\lor C\cond D\quad\text{gelesen als}\quad
(((\lnot A)\land B)\lor C)\cond D.\]
Weiterhin legt man die Implikation als rechtsassoziativ fest. So
wird
\[A\cond B\cond C\quad\text{gelesen als}\quad A\cond (B\cond C).\]
Wie den Junktoren kommt auch den Quantoren eine Rangstufe zu. Weil
diese aber präfix sind, ist bei ihnen lediglich die rechte Seite zu
berücksichtigen. Hier sind zwei Varianten verbreitet. In der
Schreibweise $(\forall x)A(x)$ oder kurz $\forall xA(x)$ haben
sie wie die Verneinung die höchste Rangstufe. In der Schreibweise
$\forall x\colon A(x)$ oder $\forall x.\, A(x)$ dagegen die niedrigste,
also eine Stufe niedriger als das Bikonditional, so dass alles
hinter dem Doppelpunkt in den Wirkungsbereich des Quantors fällt.
So wird
\[\forall x\colon A(x)\land B\cond C\quad\text{gelesen als}\quad
\forall x\colon ((A(x)\land B)\cond C).\]
Manche Schüler haben Schwierigkeiten, die Struktur von Termen zu
durchschauen. Infolge kann es bei ihnen zu Flüchtigkeitsfehlern
bei der Ersetzung von Variablen durch Terme kommen. Sie vergessen,
dass ein Term vor der Einfügung zunächst geklammert werden muss.
Erst die Operatorrangfolge gewährt es, die Klammern unter Umständen
nachträglich entfallen zu lassen. Für diese Schüler mag es förderlich
sein, einen Term als \emph{abstrakten Syntaxbaum} darzustellen.
Gleichermaßen verhält es sich mit der Programmiersprache Lisp, die
Terme als Schachtelung von Listen darstellt, deren Klammern
obligatorisch sind.  Die Aussage $A\land B\cond C$ ist beispielsweise
beschreibbar als
\[\text{\texttt{(implies (and A B) C)}}.\]
Im Wesentlichen veranschaulicht diese Schachtelung
nichts anderes als den abstrakten Syntaxbaum. Man kann gewissermaßen
sagen, dass Lisp eine Programmiersprache ohne Syntax ist. Fast ohne,
im höheren Sinne ohne.

Um sich unmissverständlich auszudrücken, formalisieren Logiker die
logische Sprache gern. Es wird hierzu eine \emph{formale Sprache} spezifiziert,
was vermittels sogenannter \emph{Produktionsregeln} gemacht werden kann.
Insofern Produktionsregeln etwas kryptisch anmuten mögen, beschreiben
Logiker die syntaktische Struktur auch in Worten.
Für die Aussagenlogik üblicherweise folgendermaßen.

\begin{enumerate}\setlength\itemsep{0em}
\item Die atomaren Variablen $a,b,c$ usw. sind Formeln.
\item Die Symbole $\bot,\top$ sind Formeln.
\item Ist $\lnot A$ eine Formel, so ist auch $(\lnot A)$ eine.
\item Sind $A,B$ Formeln, so ist auch $(A\land B)$ eine.
\item Sind $A,B$ Formeln, so ist auch $(A\lor B)$ eine.
\item Sind $A,B$ Formeln, so ist auch $(A\cond B)$ eine.
\item Sind $A,B$ Formeln, so ist auch $(A\bicond B)$ eine.
\item Nichts anderes ist eine Formel.
\end{enumerate}

\noindent
Schreibt man viele logische Formeln auf, drängt es, zumindest bei privaten
Notizen und Rechnungen, nach Kurzschreibweisen. In der Logik ist für das
Konditional $A\cond B$ auch die Schreibweise $A\rightarrow B$ gebräuchlich,
für das Bikonditional $A\bicond B$ entsprechend $A\leftrightarrow B$.
Insbesondere in der Schaltalgebra schreibt man auch $\overline A$
anstelle von $\lnot A$, und $AB$ anstelle von $A\land B$ sowie $A+B$
anstelle von $A\lor B$. Hierbei darf die Disjunktion $A+B$ allerdings
nicht mit der Kontravalenz $A\oplus B$ verwechselt werden. Für die
Quantifizierung $\forall x\colon A(x)$ bietet sich $\forall_x A_x$ oder
$\forall x.\, A_x$ als kurzschriftliche Form an.

\newpage
\section{Natürliches Schließen}

\subsection{Darstellungsformen}

Abgeleitet werden soll das Theorem
\[\vdash (A\cond B)\cond (\lnot B\cond\lnot A).\]
Meine favorisierte und in diesem Buch genutzte Form der Darstellung
des natürlichen Schließens fügt die aus den Schlussregeln erhaltenen
Schlüsse wie Legosteine zu einem Baum zusammen, dem
\emph{Beweisbaum}\index{Beweisbaum} oder \emph{Herleitungsbaum}.
Im Eigentlichen stehen in den Blättern die Grundsequenzen, und in der
Wurzel das Theorem. Wie wir es bereits getan haben, arbeitet man
allerdings auch mit Exemplaren, die irgendwelche Sequenzen in
irgendwelche Sequenzen überführen, womit man zulässige Schlussregeln
erhält. Allgemeiner ginge ferner die Formulierung als gerichteter
azyklischer Graph, die bei einigen Beweisen ein wenig den
Schreibaufwand reduzieren würde.

Der Beweisbaum genannten Theorems ist:
\[
\infer[\infernote{$\cond$E}]{\vdash (A\cond B)\cond (\lnot B\cond\lnot A)}{
  \infer[\infernote{$\cond$E}]{A\cond B\vdash \lnot B\cond\lnot A}{
    \infer[\infernote{$\lnot$E}]{A\cond B, \lnot B\vdash\lnot A}{
      \infer[\infernote{$\lnot$B}]{A\cond B, \lnot B, A\vdash\bot}{
        \infer[\infernote{Axiom}]{\lnot B\vdash\lnot B}{}
      & \infer[\infernote{$\cond$B}]{A\cond B, A\vdash B}{
          \infer[\infernote{Axiom}]{A\cond B\vdash A\cond B}{}
        & \infer[\infernote{Axiom}]{A\vdash A}{}}}}}}
\]
Die Ausformulierung der Sequenzen verlangt langwieriges erneutes
Aufschreiben der Antezedenzen. Sobald man das Prozedere einmal
verstanden hat, erscheint es überausführlich. Man kann sich daher
verkürzte Darstellungen der Beweisbäume überlegen:
\[
\begin{tabular}{@{}l@{\qquad\quad}l}
\infer{\vdash (A\cond B)\cond (\lnot B\cond\lnot A)}{
  \infer{2\vdash \lnot B\cond\lnot A}{
    \infer{1, 2\vdash\lnot A}{
      \infer{1, 2, 3\vdash\bot}{
        \infer{1\equiv\lnot B}{}
      & \infer{2, 3\vdash B}{
          \infer{2\equiv A\cond B}{}
        & \infer{3\equiv A}{}}}}}}
&
\infer[\infernote{$\sim$2}]{(A\cond B)\cond (\lnot B\cond\lnot A)}{
  \infer[\infernote{$\sim$1}]{\lnot B\cond\lnot A}{
    \infer[\infernote{$\sim$3}]{\lnot A}{
      \infer{\bot}{
        \infer[\infernote{1}]{\lnot B}{}
      & \infer{B}{
          \infer[\infernote{2}]{A\cond B}{}
        & \infer[\infernote{3}]{A}{}}}}}}
\end{tabular}
\]
Die linke Form kürzt die Antezedenzen durch Nummern ab. In der rechten
Form entfallen die Antezedenzen vollständig. Stattdessen tauchen sie
als in den Blättern gemachte nummerierte \emph{Annahmen} auf, die im
Fortgang zur Wurzel irgendwann zu tilgen sind. Ihre Tilgung erscheint
nun als Randnotiz.

Eine weitere, sehr systematische Darstellung setzt den Beweis aus
einer Liste von Tabellenzeilen zusammen. Allerdings ist sie ein wenig
mühevoll zu lesen. Jede Zeile enthält eine Aussage und dahinter
zusätzlich die Information, wie und woraus die Aussage abgeleitet wurde.
Jede der Aussagen bekommt eine Nummer, siehe Tabelle \ref{tab:Kontraposition}.
Die Nummerierung der Abhängigkeiten ist in derselben Reihenfolge wie
zuvor bei den Bäumen angegeben. Wer die Liste genauer betrachtet, erkennt,
dass die jeweilige Zeile nichts anderes als die Sequenz
$\text{Abh.}\vdash\text{Nr.}$ darstellt.

\begin{table}
\begin{center}
\caption{Beweis in Form einer Liste von Tabellenzeilen}
\label{tab:Kontraposition}
\begin{tabular}{cclll}
\toprule
\strong{Abh.} & \strong{Nr.} & \strong{Aussage} & \strong{Regel} & \strong{auf}\\
\midrule[\heavyrulewidth]
1 & 1 & $\lnot B$ & Axiom &\\
2 & 2 & $A\cond B$ & Axiom &\\
3 & 3 & $A$ & Axiom &\\
2, 3 & 4 & $B$ & $\cond$B & 2, 3\\
1, 2, 3 & 5 & $\bot$ & $\lnot$B & 1, 4\\
1, 2 & 6 & $\lnot A$ & $\lnot$E & 5\\
2 & 7 & $\lnot B\cond\lnot A$ & $\cond$E & 6\\
$\emptyset$ & 8 & $(A\cond B)\cond(\lnot B\cond\lnot A)$ & $\cond$E & 7\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

Unabhängig von Gentzen entwickelte Jaśkowski das natürliche Schließen
einige Jahre zuvor. Während Gentzen Beweise als Bäume darstellte, nutzte
Jaśkowski zunächst eine grafische Darstellung, die später von Fitch
adaptiert wurde und in dieser Form nun als \emph{Fitch"=Style}%
\index{Fitch-Style} bekannt ist.

Zu guter Letzt muss die klassische Darstellung der Beweisführung
aufgeführt werden. Die in Worten. Sie zeichnet sich durch die Auslassung
mühseliger technischer Details und blumige Formulierungen aus,
soll aber genug Information enthalten, dass der Leser im Zweifel
eine Formalisierung des Beweises erstellen und verifizieren kann.

\begin{Satz}
Es gilt $(A\cond B)\cond (\lnot B\cond\lnot A)$.
\end{Satz}
\strong{Beweis.} Aus der Annahme von sowohl $A\cond B$ als
auch $\lnot B$ als auch $A$ ist ein Widerspruch abzuleiten.
Man erhält $B$ zunächst per Modus ponens aus $A\cond B$ und $A$.
Nun steht $\lnot B$ bereits im Widerspruch zu $B$.\,\qedsymbol

Als komfortablen Bonus erhält man mit dem Theorem nun im Anschluss
kurzerhand eine weitere zulässige Regel, die
\emph{Kontraposition}\index{Kontraposition}
\[\dfrac{\Gamma\vdash A\cond B}{\Gamma\vdash\lnot B\cond\lnot A},
\quad\text{denn}\quad
\dfrac{\vdash (A\cond B)\cond (\lnot B\cond\lnot A)\quad\Gamma\vdash A\cond B}
{\Gamma\vdash \lnot B\cond\lnot A}.\]
Fügt man ihr den Modus ponens an, findet sich der
\emph{Modus tollens}\index{Modus tollens}
\[\dfrac{\Gamma\vdash A\cond B\qquad\Gamma'\vdash\lnot B}
{\Gamma,\Gamma'\vdash\lnot A}.\]

\section{Bemerkungen zur Beweisführung}

\subsection{Widerspruchsbeweise}

Beim \emph{Beweis durch Widerspruch} widerlegt man eine Aussage, indem
gezeigt wird, dass die Annahme der Aussage zu einem logischen
Widerspruch führt. In manchen Situationen bietet diese Art der
Argumentation eine große Hilfe. So schreibt der britische Mathematiker
Godfrey Harold Hardy in seinem Essay \emph{A Mathematician's Apology}
die Worte
\begin{quote}
»The proof is by \emph{reductio ad absurdum}, and \emph{reductio ad
absurdum}, which Euclid loved so much, is one of a mathematician's
finest weapons. It is a far finer gambit than any chess gambit: a chess
player may offer the sacrifice of a pawn or even a piece, but a
mathematician offers \emph{the game}.«
\end{quote}
Zur Schaffung von Klarheit muss man zunächst zwei inhaltlich
verschiedene Arten des Widerspruchsbeweises unterscheiden.
Präzisieren lässt sich diese Unterscheidung anhand
der Regeln
\[\dfrac{\Gamma,A\vdash\bot}{\Gamma\vdash\lnot A},\qquad
\dfrac{\Gamma,\lnot A\vdash\bot}{\Gamma\vdash A}.\]
Die linke Regel stellt die stets verfügbare Negationseinführung dar,
die man auch als \emph{Widerlegung durch Widerspruch} bezeichnen kann.
In der rechten Regel, der klassischen \emph{Reductio ad absurdum},
gelangt man zunächst per Negationseinführung von
$\Gamma,\lnot A\vdash\bot$ zu $\Gamma\vdash\lnot\lnot A$, und daraufhin
zu $\Gamma\vdash A$. Die Beseitigung der Doppelnegation ist allerdings
lediglich in der klassischen Logik verfügbar, in der intuitionistischen
gilt sie dagegen als unzulässig.

Manche stellen die Regeln in einer Form dar, in der die Kontradiktion
nicht explizit auftaucht. Wir erhalten sie als zulässige Regeln, indem
der Einführung der Kontradiktion direkt ihre Beseitigung
angeschlossen wird. Es findet sich
\[\dfrac{\Gamma,A\vdash\lnot B\qquad\Gamma'\vdash B}
{\Gamma,\Gamma'\vdash\lnot A},\qquad
\dfrac{\Gamma,\lnot A\vdash\lnot B\qquad\Gamma'\vdash B}
{\Gamma,\Gamma'\vdash A}.\]
Wie zuvor ist die linke Form allgemein verfügbar, die rechte dagegen
nur bei Vorhandensein der Beseitigung der Doppelnegation.

\subsection{Klassische Kontraposition}

Eine weitere Regel ist die umgekehrte Kontraposition
\[\dfrac{\Gamma\vdash\lnot A\cond\lnot B}{\Gamma\vdash B\cond A}.\]
Sie verlangt ebenfalls die klassische Logik. Mit ihr lässt sich
nämlich die klassische Reductio ad absurdum herleiten:
\[
\infer[\infernote{Kürzung der Tautologie}]{\Gamma\vdash A}{
  \infer[\infernote{Modus ponens}]{\Gamma,\top\vdash A}{
    \infer[\infernote{bedenklich}]{\Gamma\vdash\top\cond A}{
      \infer[\infernote{Impl-Einf.}]{\Gamma\vdash\lnot A\cond\lnot\top}{
        \infer[\infernote{Neg-Einf.}]{\Gamma,\lnot A\vdash\lnot\top}{
          \infer[\infernote{Abschwächung}]{\Gamma,\lnot A,\top\vdash\bot}{
            \Gamma,\lnot A\vdash\bot}}}}
  & \infer[\infernote{Axiom}]{\top\vdash\top}{}}}
\]
Weil alle anderen Schlüsse unbedenklich sind, kann die umgekehrte
Kontraposition als der bedenkliche Schritt identifiziert werden.
In der klassischen Logik ist sie allerdings zulässig. Die Herleitung
unter Verwendung der Beseitigung der Doppelnegation sei dem Leser
überlassen. Als kleiner Tipp sei aber gegeben, dass die Einführung
der Doppelnegation unter allen Umständen zulässig ist, wie man sich
unschwer überzeugt.

Wir schreiben die Abkürzungen DNE für die Beseitigung der
Doppelnegation, LEM für den Satz vom ausgeschlossenen Dritten
und EFQ für Ex falso quodlibet. Eine Alternative zu DNE bietet
LEM zuzüglich EFQ. Manche Beweise verkürzen sich damit, andere
verlängern sich. Tatsächlich lässt sich DNE aus LEM zuzüglich EFQ
herleiten. Umgekehrt lässt sich sowohl LEM als auch EFQ aus DNE
herleiten. Es tut sich die Frage auf, ob sich EFQ aus LEM herleiten
lässt. Die Antwort darauf lautet nein. Eine ausführliche Untersuchung
findet man in \cite{Diener}.

\subsection{Notwendige und hinreichende Bedingungen}

Manchmal trifft man auf die Ausdrucksweise, eine Bedingung $B$ sei für
eine Aussage $A$ notwendig. Sie sagt aus, dass $\lnot B$ zu $\lnot A$
führt. Falls die Bedingung verletzt ist, kann die Aussage unmöglich
gelten. Es liegt demnach die Implikation $\lnot B\cond\lnot A$ vor.
Sie wird im Sinne der klassischen Logik verstanden. Man hat also
\[(A\cond B) \iff (\text{$B$ ist notwendig für $A$}).\]
Die Ausdrucksweise, eine Bedingung $B$ sei für $A$ hinreichend,
sagt aus, dass $B$ die Aussage $A$ bereits nach sich zieht. Es liegt
demnach die Implikation $B\cond A$ vor. Man hat also
\[(B\cond A) \iff (\text{$B$ ist hinreichend für $A$}).\]
Ist eine Bedingung $B$ sowohl notwendig als auch hinreichend für $A$,
liegt eine Äquivalenz vor. Man hat also
\[(A\bicond B) \iff (\text{$B$ ist notwendig und hinreichend für $A$}).\]

\section{Logik mit Gleichheit}

\subsection{Axiome der Gleichheit}

Moderne Formulierungen charakterisieren die Gleichheit durch die Axiome
\begin{align*}
&\vdash\forall x\colon x=x, &&\text{(Reflexivität)}\\
&\vdash\forall x\colon\forall y\colon x=y\cond A(x)\cond A(y).
&&\text{(Ersetzung)}
\end{align*}
Das zweite Axiom ist eigentlich ein Schema, weil dieses für jede
Formel $A$ gilt. Es meint $A(a)$ eine Aussageform, wobei $A(t)$ als
$A(a)[a:=t]$ zu verstehen sein soll. Man gewinnt aus dem Schema
kurzerhand die Regel
\[\dfrac{\Gamma\vdash t=t'\qquad\Gamma'\vdash A(t)}
{\Gamma,\Gamma'\vdash A(t')}.\qquad\text{($t,t'$ sind beliebige Terme)}\]
Das erste Axiom charakterisiert insofern die Regel zur Einführung
der Gleichheit, das zweite die Regel zur Beseitigung. Die Symmetrie
der Gleichheit lässt sich aus den beiden Regeln ableiten. Sei hierzu
$A(a):\equiv (a=x)$. Nun ist $A(x)\equiv (x=x)$ und
$A(y)\equiv (y=x)$. Man setze $t:=x$ und $t':=y$. Es findet sich:
\[
\infer{x=y\vdash y=x}{
  \infer{x=y\vdash x=y}{}
& \infer{\vdash x=x}{}}
\]
Aus dieser Sequenz erhält man anschließend
\[\vdash\forall x\colon\forall y\colon x=y\cond y=x.\]
Bezüglich $A(a):\equiv (f(x)=f(a))$ führt die Ausübung der soeben
gemachten Vorgehensweise auf
\[\vdash\forall x\colon\forall y\colon x=y\cond f(x)=f(y).\]
Es induziert die Ersetzungsregel für Funktionen,
\[\dfrac{\Gamma\vdash t=t'}{\Gamma\vdash f(t)=f(t')}.\]
Mehrmalige Anwendung des Ersetzungsaxioms ermöglicht darüber hinaus
mehrstellige Ersetzungen wie
\begin{gather*}
\vdash\forall x,x',y,y'\colon x=x'\land y=y'\cond A(x,y)\cond A(x',y'),\\
\vdash\forall x,x',y,y'\colon x=x'\land y=y'\cond f(x,y)=f(x',y').
\end{gather*}
Ferner implizieren die Axiome das Transitivgesetz
\[\vdash\forall x,y,z\colon x=y\land y=z\cond x=z.\]
Es steht $\forall x,y,z\colon A$ als Abkürzung für
$\forall x\colon\forall y\colon\forall z\colon A$.



