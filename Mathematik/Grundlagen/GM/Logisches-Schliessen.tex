
\chapter{Logisches Schließen}

\section{Grundbegriffe}

\subsection{Schlussregeln}

% Alles Schlussregeln und Axiome müssen unmittelbar einsichtig sein,
% müssen unbedenklich sein. Normalerweise will man in der Wissenschaft
% nicht so informell sein, aber hier sind wir am basalen Grund.
% Selbst in der Semantik wird der hier aufgestellte Formalismus
% benötigt. Der Korrektheitsbeweis würde somit zirkulär.

% Am Anfang ist noch nicht allzu viel zu rechnen. Wir müssen uns
% erst um die Schlussregeln und Axiome bemühen, bevor das erste Theorem
% bewiesen werden kann.

Logisches Schließen findet in einzelnen Schritten statt. Ein Schritt
stellt hierbei immer die Ableitung einer Schlussfolgerung aus einer
oder mehreren Voraussetzungen dar. Die Voraussetzungen heißen
\emph{Prämissen}\index{Praemisse@Prämisse}, die Schlussfolgerung
\emph{Konklusion}\index{Konklusion}. Darstellen wollen wir den Schritt
durch eine waagerechte Linie, wobei die Prämissen oberhalb befindlich
sein sollen, und die Konklusion unterhalb. Der Schritt
\[\dfrac{\text{Wenn es regnet, wird die Straße nass}\qquad\text{Es regnet}}
{\text{Die Straße wird nass}}\]
beschreibt beispielsweise, dass aus den Prämissen »Wenn es regnet, wird
die Straße nass« und »Es regnet« die Konklusion »Die Straße wird nass«
gefolgert wird.

Schlüsse wie der Obige treten in der Mathematik ständig auf. Ihnen allen
liegt ein bestimmtes Muster zugrunde, welches sich durch eine als
\emph{Modus ponens}\index{Modus ponens} oder
\emph{Abtrennungsregel}\index{Abtrennungsregel}
bezeichnete schematische \emph{Schlussregel}\index{Schlussregel}
beschreiben lässt. Es bezeichne hierzu $A\cond B$ die Implikation
»wenn $A$, dann $B$«. Es dürfen nun in
\[\dfrac{A\cond B\qquad A}{B}\]
für $A,B$ beliebige Aussagen eingesetzt werden. So darf »Es regnet»
für $A$ und »Die Straße wird nass« für $B$ eingesetzt werden.

\subsection{Sequenzen}

Das Schließen von Aussagen allein genügt nicht. Um freier argumentieren
zu können, würden wir gerne den Umstand beschreiben können, dass eine
Aussage unter bestimmten Annahmen abgeleitet werden konnte. Diese
Annahmen $A_k$ sind selbst Aussagen. Wir fassen sie zu einer endlichen
Ansammlung
\[\Gamma := [A_1,A_2,\ldots,A_n]\]
zusammen, worunter wir eine endliche Liste, oder auch eine endliche
Menge verstehen wollen, denn man soll mit dieser Liste umgehen können
wie mit einer Menge. Das heißt, es ist nicht von Bedeutung, wie
oft eine Aussage vorkommt oder in welcher Reihenfolge die Aussagen
stehen. Man bezeichnet $\Gamma$ als die \emph{Antezedenz}%
\index{Antezedenz} oder die Liste der \emph{Antezedenzen}. Es wird
$\Gamma$ auch der \emph{Kontext}\index{Kontext}
oder die \emph{Umgebung}\index{Umgebung} genannt, das sind auf die
Typentheorie zurückzuführende Sprechweisen, die einen ganz ähnlichen
Formalismus besitzt. Wir bezeichnen die Symbolik \[\Gamma\vdash A\]
als \emph{Sequenz}\index{Sequenz}. Sie drückt das \emph{Urteil}%
\index{Urteil} aus, dass die Aussage $A$ aus den Annahmen
vermittels Schlussregeln ableitbar ist. Der Modus ponens%
\index{Modus ponens} wird nun in der allgemeinen Form
\[\dfrac{\Gamma\vdash A\cond B\qquad\Gamma\vdash A}{\Gamma\vdash B}\]
beschrieben. Wir argumentieren beim Schließen also ab jetzt nicht mehr
mit den Aussagen selbst, sondern mit den Sequenzen. Dies hat einen wichtigen
Grund, nämlich dass die Berücksichtigung der Abhängigkeit von Annahmen
expliziter Teil des Schließens wird.

Ein Kontext kann auch eine leere Liste sein. Besitzt eine vermittels
Schlussregeln ableitbare Sequenz einen leeren Kontext, so bezeichnet
man die Antezedenz als ein \emph{Theorem}\index{Theorem} im engeren
Sinne. Ein Theorem ist also eine Aussage, die für sich allein gilt,
ohne dass dafür irgendwelche Annahmen getroffen werden müssen.

Für Sequenzen gilt die \emph{Abschwächungsregel}%
\index{Abschwaechungsregel@Abschwächungsregel}. Sie besagt, dass
falls die Aussage $A$ bereits aus $\Gamma$ ableitbar ist, diese
Aussage erst recht ableitbar ist, wenn zu $\Gamma$ weitere Annahmen
$\Gamma'$ hinzugefügt werden. Kurzum gilt die Regel
\[\dfrac{\Gamma\vdash A}{\Gamma,\Gamma'\vdash A}.\]
Hierbei bedeutet $\Gamma,\Gamma'$ die Konkatenation der Listen
$\Gamma$ und $\Gamma'$, also im Wesentlichen dasselbe wie die
Vereinigung $\Gamma\cup\Gamma'$, insofern man die Kontexte als
Mengen betrachtet.

\subsection{Zulässige Schlussregeln}

Wiewohl die Regeln des Schließens den Mechanismus zum Beweis
von Aussagen bilden, ist ihre Rolle sogar noch ein wenig tiefgreifender.
Wir können sie nämlich ebenfalls zur Ableitung \emph{weiterer Regeln}
nutzen. Das heißt, wir können sie dazu nutzen, den logischen Kalkül
selbst zu erweitern. Erweiterungen dieser Art nennen wir
\emph{zulässige Schlussregeln}%
\index{zulaessige Schlussregel@zulässige Schlussregel}.

Mit den bisherigen Regeln ist bereits die zulässige Regel
\[\dfrac{\Gamma\vdash A\cond B\qquad\Gamma'\vdash A}
{\Gamma,\Gamma'\vdash B}\]
ableitbar, die eine allgemeinere Form des Modus ponens darstellt. Man
erhält sie kurzerhand, indem den Prämissen des Modus
ponens jeweils die Abschwächungsregel vorgesetzt wird:
\[\infer{\Gamma,\Gamma'\vdash B}{
  \infer{\Gamma,\Gamma'\vdash A\cond B}{\Gamma\vdash A\cond B}
& \infer{\Gamma,\Gamma'\vdash A}{\Gamma'\vdash A}}
\]
Die einfache Form des Modus ponens erhält man mit $\Gamma':=\Gamma$ als
Spezialfall unter Anwendung der Kontraktionsregel.

\subsection{Implikationseinführung}

Ich möchte mich nun der Frage zuwenden, wie eine Implikation $A\cond B$
bewiesen wird. Intuitiv ist hierzu aus der Annahme $A$ die
Aussage $B$ zu folgern. Das heißt, es genügt die Ableitung
der Sequenz $A\vdash B$. Ein weiteres Mal gilt es noch zu
berücksichtigen, dass ein Beweis auch auf einen vorausgesetzten
Kontext $\Gamma$ beschränkt sein dürfen soll. Reflektiert man darüber
eine Weile, dürfte es der Überlegung nach wohl genügen, dass $A$
einfach dem Kontext $\Gamma$ hinzugefügt wird, woraus $B$ zu folgern
ist. Man gelangt zur Regel
\[\dfrac{\Gamma,A\vdash B}{\Gamma\vdash A\cond B}.\]
Wer diese Regel nicht so leicht fassbar findet, insbesondere nicht
direkt plausibel, ob sie bedenkenlos eingesetzt werden darf, der
ist nicht allein. Es gibt auch logische Kalküle, die diese Regel nicht
explizit enthalten. Sie tritt dennoch als \emph{Deduktionstheorem} in
Erscheinung, ein metalogisches Theorem, dessen Beweis erst erbracht
werden muss. Ich möchte diesen Weg allerdings aus einem bestimmten Grund
nicht gehen. Nämlich ist beim Beweis eigentlich natürliches Schließen
auf der metalogischen Ebene zu verwenden, wenn dies auch in informaler
Weise stattfinden mag. Aber nicht jeder Leser weiß zu diesem Zeitpunkt,
wie akkurates logisches Schließen geht. Der Leser benötigt am Anfang
etwas, um sich an den eigenen Haaren aus dem Sumpf zu ziehen.

\subsection{Axiome}

Zur Komplettierung des Kalküls gesellen sich schließlich auch noch
\emph{Axiome}\index{Axiom} hinzu, das sind gemachte Grundannahmen, die
nicht weiter bewiesen werden müssen. Sie sollten daher möglichst
plausibel, oder besser noch zweifelsfrei einsichtig sein. Für die Logik
selbst genügt das Axiom
\[A\vdash A.\]
Der Kalkül funktioniert dergestalt, dass für $A$ eine beliebige Aussage
eingesetzt werden darf, worunter auch zusammengesetzte Aussagen
wie fallen. Eine gern gewählter Weg der Definition des logischen
Kalküls sieht $A$ als eine metasprachliche Variable, für die eine
beliebige Formel eingesetzt werden darf. Unter dieser Sichtweise
spricht man von einem \emph{Axiomenschema}\index{Axiomenschema}. Wie
eine Schablone produziert es für jede Einsetzung einer konkreten
logischen Formel ein eigenes Axiom.

Anstelle $A,B,C$ werden für metasprachliche Variablen zuweilen auch
die griechischen Buchstaben $\varphi,\psi,\chi$ benutzt. Man muss sie
von atomaren logischen Variablen unterscheiden, für die wir in diesem
Buch, um Missverständnissen aus dem Weg zu gehen, kleine Buchstaben
$a,b,c$ oder $p,q,r$ verwenden werden. Sprachlich suggestiv steht
$\varphi$ für \emph{Formel}\index{Formel} oder \emph{formula}, $a$ für
\emph{Aussage} und $p$ für \emph{proposition}.

In diesem Sinne sind auch die Schlussregeln Schemata. Sofern man
Schlussregeln mit null Prämissen gestattet, lässt sich das
Axiomenschema auch als Regel
\[\dfrac{}{A\vdash A}\]
auffassen. In dieser Weise wollen wir die Anwendung von Axiomen in den
Beweisbäumen darstellen.

Axiome in der Form von Sequenzen heißen auch
\emph{Grundsequenzen}\index{Grundsequenz}.

Wir haben nun die Mittel in der Hand, um erste Theoreme beweisen
zu können. Es ist $A\cond A$ ein Theorem. Der Beweisbaum ist:
\[
\infer[\infernote{Implikationseinführung}]{\vdash A\cond A}{
  \infer[\infernote{Axiom}]{A\vdash A}{}}
\]
Unter der Lesung, dass $A$ eine Metavariable ist, handelt es
eigentlich nicht nur um ein Theorem, sondern um ein Schema von
Theoremen. Setzt man für $A$ bspw. die konkrete Formel $p\cond q$
ein, bekommt man das konkrete Theorem
\[\vdash (p\cond q)\cond (p\cond q).\]
% Es ist zu bemerken, dass die Unterscheidung zwischen Metavariablen
% und atomaren logischen Variablen später durch die Einsetzungsregel
% mehr oder weniger hinfällig wird. Hierbei handelt es sich aber um eine
% höhere Überlegung, deren Beweis der Logiker erbringen will. In der
% Wissenschaft, insbesondere in der Logik, will man den Dingen auf den
% Grund gehen, will alles genau auseinandernehmen. Da möchte man bestimmte
% Regeln nicht einfach so als gegeben voraussetzen.

\subsection{Junktoren}

Bisher traten zusammengesetzte Aussagen alleinig in Form einer
Implikation auf. Will man logische Zusammenhänge beschreiben können,
muss die logische Sprache um weitere Junktoren bereichert werden.
Unter einem \emph{Junktor}\index{Junktor} versteht man eine logische
Verknüpfung von Aussagen zu einer zusammengesetzten Aussage.

Wir werden einen Junktor durch \emph{Einführungsregeln}%
\index{Einfuehrungsregel@Einführungsregel} und
\emph{Beseitigungsregeln}\index{Beseitigungsregel}
charakterisieren. Die Regeln der Implikation
wurden bereits beschrieben; die Einführung geschieht per
Implikationseinführung, die Beseitigung per Modus ponens.
Für die restlichen Junktoren der Aussagenlogik lassen sich die Regeln
wahlweise in Form von Axiomenschemata oder in Form von Schlussregeln
darstellen. Ich möchte das per Schemata machen, weil diese ein wenig
kompakter sind, was sie hoffentlich ein wenig leichter einsichtig macht.
Die entsprechenden Schlussregeln leiten wir anschließend als zulässige
Regeln ab.

Die Konjunktion\index{Konjunktion} $A\land B$, auch Und"=Verknüpfung
genannt, sprich »$A$ und $B$«, ist charakterisiert durch die Sequenzen
\[A,B\vdash A\land B;\qquad A\land B\vdash A;\qquad A\land B\vdash B.\]
Aus dem Fall von sowohl Regen als auch Schnee ist der Fall von
Schneeregen ableitbar. Aus dem Fall von Schneeregen ist der Fall
von Regen ableitbar. Aus dem Fall von Schneeregen ist der Fall
von Schnee ableitbar. So sind diese Sequenzen zu verstehen.

Die Einführung der Konjunktion geschieht mit der Regel
\[\dfrac{\Gamma\vdash A\qquad\Gamma'\vdash B}{\Gamma,\Gamma'\vdash A\land B}.\]
Denn es findet sich der Beweisbaum:
\[
\infer[\infernote{MP}]{\Gamma,\Gamma'\vdash A\land B}{
  \infer[\infernote{MP}]{\Gamma\vdash B\cond A\land B}{
    \infer[\infernote{Impl-Einf.}]{\vdash A\cond (B\cond A\land B)}{
      \infer[\infernote{Impl-Einf.}]{A\vdash B\cond A\land B}{
        \infer[\infernote{Axiom}]{A,B\vdash A\land B}{}}}
  & \Gamma\vdash A}
& \Gamma'\vdash B}
\]
Es steht MP als Abkürzung für Modus ponens, und Impl-Einf. für
Implikationseinführung. Man schreibt alternativ auch das Kürzel
$\cond$E anstelle Impl-Einf. und das Kürzel $\cond$B anstelle
von MP. Hierbei steht E offenkundig für \emph{Einführung} und
B für \emph{Beseitigung}. Aber Vorsicht, in der englischsprachigen
Literatur sind das I für \emph{introduction} und E für
\emph{elimination}.

Die beiden Regeln zur Beseitigung der Konjunktion sind
\[\dfrac{\Gamma\vdash A\land B}{\Gamma\vdash A},
\qquad\dfrac{\Gamma\vdash A\land B}{\Gamma\vdash B}.\]
Denn es findet sich:
\[
\infer[\infernote{MP}]{\Gamma\vdash A}{
  \infer[\infernote{Impl-Einf.}]{\vdash A\land B\cond A}{
    \infer[\infernote{Axiom}]{A\land B\vdash A}{}}
& \Gamma\vdash A\land B}
\]
Die Disjunktion\index{Disjunktion} $A\lor B$, auch Oder"=Verknüpfung
genannt, sprich »$A$ oder $B$«, ist charakterisiert durch die Sequenzen
\[A\vdash A\lor B;\qquad B\vdash A\lor B;\qquad
A\lor B, (A\cond C), (B\cond C)\vdash C.\]
So ist »Die Erde des Beetes ist nass« ableitbar aus »Es hat geregnet
oder das Beet wurde gegossen«. Denn sowohl »Es hat geregnet« als auch
»Das Beet wurde gegossen« impliziert »Die Erde des Beetes ist nass«.

Die beiden Regeln zur Einführung der Disjunktion sind
\[\dfrac{\Gamma\vdash A}{\Gamma\vdash A\lor B},\qquad
\dfrac{\Gamma\vdash B}{\Gamma\vdash A\lor B}.\]
Die Regel zur Beseitigung der Disjunktion ist
\[\dfrac{\Gamma\vdash A\lor B\qquad\Gamma',A\vdash C\qquad\Gamma'',B\vdash C}
{\Gamma,\Gamma',\Gamma''\vdash C}.\]
Die Beweise dieser Regeln seien dem Leser überlassen.

Eine Aussage wie »Bertram wird seine Hausaufgaben nicht machen«
formuliert man gern in der Form »Wenn Bertram seine Hausaufgaben macht,
färbt sich der Mond grün«. In gleichartiger Weise lässt sich die
Verneinung auch in der formalen Logik definieren. Hierzu legt man als
Hilfsbegriff zunächst $\bot$ als die \emph{Kontradiktion}%
\index{Kontradiktion} fest, sie steht für eine widersprüchliche Formel.

Die Negation\index{Negation} $\lnot A$, auch Verneinung genannt, sprich
»nicht $A$«, definiert man als identisch mit $A\cond\bot$. Hierdurch
sind die Regeln zu ihrer Einführung und Beseitigung auf die der
Implikation zurückführbar. Es ergibt sich
\[\dfrac{\Gamma,A\vdash\bot}{\Gamma\vdash\lnot A},
\qquad\dfrac{\Gamma\vdash\lnot A\qquad\Gamma'\vdash A}
{\Gamma,\Gamma'\vdash\bot}.\]
Alternativ ließe sich die Negation durch die Sequenzen
\[(A\cond\bot)\vdash\lnot A;\qquad A,\lnot A\vdash\bot\]
charakterisieren. Man überzeuge sich, dass dies aufs selbe hinausläuft.

Die Äquivalenz\index{Aequivalenz@Äquivalenz} $A\bicond B$, sprich
»$A$ genau dann, wenn $B$«, definiert man als identisch mit
$(A\cond B)\land (B\cond A)$. Insofern sind die Regeln zu ihrer
Einführung und Beseitigung auf die der Konjunktion zurückführbar.
Es ergibt sich
\[\dfrac{\Gamma\vdash A\cond B\qquad\Gamma'\vdash B\cond A}
{\Gamma,\Gamma'\vdash A\bicond B},\qquad
\dfrac{\Gamma\vdash A\bicond B}{\Gamma\vdash A\cond B},\qquad
\dfrac{\Gamma\vdash A\bicond B}{\Gamma\vdash B\cond A}.\]
Die entsprechenden charakterisierenden Sequenzen sind
\[(A\cond B),(B\cond A)\vdash A\bicond B;\qquad (A\bicond B),A\vdash B;
\qquad (A\bicond B),B\vdash A.\]

\subsection{Zur Syntax}

So wie »Punktrechnung vor Strichrechnung« gilt, legt man für jeden Junktor
zur Einsparung von Klammern eine Stufe der Priorität fest. In
absteigender Rangfolge sind dies ${\lnot}, {\land}, {\lor}, {\cond},
{\bicond}$. So wird die Formel
\[\lnot A\land B\lor C\cond D\quad\text{gelesen als}\quad
(((\lnot A)\land B)\lor C)\cond D.\]
Weiterhin legt man die Implikation als rechtsassoziativ fest. So
wird
\[A\cond B\cond C\quad\text{gelesen als}\quad A\cond (B\cond C).\]
Manche Schüler haben Schwierigkeiten, die Struktur von Termen zu
durchschauen. Infolge kann es bei ihnen zu Flüchtigkeitsfehlern
bei der Ersetzung von Variablen durch Terme kommen. Sie vergessen,
dass ein Term vor der Einfügung zunächst geklammert werden muss.
Erst die Operatorrangfolge gewährt es, die Klammern unter Umständen
nachträglich entfallen zu lassen. Für diese Schüler mag es förderlich
sein, einen Term als \emph{abstrakten Syntaxbaum} darzustellen.
Gleichermaßen verhält es sich mit der Programmiersprache Lisp, die
Terme als Schachtelung von Listen darstellt, deren Klammern
obligatorisch sind.  Die Aussage $A\land B\cond C$ ist beispielsweise
beschreibbar als
\[\text{\texttt{(implies (and A B) C)}}.\]
Im Wesentlichen veranschaulicht diese Schachtelung
nichts anderes als den abstrakten Syntaxbaum. Man kann gewissermaßen
sagen, dass Lisp eine Programmiersprache ohne Syntax ist. Fast ohne,
im höheren Sinne ohne.

% In der Logik versucht man, die Objektsprache genau zu fassen.
% Daher nutzt man das Konzept der formalen Sprache. Terme werden
% in ihr durch Produktionsregeln beschrieben. Produktionsregeln
% lassen unter anderem in Form der EBNF notieren.

Schreibt man viele logische Formeln auf, drängt es, zumindest bei privaten
Notizen und Rechnungen, nach Kurzschreibweisen. In der Logik ist für das
Konditional $A\cond B$ auch die Schreibweise $A\rightarrow B$ gebräuchlich,
für das Bikonditional $A\bicond B$ entsprechend $A\leftrightarrow B$.
Insbesondere in der Schaltalgebra schreibt man auch $\overline A$
anstelle von $\lnot A$, $AB$ anstelle von $A\land B$ und $A+B$ anstelle
von $A\lor B$. Hierbei darf die Disjunktion $A+B$ allerdings nicht mit
der Kontravalenz $A\oplus B$ verwechselt werden.


\section{Natürliches Schließen}

\subsection{Darstellungsformen}

Abgeleitet werden soll das Theorem
\[\vdash (A\cond B)\cond (\lnot B\cond\lnot A).\]
Meine favorisierte und in diesem Buch genutzte Form der Darstellung
des natürlichen Schließens fügt die aus den Schlussregeln erhaltenen
Schlüsse wie Legosteine zu einem Baum zusammen, dem
\emph{Beweisbaum}\index{Beweisbaum} oder \emph{Herleitungsbaum}.
Im Eigentlichen stehen in den Blättern die Grundsequenzen, und in der
Wurzel das Theorem. Wie wir es bereits getan haben, arbeitet man
allerdings auch mit Exemplaren, die irgendwelche Sequenzen in
irgendwelche Sequenzen überführen, womit man zulässige Schlussregeln
erhält. Allgemeiner ginge ferner die Formulierung als gerichteter
azyklischer Graph, die bei einigen Beweisen ein wenig den
Schreibaufwand reduzieren würde.

Der Beweisbaum genannten Theorems ist:
\[
\infer[\infernote{$\cond$E}]{\vdash (A\cond B)\cond (\lnot B\cond\lnot A)}{
  \infer[\infernote{$\cond$E}]{A\cond B\vdash \lnot B\cond\lnot A}{
    \infer[\infernote{$\lnot$E}]{A\cond B, \lnot B\vdash\lnot A}{
      \infer[\infernote{$\lnot$B}]{A\cond B, \lnot B, A\vdash\bot}{
        \infer[\infernote{Axiom}]{\lnot B\vdash\lnot B}{}
      & \infer[\infernote{$\cond$B}]{A\cond B, A\vdash B}{
          \infer[\infernote{Axiom}]{A\cond B\vdash A\cond B}{}
        & \infer[\infernote{Axiom}]{A\vdash A}{}}}}}}
\]
Die Ausformulierung der Sequenzen verlangt langwieriges erneutes
Aufschreiben der Antezedenzen. Sobald man das Prozedere einmal
verstanden hat, erscheint es überausführlich. Man kann sich daher
verkürzte Darstellungen der Beweisbäume überlegen:
\[
\begin{tabular}{@{}l@{\qquad\quad}l}
\infer{\vdash (A\cond B)\cond (\lnot B\cond\lnot A)}{
  \infer{2\vdash \lnot B\cond\lnot A}{
    \infer{1, 2\vdash\lnot A}{
      \infer{1, 2, 3\vdash\bot}{
        \infer{1\equiv\lnot B}{}
      & \infer{2, 3\vdash B}{
          \infer{2\equiv A\cond B}{}
        & \infer{3\equiv A}{}}}}}}
&
\infer[\infernote{$\sim$2}]{(A\cond B)\cond (\lnot B\cond\lnot A)}{
  \infer[\infernote{$\sim$1}]{\lnot B\cond\lnot A}{
    \infer[\infernote{$\sim$3}]{\lnot A}{
      \infer{\bot}{
        \infer[\infernote{1}]{\lnot B}{}
      & \infer{B}{
          \infer[\infernote{2}]{A\cond B}{}
        & \infer[\infernote{3}]{A}{}}}}}}
\end{tabular}
\]
Die linke Form kürzt die Antezedenzen durch Nummern ab. In der rechten
Form entfallen die Antezedenzen vollständig. Stattdessen tauchen sie
als in den Blättern gemachte nummerierte \emph{Annahmen} auf, die im
Fortgang zur Wurzel irgendwann zu tilgen sind. Ihre Tilgung erscheint
nun als Randnotiz.

Eine weitere, sehr systematische Darstellung setzt den Beweis aus
einer Liste von Tabellenzeilen zusammen. Allerdings ist sie ein wenig
mühevoll zu lesen. Jede Zeile enthält eine Aussage und dahinter
zusätzlich die Information, wie und woraus die Aussage abgeleitet wurde.
Jede der Aussagen bekommt eine Nummer, siehe Tabelle \ref{tab:Kontraposition}.
Die Nummerierung der Abhängigkeiten ist in derselben Reihenfolge wie
zuvor bei den Bäumen angegeben. Wer die Liste genauer betrachtet, erkennt,
dass die jeweilige Zeile nichts anderes als die Sequenz
$\text{Abh.}\vdash\text{Nr.}$ darstellt.

\begin{table}
\begin{center}
\caption{Beweis in Form einer Liste von Tabellenzeilen}
\label{tab:Kontraposition}
\begin{tabular}{cclll}
\toprule
\strong{Abh.} & \strong{Nr.} & \strong{Aussage} & \strong{Regel} & \strong{auf}\\
\midrule
1 & 1 & $\lnot B$ & Axiom &\\
2 & 2 & $A\cond B$ & Axiom &\\
3 & 3 & $A$ & Axiom &\\
2, 3 & 4 & $B$ & $\cond$B & 2, 3\\
1, 2, 3 & 5 & $\bot$ & $\lnot$B & 1, 4\\
1, 2 & 6 & $\lnot A$ & $\lnot$E & 5\\
2 & 7 & $\lnot B\cond\lnot A$ & $\cond$E & 6\\
$\emptyset$ & 8 & $(A\cond B)\cond(\lnot B\cond\lnot A)$ & $\cond$E & 7\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

Unabhängig von Gentzen entwickelte Jaśkowski das natürliche Schließen
einige Jahre zuvor. Während Gentzen Beweise als Bäume darstellte, nutzte
Jaśkowski zunächst eine grafische Darstellung, die später von Fitch
adaptiert wurde und in dieser Form nun als \emph{Fitch"=Style}%
\index{Fitch-Style} bekannt ist.

Zu guter Letzt muss die klassische Darstellung der Beweisführung
aufgeführt werden. Die in Worten. Sie zeichnet sich durch die Auslassung
mühseliger technischer Details und blumige Formulierungen aus,
soll aber genug Information enthalten, dass der Leser im Zweifel
eine Formalisierung des Beweises erstellen und verifizieren kann.

\begin{Satz}
Es gilt $(A\cond B)\cond (\lnot B\cond\lnot A)$.
\end{Satz}
\strong{Beweis.} Aus der Annahme von sowohl $A\cond B$ als
auch $\lnot B$ als auch $A$ ist ein Widerspruch abzuleiten.
Man erhält $B$ zunächst per Modus ponens aus $A\cond B$ und $A$.
Nun steht $\lnot B$ bereits im Widerspruch zu $B$.\,\qedsymbol

Als komfortablen Bonus erhält man mit dem Theorem nun im Anschluss
kurzerhand eine weitere zulässige Regel, die
\emph{Kontraposition}\index{Kontraposition}
\[\dfrac{\Gamma\vdash A\cond B}{\Gamma\vdash\lnot B\cond\lnot A},
\quad\text{denn}\quad
\dfrac{\vdash (A\cond B)\cond (\lnot B\cond\lnot A)\quad\Gamma\vdash A\cond B}
{\Gamma\vdash \lnot B\cond\lnot A}.\]
Fügt man ihr den Modus ponens an, findet sich der
\emph{Modus tollens}\index{Modus tollens}
\[\dfrac{\Gamma\vdash A\cond B\qquad\Gamma'\vdash\lnot B}
{\Gamma,\Gamma'\vdash\lnot A}.\]

\subsection{Widerspruchsbeweise}

Beim \emph{Beweis durch Widerspruch} widerlegt man eine Aussage, indem
gezeigt wird, dass die Annahme der Aussage zu einem logischen
Widerspruch führt. In manchen Situationen bietet diese Art der
Argumentation eine große Hilfe. So schreibt der britische Mathematiker
Godfrey Harold Hardy in seinem Essay \emph{A Mathematician's Apology}
die Worte
\begin{quote}
»The proof is by \emph{reductio ad absurdum}, and \emph{reductio ad
absurdum}, which Euclid loved so much, is one of a mathematician's
finest weapons. It is a far finer gambit than any chess gambit: a chess
player may offer the sacrifice of a pawn or even a piece, but a
mathematician offers \emph{the game}.«
\end{quote}
Zur Schaffung von Klarheit muss man zunächst zwei inhaltlich
verschiedene Arten des Widerspruchsbeweises unterscheiden.
Präzisieren lässt sich diese Unterscheidung anhand
der Regeln
\[\dfrac{\Gamma,A\vdash\bot}{\Gamma\vdash\lnot A},\qquad
\dfrac{\Gamma,\lnot A\vdash\bot}{\Gamma\vdash A}.\]
Die linke Regel stellt die stets verfügbare Negationseinführung dar,
die man auch als \emph{Widerlegung durch Widerspruch} bezeichnen kann.
In der rechten Regel, der klassischen \emph{Reductio ad absurdum},
gelangt man zunächst per Negationseinführung von
$\Gamma,\lnot A\vdash\bot$ zu $\Gamma\vdash\lnot\lnot A$, und daraufhin
zu $\Gamma\vdash A$. Die Beseitigung der Doppelnegation ist allerdings
lediglich in der klassischen Logik verfügbar, in der intuitionistischen
gilt sie dagegen als unzulässig.


