
\chapter{Mengenlehre}

\section{Grundbegriffe}

\subsection{Der Mengenbegriff}

Eine \emph{Menge}\index{Menge} darf man sich wie einen Beutel
vorstellen, der einzelne Objekte enthält. Die Objekte heißen
\emph{Elemente}\index{Element} der Menge. Jedoch gilt es hierbei zu
beachten, dass es sich mit einer Menge nicht gänzlich wie mit einem
Beutel verhält, in dem dasselbe Objekt mehrmals zu finden sein kann.
\begin{quote}
»\emph{Unter einer Menge verstehen wir jede Zusammenfassung von
bestimmten wohlunterschiedenen Objekten unserer Anschauung oder
unseres Denkens zu einem Ganzen.}«\\
--- Georg Cantor, 1895 (redigiert aus \cite{Cantor})
\end{quote}
Obwohl blumig anmutend, fassen diese Worte das Konzept recht gut
auf den Punkt. Wichtig ist hier das Wort \emph{wohlunterschieden},
das uns zu verstehen gibt, dass ein Element nicht mehrmals in einer
Menge enthalten sein kann. \emph{Eine Menge ist genau dadurch festgelegt,
welche Elemente sie enthält. Sie enthält Elemente weder mehrmals, noch
in einer bestimmten Reihenfolge.}

Es gibt die \emph{leere Menge}\index{leere Menge}, notiert als
$\emptyset$ oder $\{\}$. Man darf sie sich wie einen leeren Beutel
vorstellen. Dagegen enthält die Menge $\{\emptyset\}$ genau ein Element.
Es ist ein Beutel,  der den leeren Beutel enthält.

Wir schreiben kurz $x\in A$ für »$x$ ist ein Element von $A$«,
auch »$x$ gehört zu $A$« oder »$x$ liegt in $A$«.
Es steht $x\notin A$ für $\lnot x\in A$.

Für eine endliche Menge definiert man
\[x\in\{x_1,\ldots,x_n\}\defiff x=x_1\lor\ldots\lor x=x_n.\]

\subsection{Gleichheit von Mengen}

Es wurde gesagt, eine Menge ist dadurch charakterisiert, welche
Elemente sie enthält. Um diesen Gedanke näher zu erfassen, sollten
wir klären, wie es sich mit der Gleichheit von Mengen verhält.
Insofern Mengen durch ihre Elemente bestimmt sind, darf man doch sagen,
zwei Mengen $A,B$ sind genau dann gleich, falls $A,B$ ein Objekt
gemeinsam enthalten oder gemeinsam nicht enthalten. Das heißt, betrachtet
man ein beliebiges Objekt $x$, so ist $x$ genau dann in $A$ enthalten,
wenn $x$ in $B$ enthalten ist.
\begin{Definition}[Gleichheit von Mengen]\newlinefirst
Für zwei Mengen $A,B$ definiert man
\[A = B \defiff (\forall x\colon x\in A\bicond x\in B).\]
\end{Definition}
Der Leser wird mühelos bestätigen, dass die Gleichheit die Axiome
einer Äquivalenzrelation erfüllt. Wobei der Begriff der Relation
noch zu definieren wäre. Weil die Gesamtheit aller Mengen eine
sogenannte echte Klasse ist, handelt es sich nicht um eine
Äquivalenzrelation im engeren Sinne.

Es ist zulässig, ein Element bei der aufzählenden Angabe einer Menge
mehrmals aufzuführen. Dies ändert allerdings nichts daran, dass ein
Element stets nur einmal in einer Menge enthalten ist. Zum Beispiel
gilt $\{\emptyset,\emptyset\}=\{\emptyset\}$. Mit der Definition der
aufzählenden Angabe und dem Idempotenzgesetz
der Aussagenlogik findet sich nämlich die äquivalente Umformung
\[x\in\{\emptyset,\emptyset\}\iff x=\emptyset\lor x=\emptyset
\iff x=\emptyset\iff x\in\{\emptyset\}.\]

\subsection{Beschränkte Quantifizierung}

In der Mathematik erstreckt sich die Quantifizierung meist nicht
über das gesamte Diskursuniversum, sondern bleibt auf eine bestimmte
Menge beschränkt. Eine extra Notation macht dies ergonomisch, wobei
eine Erweiterung der logischen Sprache hierfür nicht nötig ist. Die
beschränkte Quantifizierung wird logisch auf eine unbeschränkte
zurückgeführt.

\begin{Definition}[Beschränkte Quantifizierung]\newlinefirst
Für jede Menge $M$ und jede Aussageform $A(x)$ setzt man
\begin{gather*}
(\forall x\in M\colon A(x))\defiff (\forall x\colon x\in M\cond A(x)),\\
(\exists x\in M\colon A(x))\defiff (\exists x\colon x\in M\land A(x)).
\end{gather*}
\end{Definition}
Die Aussage $\forall x\in\emptyset\colon A(x)$ ist allgemeingültig, man
spricht von der \emph{leeren Wahrheit}\index{leere Wahrheit}, engl.
\emph{vacuous truth}\index{vacuous truth}. Via Ex falso quodlibet
erhält man nämlich:
\[
\infer{\vdash\forall x\colon x\in\emptyset\cond A(x)}{
  \infer[\infernote{EFQ}]{x\in\emptyset\vdash A(x)}{
    \infer{x\in\emptyset\vdash\bot}{
      \infer{\vdash\lnot x\in\emptyset}{}
    & \infer{x\in\emptyset\vdash x\in\emptyset}{}}}}
\]
Viele Regeln zur beschränkten Quantifizierung sind analog zu den
Regeln der unbeschränkten. Beispielsweise gilt
\[(\forall x\in M\colon A(x)\land B(x)) \iff (\forall x\in M\colon A(x))
\land (\forall x\in M\colon B(x)).\]
Man muss allerdings Vorsicht walten lassen. Nicht bei jeder Äquivalenz
liegt eine direkte Analogie vor. Zwar besteht für eine Formel $A$,
in der $x$ nicht frei vorkommt, die Äquivalenz
\[(\exists x\colon A) \iff A.\]
Die Analogie ist jedoch von der ein klein wenig intrikateren Form
\[(\exists x\in M\colon A) \iff M\ne\emptyset\land A.\]
Diese Beziehung erklärt sich durch die Umformung
\[(\exists x\in M\colon A)\bicond (\exists x\colon x\in M\land A)
\bicond (\exists x\colon x\in M)\land A \bicond M\ne\emptyset\land A.\]
Die letzte Umformung gilt, weil $M\ne\emptyset$ gleichbedeutend mit
$\exists x\colon x\in M$ ist.

\subsection{Komprehension}

\begin{Definition}[Komprehension]\newlinefirst
Zu einer Aussageform $A(x)$ definiert man die Klasse
$\{x\mid A(x)\}$ gemäß
\[a\in\{x\mid A(x)\}\defiff A(a).\]
\end{Definition}
Man muss mit der Komprehension ein wenig vorsichtig umgehen, denn nicht
jede Klasse ist eine Menge. Die russellsche Klasse $R := \{x\mid x\notin x\}$
ist das klassische Beispiel. Angenommen, $R$ wäre eine
Menge. Dann dürfte man eine Aussage wie $R\in M$ bezüglich
einer Menge $M$ formulieren, also speziell $R\in R$. Gemäß Definition
von $R$ findet sich die folgende Ableitung:
\[
\infer{\vdash R\in R\bicond R\notin R}{
  \infer[\infernote{laut Def.}]{R\in R\vdash R\notin R}{
    \infer{R\in R\vdash R\in R}{}}
& \infer[\infernote{laut Def.}]{R\notin R\vdash R\in R}{
    \infer{R\notin R\vdash R\notin R}{}}}
\]
Für jede Formel $A$ gilt allerdings das Theorem
\[\vdash (A\bicond\lnot A)\cond\bot.\]
Insgesamt ergibt sich so ein Beweis der Kontradiktion. Irgendetwas kann
also nicht gut sein. Diese von Bertrand Russell im Jahre 1901 entdeckte
Verwicklung, die seit jeher den Namen \emph{russellsche Antinomie}%
\index{russellsche Antinomie} trägt, brachte Gottlob Freges
logizistisches Programm in unangenehme Schwierigkeiten. Frege versuchte,
eine Reduktion der Mathematik auf die Logik zu unternehmen, wurde
daraufhin aber von Russell brieflich in Kenntnis gesetzt, dass sein
Werk \emph{Grundgesetze der Arithmetik} in wesentlicher Weise von der
Antinomie unterhöhlt wird. Russell führte das Programm fort, und
veröffentlichte schließlich die \emph{Principia Mathematica}, die der
Antinomie mithilfe einer Typentheorie aus dem Weg geht.

Man begegnet der Problematik, indem man $R$ als eine echte
Klasse ansieht. Für sie darf die Aussage $R\in M$ nicht formuliert
werden. Man definiert weiterhin eine weniger allgemeine Form der
Komprehension, die \emph{Aussonderung}\index{Aussonderung}. Sie verhält
sich gutartig, da sie nicht mehr ermöglicht, als das Ausfiltern von
Elementen aus einer gegebenen Menge.

\begin{Definition}[Aussonderung]\newlinefirst
Zu einer Menge $M$ und einer Aussageform $A(x)$ definiert man
\[a\in\{x\in M\mid A(x)\}\defiff a\in M\land A(a).\]
\end{Definition}

\subsection{Teilmengen}

Gehört jedes Element einer Menge $A$ auch zu einer Menge $B$, nennt
man $A$ eine \emph{Teilmenge}\index{Teilmenge} von $B$. Man sagt auch,
$B$ umfasse $A$, oder $B$ sei eine Obermenge von $A$. Eine \emph{echte
Teilmenge} sei $A$ dann, wenn zusätzlich $A\ne B$ gilt. Die Menge der
geraden Zahlen ist eine echte Teilmenge der ganzen Zahlen. Jede Menge
ist eine Teilmenge von sich selbst, jedoch keine echte.

Die Menge der Quadrate ist eine Teilmenge der Vierecke, genauer eine
Teilmenge der Rechtecke und auch eine Teilmenge der Rhomben.
Weder ist die Menge der Rechtecke eine Teilmenge der Rhomben, noch
ist die Menge der Rhomben eine Teilmenge der Rechtecke. 
Allerdings ist sowohl die Menge der Rechtecke als auch die der Rhomben
eine Teilmenge der Parallelogramme.

\begin{Definition}[Teilmengenbeziehung]\newlinefirst
Man definiert $A\subseteq B$, gelesen »$A$ ist eine Teilmenge von $B$«, als
\[A\subseteq B\defiff (\forall x\colon x\in A\cond x\in B).\]
\end{Definition}
Unschwer bestätigt sich die Äquivalenz
\[A = B \iff A\subseteq B\land B\subseteq A.\]

\begin{Definition}[Potenzmenge]\newlinefirst
Die Potenzmenge\index{Potenzmenge} einer Menge $M$ ist definiert als
\[\mathcal P(M) := \{A\mid A\subseteq M\}.\]
\end{Definition}
Zum Beispiel ist $\mathcal P(\emptyset) = \{\emptyset\}$ und
$\mathcal P(\{0\}) = \{\emptyset, \{0\}\}$. Des Weiteren
\begin{gather*}
\mathcal P(\{0,1\}) = \{\emptyset, \{0\}, \{1\}, \{0,1\}\},\\
\mathcal P(\{0,1,2\}) = \{\emptyset, \{0\}, \{1\}, \{2\}, \{0,1\}, \{0,2\}, \{1,2\}, \{0,1,2\}\}.
\end{gather*}
Die Teilmengenbeziehung darf als eine Art Ordnung zwischen Mengen
betrachtet werden, jedoch nicht als eine Totalordnung, das heißt,
bei einigen Mengen $A,B$ gilt weder $A\subseteq B$ noch $B\subseteq A$.
So ist wie gesagt weder die Menge der Rechtecke eine Teilmenge der
Rhomben, noch umgekehrt.

Die Potenzmenge einer Grundmenge $G$ bildet mit der Teilmengenbeziehung
eine halbgeordnete Menge, engl. \emph{poset} für
\emph{partially ordered set}. Das heißt, alle Mengen
$A,B,C\in\mathcal P(G)$ erfüllen die drei Axiome
\begin{align*}
& A\subseteq A, &&\text{(Reflexivität)}\\
& A\subseteq B\land B\subseteq A\cond A = B, &&\text{(Antisymmetrie)}\\
& A\subseteq B\land B\subseteq C\cond A\subseteq C. &&\text{(Transitivität)}
\end{align*}


\subsection{Mengenoperationen}

\begin{Definition}[Schnitt, Vereinigung, Differenz]\newlinefirst
Zu zwei Mengen $A,B$ definiert man
\begin{align*}
A\cap B &:= \{x\mid x\in A\land x\in B\}, && \text{(Schnittmenge)}\\
A\cup B &:= \{x\mid x\in A\lor x\in B\}, && \text{(Vereinigungsmenge)}\\
A\setminus B &:= \{x\mid x\in A\land x\notin B\}. && \text{(Differenzmenge)}
\end{align*}
\end{Definition}
Sind $A,B$ Teilmengen einer Grundmenge $G$, so sind auch
$A\cap B$, $A\cup B$ und $A\setminus B$ Teilmengen der Grundmenge.
Der Beweis zu $A\cap B\subseteq G$ ist:
\[
\infer{A\subseteq G\vdash A\cap B\subseteq G}{
  \infer{A\subseteq G\vdash\forall x\colon x\in A\cap B\cond x\in G}{
    \infer{A\subseteq G, x\in A\cap B\vdash x\in G}{
      \infer{x\in A\cap B\vdash x\in A}{
        \infer{x\in A\cap B\vdash x\in A\land x\in B}{
          \infer{x\in A\cap B\vdash x\in A\cap B}{}}}
    & \infer{A\subseteq G\vdash x\in A\cond x\in G}{
        \infer{A\subseteq G\vdash \forall x\colon x\in A\cond x\in G}{
          \infer{A\subseteq G\vdash A\subseteq G}{}}}}}}
\]
In so pedantischer Ausführlichkeit findet man Beweise in Büchern
nicht vor. Erstens wird man stillschweigend zulässige Schlussregeln zur
Verkürzung aufstellen. So nimmt der Baum die konzise Form
\[
\begin{array}{@{}l@{\qquad\quad}l}
\infer{A\subseteq G\vdash A\cap B\subseteq G}{
  \infer{A\subseteq G,x\in A\cap B\vdash x\in G}{
    \infer{x\in A\cap B\vdash x\in A}{
      \infer{x\in A\cap B\vdash x\in A\cap B}{}}
  & \infer{A\subseteq G\vdash A\subseteq G}{}}}
&
\infer[\infernote{$\sim$1}]{A\cap B\subseteq G}{
  \infer{x\in G}{
    \infer{x\in A}{
      \infer[\infernote{1}]{x\in A\cap B}{}}
  & A\subseteq G}}
\end{array}
\]
an. Zweitens formuliert der Mathematiker den Beweis meist in Worten:
Um $A\cap B\subseteq G$ zu zeigen, muss $x\in G$ aus $x\in A\cap B$
abgeleitet werden. Mit $x\in A\cap B$ gilt erst recht $x\in A$.
Wegen $A\subseteq G$ ist somit $x\in G$, was zu zeigen war.\,\qedsymbol

\begin{Definition}[Komplement]\newlinefirst
Bezüglich einer Grundmenge $G$ heißt $A^\compc := G\setminus A$
Komplementärmenge.
\end{Definition}
Es zeigt sich elementar, dass die Potenzmenge einer Grundmenge $G$
mit den Operationen $A\cap B$, $A\cup B$ die Axiome
einer booleschen Algebra\index{boolesche Algebra} erfüllt, wobei
$\emptyset$ das Nullelement und $G$ selbst das Einselement ist. Es
gelten somit analoge Regeln wie in der klassischen Aussagenlogik. Wie
die Notation suggeriert, entspricht der Schnitt der Konjunktion, die
Vereinigung der Disjunktion und das Komplement der Negation.

Wie in jedem Verband ist in einer booleschen Algebra
$(M,\wedge,\vee)$ für $a,b\in M$ eine Halbordnung $a\le b$
definiert, indem $a\le b$ und $a\wedge b = a$ als äquivalent
angesehen werden. Bei der Mengenalgebra entpuppt sie sich
als die Teilmengenrelation. Das heißt, es gilt%
\[A\subseteq B\iff A\cap B = A\iff A\cup B = B.\]
Für mehrere Mengen definiert man
\[\bigcap_{i=1}^n A_i := A_1\cap A_2\cap\ldots\cap A_n,\qquad
\bigcup_{i=1}^n A_i := A_1\cup A_2\cup\ldots\cup A_n.\]
Pedantiker mögen die Schreibweise mit den Auslassungspunkten als
ungenau empfinden. Zufriedenstellend ist für sie die Erklärung, dass
es sich um die rekursive Festlegung
\[\bigcap_{i=1}^1 A_i := A_1,\qquad
\bigcap_{i=1}^n A_i := A_n\cap\bigcap_{i=1}^{n-1} A_i\]
handelt. Regeln wie $B\cup\bigcap_{i=1}^n A_i
= \bigcap_{i=1}^n (B\cup A_i)$ kann man nun per Induktion über $n$
beweisen. Es geht fast trivial vonstatten, sobald man das Prinzip
verstanden hat. Im Wesentlichen weiten sich hier die Regeln der
booleschen Algebra von den zweistelligen auf die mehrstelligen
Operationen aus.

\begin{Definition}[Allgemeine Vereinigung]\newlinefirst
Sei $M$ eine Menge von Mengen. Die Vereinigung der $A\in M$ ist
\[\bigcup M = \bigcup_{A\in M} A := \{x\mid\exists A\in M\colon x\in A\}.\]
\end{Definition}
Für $M=\emptyset$ ist $\bigcup M = \emptyset$. Die Disjunktion findet
ihre Entsprechung genau in der Vereinigung
von zwei Mengen. Dazu passend findet der Existenzquantor seine
Entsprechung genau in der Vereinigung beliebig vieler Mengen.
Aus diesem Grund weiten sich die Regeln der booleschen Algebra
auf die allgemeine Vereinigung aus. Zum Beispiel lautet das
Distributivgesetz für Mengen
\[B\cap\bigcup_{A\in M} A = \bigcup_{A\in M}(B\cap A).\]
Entfaltung der Definition führt nämlich zur logischen Äquivalenz
\[x\in B\land(\exists A\in M\colon x\in A) \iff (\exists A\in M\colon x\in B\land x\in A).\]
Ihr Beweis gelingt mühelos.

\begin{Definition}[Allgemeiner Schnitt]\newlinefirst
Sei $M$ eine nichtleere Menge von Mengen. Der Schnitt der $A\in M$ ist
\[\bigcap M = \bigcap_{A\in M} A := \{x\mid\forall A\in M\colon x\in A\}.\]
\end{Definition}
Im Gegensatz zur Vereinigung wurde der Schnitt $\bigcap M$ 
für $M=\emptyset$ undefiniert gelassen. Hier gibt es zwei Möglichkeiten.
Zum einen könnte man die Bedingung $M\ne\emptyset$ einfach fallen
lassen, dann ergibt im allgemeinen Mengenuniversum beim leeren Schnitt
die Allklasse $\{x\mid\top\}$, die jedoch keine Menge ist.

Aus diesen Grund gibt es noch die alternative Definition
\[\bigcap M :=
\{x\in G\mid\forall A\in M\colon x\in A\}.\]
Hierzu ist eine Grundmenge $G$ festzulegen, so dass $M\subseteq\mathcal P(G)$
gilt, oder man setzt $G:=\bigcup M$, wobei sich da die Frage
nach der Nützlichkeit stellt.

Eine Menge von Mengen nennt man ein \emph{Mengensystem}\index{Mengensystem},
wobei aber einige Autoren diese Begrifflichkeit für eine Familie von
Mengen benutzen, die von einer Menge von Mengen zu unterscheiden ist.
Eine Familie stellt eine Verallgemeinerung einer Folge von Mengen dar.
In ihr darf dieselbe Menge mehrmals vorkommen. Man kann Schnitt und
Vereinigung auch für Familien definieren, was aber eigentlich keine
wesentliche Verallgemeinerung zu den obigen Festlegungen darstellt,
wie ich im Folgenden diskutieren möchte.

Eine \emph{Familie}\index{Familie} $(A_i)$ von Mengen $A_i$ mit $i\in I$
ist eine Abbildung $A\colon I\to Z$, wobei $Z$ eine Zielmenge ist,
welche die $A_i$ als Elemente enthält. Die Menge $I$ wird in diesem
Zusammenhang auch \emph{Indexmenge}\index{Indexmenge} genannt. Man
definiert
\[\bigcup_{i\in I} A_i := \bigcup A(I)
= \bigcup\{X\mid\exists i\in I\colon X=A_i\} = \{x\mid\exists i\in I\colon x\in A_i\},\]
wobei mit $A(I)$ das Bild von $I$ unter $A$ gemeint ist. Man bekommt
\begin{align*}
\smash{\bigcup_{i\in I} A_i}
&= \{x\mid\exists X\colon X\in \{X\mid\exists i\in I\colon X=A_i\}\land x\in X\}\\
&= \{x\mid\exists X\colon (\exists i\in I\colon X=A_i)\land x\in X\}\\
&= \{x\mid\exists X\colon \exists i\in I\colon X=A_i\land x\in X\}
= \{x\mid\exists i\in I\colon x\in A_i\}.
\end{align*}
Für $I\ne\emptyset$ definiert man entsprechend
\[\bigcap_{i\in I} A_i := \bigcap A(I) = \{x\mid\forall i\in I\colon x\in A_i\}.\]
Die Operation über eine Familie $(A_i)_{i\in I}$ kann also
auf die jeweilige Operation über das System $A(I)$ zurückgeführt
werden.

Später nützlich ist der

\begin{Satz}\label{Index-in-Schnitt}
Es gilt $\bigcup_{i\in I\cap J} A_i = (\bigcup_{i\in I} A_i)\cap
(\bigcup_{i\in J} A_j)$.
\end{Satz}
\begin{Beweis}
Es findet sich die äquivalente Umformung
\begin{align*}\textstyle
x\in\bigcup_{i\in I\cap J} A_i &\iff (\exists i\colon i\in I\cap J\land x\in A_i)\\
&\iff(\exists i\colon (i\in I\land x\in A_i)\land (i\in J\land x\in A_i))\\
&\iff(\exists i\colon i\in I\land x\in A_i)\land (\exists i\colon i\in J\land x\in A_i)\\
&\iff\textstyle x\in\bigcup_{i\in I} A_i\land x\in\bigcup_{i\in J} A_i\\
&\iff\textstyle x\in(\bigcup_{i\in I} A_i)\cap (\bigcup_{i\in J} A_i).\,\qedsymbol
\end{align*}
\end{Beweis}

\noindent
Gelegentlich hat man es mit einer \emph{disjunkten Vereinigung}%
\index{disjunkte Vereinigung} zu tun. Sie ist bedeutsam in der
Theorie der Kardinalzahlen und in der Informatik bei algebraischen
Datentypen sowie deren Bezug zur Beweistheorie. Genauer gesagt hantiert
man in der Informatik nicht mit Mengen, sondern mit Typen, die sich
in gewissen Zügen analog zu Mengen verhalten. Die disjunkte Vereinigung
zweier Mengen kennzeichnet jedes Element vor der Vereinigung mit einem
Tag, das die Information liefert, aus welcher der Mengen es entstammt.
Man setzt
\[A\sqcup B := \{(0,a)\mid a\in A\}\cup\{(1,b)\mid b\in B\}.\]
Die Zahlen $0,1$ sind hier die \emph{Tags} oder \emph{Diskriminatoren}.
Anstelle der Zahlen könnten genauso gut zwei beliebige unterschiedliche
Elemente als Tags verwendet werden. Beispielsweise ginge auch
\[A\sqcup B = \{(\text{Grün},a)\mid a\in A\}\cup\{(\text{Blau},b)\mid b\in B\}.\]
In der Informatik verwendet man gern left, right als Tags.

Mit jeder disjunkten Vereinigung ist eine Fallunterscheidung verbunden.
Liegt ein $x\in A\sqcup B$ vor, so muss entweder $x=(0,a)$ für ein
$a\in A$ oder $x=(1,b)$ für ein $b\in B$ sein. Bei einer gewöhnlichen
Vereinigung besteht dagegen kein ausschließendes Oder.

Wir fassen zwei Objekte $x,y$ zu einem \emph{geordneten Paar}%
\index{Paar}\index{geordnetes Paar} $(x,y)$ zusammen. Die beiden
Objekte müssen nicht unbedingt etwas miteinander zu tun haben, sie
dürfen völlig verschiedener Art sein. Im Unterschied zu einer Menge
spielt bei Paaren die Reihenfolge eine Rolle, auch darf dasselbe Objekt
zweimal vorkommen. Im Paar $t=(x,y)$ ist genau die Information über
$x,y$ enthalten. Das heißt, es lassen sich $x,y$ aus dem Paar
extrahieren. Man schreibt dafür $t_1=x$ und $t_2=y$. Die Schreibweise
$t_i$ heißt \emph{Indizierung}, es ist darin $i$ der
\emph{Index}\index{Index}.

Zwei Paare seien definitionsgemäß genau dann gleich, wenn sie
komponentenweise gleich sind,
\[(x,y) = (x',y')\defiff x=x'\land y=y'.\]
Die genannten Eigenschaften charakterisieren den Begriff Paar
im Wesentlichen, mehr müssen wir nicht wissen. Man hat sich trotzdem
auch mal überlegt, wie Paare in der reinen Mengenlehre dargestellt
werden können, wo alle Objekte Mengen sein sollen. Nach Kuratowski
sind Paare kodierbar als
\[(x,y) := \{\{x\},\{x,y\}\}.\]
Unter dem allgemeineren Begriff \emph{Tupel}\index{Tupel} fassen
wir eine beliebige endliche Zahl von Objekten in einer bestimmten
Reihenfolge zusammen. Tupel aus drei Objekten heißt \emph{Tripel},
die aus vier heißen \emph{Quadrupel}. Analog zu den Paaren ist ihre
Gleichheit definiert als
\[(x_1,\ldots,x_n) = (x_1,\ldots,x_n')
\defiff x_1=x_1'\land\ldots\land x_n=x_n'.\]
Zu zwei Mengen $X,Y$ kann man nun die Menge aller Paare betrachten,
deren erste Komponente $X$ entstammt, und deren zweite
Komponente $Y$ entstammt. Sie heißt \emph{Produktmenge}\index{Produktmenge}
oder \emph{kartesisches Produkt}\index{kartesisches Produkt}
der Mengen $X,Y$.
\begin{Definition}[Produktmenge]\newlinefirst
Das kartesische Produkt zweier Mengen $X,Y$ ist
\[X\times Y := \{(x,y)\mid x\in X\land y\in Y\}.\]
\end{Definition}
Genau genommen handelt es sich hierbei um eine Bildmenge, was bedeutet,
dass sich im rechten Term Existenzquantoren verstecken. Ausführlich
ausgeschrieben lautet der Term
\begin{align*}
X\times Y &= \{t\mid\exists x\in X\colon\exists y\in Y\colon t=(x,y)\}\\
&= \{t\mid\exists x\colon\exists y\colon x\in X\land y\in Y\land t=(x,y)\}.
\end{align*}
Wie jede Bildmenge ist das Produkt als Vereinigung darstellbar. Es ist
\[X\times Y = \bigcup_{x\in X}\bigcup_{y\in Y}\{(x,y)\}.\]
Die beiden kurzen Identitäten $X\times\emptyset = \emptyset$ und
$\emptyset\times Y = \emptyset$ gehen unmittelbar aus der Definition
hervor. Es verhält sich analog wie mit der Multiplikation einer
Zahl mit null. Eine sinnvolle Sichtweise, wie die Theorie der
Kardinalzahlen lehrt.

\begin{Satz}
Ist $A\subseteq X$ und $B\subseteq Y$, dann ist
$A\times B\subseteq X\times Y$.
\end{Satz}
\begin{Beweis}
Es liege $t$ in $A\times B$. Laut Definition existieren mithin
$a\in A$ und $b\in B$, so dass $t=(a,b)$. Wegen $A\subseteq X$ ist aber
auch $a\in X$ und wegen $B\subseteq Y$ ist auch $b\in Y$. Daher existieren
$a\in X$ und $b\in Y$, so dass $t=(a,b)$. Gemäß Definition heißt das,
$t\in X\times Y$. Gemäß Definition ist $A\times B$ somit eine Teilmenge
von $X\times Y$.\;\qedsymbol
\end{Beweis}

\begin{Satz}
Es gilt $X\times (A\cap B) = (X\times A)\cap (X\times B)$.
\end{Satz}
\begin{Beweis}
Es ginge zu Fuß. Aber Satz \ref{Index-in-Schnitt} ermöglicht die
kurze Termumformung
\begin{align*}
& X\times (A\cap B) = \bigcup_{x\in X}\bigcup_{y\in A\cap B} \{(x,y)\}
= \bigcup_{x\in X}\Big(\Big(\bigcup_{y\in A}\{(x,y)\}\Big)\cap \Big(\bigcup_{y\in B}\{(x,y)\}\Big)\Big)\\
&\quad = \Big(\bigcup_{x\in X}\bigcup_{y\in A}\{(x,y)\}\Big)\cap\Big(\bigcup_{x\in X}\bigcup_{y\in B}\{(x,y)\}\Big)
= (X\times A)\cap (X\times B).\,\qedsymbol
\end{align*}
\end{Beweis}

\newpage
\section{Abbildungen}

\subsection{Der Abbildungsbegriff}

Unter einer \emph{Abbildung}\index{Abbildung}, auch \emph{Funktion}%
\index{Funktion} genannt, verstehen wir ganz allgemein eine Zuordnung von
Elementen einer Definitionsmenge zu Elementen einer Zielmenge, bei der
zu \emph{jedem} Element der Definitionsmenge \emph{genau ein} Element
der Zielmenge gehört. Es hat allerdings ein wenig gedauert, bis
diese Vorstellung als die Förderliche erkannt wurde.

In der historischen Entwicklung kam ihr die speziellere Vorstellung
zuvor, dass eine Größe, etwa eine physikalische Größe, in einer
rechnerischen Abhängigkeit von einer anderen Größe steht. So steht
die Periodendauer der Schwingung eines Pendels in einer bestimmten
rechnerischen Abhängigkeit von der Pendellänge.

Eine recht pragmatische Vorstellung von einer Funktion vermittelt das Modell
der Black Box, das soll eine Rechenmaschine sein, deren innere Mechaniken
bzw. Elektroniken unbekannt bleiben. Speist man ein Argument $x$ in die
Black Box ein, spuckt sie daraufhin einen Wert $f(x)$ aus. Speist man
abermals dasselbe Argument ein, spuckt sie abermals denselben Wert aus.

Der Begriff der Abbildung ist für die Mathematik zentral.

\begin{Definition}[Abbildung]\newlinefirst
Eine Abbildung $f\colon X\to Y$ ist eine Relation $f=(X,Y,G)$ mit
$G\subseteq X\times Y$, die die beiden Eigenschaften
\begin{gather*}
\forall x\in X\colon\exists y\in Y\colon (x,y)\in G,\\
\forall x\in X\colon\forall y,y'\in Y\colon (x,y)\in G\land (x,y')\in G\cond y=y'
\end{gather*}
erfüllt. Man nennt $G$ den Graph, $X$ die Definitions- und
$Y$ die Zielmenge.
\end{Definition}
Genau genommen möchte man die Abbildung $f$ eigentlich nicht als mit
dem Tripel $(X,Y,G)$ identisch sehen, sondern als dasjenige Objekt,
dessen innere Information aus diesem Tripel besteht.

Zuweilen wird der Graph von $f$ auch einfach als $f$ bezeichnet.
Sollte dies verwirrend sein, schreibt man ausführlicher $G_f$ oder
$\mathrm{Graph}(f)$.

Statt $(x,y)\in G_f$ schreibt man üblicherweise $y=f(x)$. Es
wird $f(x)$ gelesen als »$f$ von $x$« oder »das Bild von $x$ unter
$f$«. Es wird $f\colon X\to Y$ gelesen als »$f$ ist eine Abbildung
von $X$ nach $Y$«. Besitzt ein $y\in Y$ ein $x\in X$ mit $y=f(x)$,
nennt man $x$ ein Urbildelement zu $y$.

\newpage
\subsection{Bild, Urbild}

\begin{Definition}[Bild]\newlinefirst
Die Bildmenge einer Menge $A\subseteq X$ unter der Abbildung
$f\colon X\to Y$ ist
\[f(A) := \{f(x)\mid x\in A\} = \{y\mid\exists x\in A\colon y=f(x)\}.\]
\end{Definition}
Insofern $y=f(x)$ als äquivalent zu $y\in\{f(x)\}$ befunden wird, ergibt
sich auch die Darstellung $f(A) = \bigcup_{x\in A} \{f(x)\}$.
Insbesondere in Programmiersprachen treten endliche Mengen als
Objekte auf. Die Berechnung verläuft mithin gemäß der rekursiven Festlegung
\[f(\emptyset) := \emptyset,\qquad f(\{x_1,\ldots,x_n\}) :=
f(\{x_1,\ldots,x_{n-1}\})\cup \{f(x_n)\},\]
für die auch die Bezeichnung $\mathrm{map}(f,A)$ gebräuchlich ist.

\begin{Definition}[Urbild]\newlinefirst
Das Urbild einer Menge $B$ unter $f\colon X\to Y$ ist
\[f^{-1}(B) := \{x\in X\mid f(x)\in B\} = \{x\in X\mid \exists y\in B\colon y=f(x)\}.\]
\end{Definition}
Dem Wesen des Abbildungsbegriffs entspringend, zeichnet sich die
Urbildoperation durch Verträglichkeit mit den Mengenoperationen aus,
was bei der Bildoperation nur zum Teil stimmt.

\begin{Satz}
Für jede Abbildung $f$ und beliebige Mengen $A,B,A_i$ gilt
\begin{align*}
f^{-1}(A\cap B) &= f^{-1}(A)\cap f^{-1}(B), &&\textstyle
f^{-1}(\bigcap_{i\in I} A_i) = \bigcap_{i\in I} f^{-1}(A_i),\\
f^{-1}(A\cup B) &= f^{-1}(A)\cup f^{-1}(B), &&\textstyle
f^{-1}(\bigcup_{i\in I} A_i) = \bigcup_{i\in I} f^{-1}(A_i).
\end{align*}
\end{Satz}
\begin{Beweis}
Den Beweis verschafft die äquivalente Umformung
\begin{align*}
&\textstyle x\in f^{-1}(\bigcap_{i\in I} A_i)
\iff f(x)\in\bigcap_{i\in I} A_i
\iff (\forall i\in I\colon f(x)\in A_i)\\
&\textstyle\quad\iff (\forall i\in I\colon x\in f^{-1}(A_i))
\iff x\in\bigcap_{i\in I} f^{-1}(A_i).
\end{align*}
Bei der Vereinigung verläuft die Umformung analog.\,\qedsymbol
\end{Beweis}

\noindent
Der Satz lehrt die wichtige Folgerung, dass die Urbilder zweier
disjunkter Mengen ebenfalls disjunkt sind. Allgemein überführt die
Urbildoperation eine disjunkte Zerlegung einer Menge in disjunkte
Urbilder. Ist die Zielmenge am feinsten zerlegt, besteht sie also
aus einelementigen Mengen, nennt man die Urbilder dieser Mengen
auch Fasern. Man beachte, dass ein Urbild oder eine Faser leer
sein kann.

Ist die Zielmenge bezüglich einer Ordnungsrelation angeordnet,
nennt man die Fasern auch \emph{Niveaumengen}\index{Niveaumenge}.
Diese Begrifflichkeit betrifft vor allem die Funktionen $f\colon X\to\R$
mit $X\subseteq\R^n$. Eine Faser $f^{-1}(\{c\})$, auch als $f(x)=c$
beschrieben, nennt man auch eine \emph{implizite Funktion}. Sie sind
in der analytischen Geometrie und der mehrdimensionalen Analysis von
großer Bedeutung.

\subsection{Komposition}

\begin{Definition}[Komposition]\newlinefirst
Sei $f\colon X\to Y$ und $g\colon Y\to Z$. Ihre Verkettung,
gelesen »$g$ nach $f$«, ist
\[(g\circ f)\colon X\to Z,\quad (g\circ f)(x):=g(f(x)).\]
\end{Definition}

\noindent
Oft liegt die Situation $f\colon X\to Y$ und $g\colon Y'\to Z$
mit $Y\subseteq Y'$ vor. Das ist aber nicht weiter schlimm. Es
darf dann $g\circ f := g|_Y\circ f$ gesetzt werden, wobei mit $g|_Y$ die
Einschränkung des Definitionsbereichs von $g$ auf $Y$ gemeint ist.

\begin{Definition}[Einschränkung]\newlinefirst
Sei $f\colon X\to Y$ und $A\subseteq X$. Die Einschränkung von $f$ auf $A$ ist
\[f|_A\colon A\to Y,\quad f|_A(x):=f(x).\]
\end{Definition}

\noindent
Die Abbildung $\id_X\colon X\to X$ mit $\id_X(x):=x$ heißt
\emph{identische Abbildung}\index{identische Abbildung}. Sie verhält
sich bei der Komposition neutral, das heißt, bezüglich
$f\colon X\to Y$ gilt $f\circ\id_X = f$ und $\id_Y\circ f=f$.

\subsection{Injektionen, Surjektionen, Bijektionen}

\begin{Definition}[Injektion]\newlinefirst
Eine Abbildung $f\colon X\to Y$ heißt injektiv\index{injektiv}, wenn
\[\forall x,x'\in X\colon f(x)=f(x')\cond x=x'.\]
\end{Definition}

\noindent
Erinnern wir uns an den Abschnitt \emph{Logik mit Gleichheit}, fällt
auf, dass die Definition der Injektivität als Umkehrung der
Ersetzungsregel betrachtbar ist. Das heißt, für eine auf den Werten
der Terme $t,t'$ definierte Injektion $f$ gilt die Äquivalenz
\[t=t' \iff f(t)=f(t').\]
Die Injektionen vermitteln genau die \emph{Äquivalenzumformungen}%
\index{Aequivalenzumformung@Äquivalenzumforumung} von Gleichungen.
In der Schulmathematik sind das zu Parametern $a,b$ mit
$a\ne 0$ die Funktionen
\[\begin{array}{@{}r@{\quad}r@{\,}l}
f_a\colon\R\to\R, & f_a(x) &:=ax,\\[2pt]
g_b\colon\R\to\R, & g_b(x) &:=x+b.
\end{array}
\]

\begin{Satz}
Eine Abbildung $g$ mit $g\circ f = \id$ heißt Linksinverse von $f$.
Eine Abbildung $f\colon X\to Y$ mit nichtleerem $X$ ist genau dann
injektiv, wenn sie mindestens eine Linksinverse besitzt.
\end{Satz}
\begin{Beweis}
Sei $g$ eine Linksinverse von $f$. Seien $x,x'$ fest, aber beliebig,
und sei $f(x)=f(x')$. Mithin gilt $g(f(x))=g(f(x'))$. Weil $g$ eine
Linksinverse ist, hat man aber $g(f(x))=x$ und $g(f(x'))=x'$, womit
sich wie gewünscht $x=x'$ ergibt.

Sei $f$ injektiv. Mit $X\ne\emptyset$ liegt irgendein $a\in X$ vor.
Sofern $y\in f(X)$ ist, liegt außerdem ein $x$ mit $y=f(x)$ vor.
Es wird $g$ festgelegt per Fallunterscheidung
\[g(y) := \begin{cases}
x & \text{wenn}\;y\in f(X),\\
a & \text{wenn}\;y\notin f(X).
\end{cases}\]
Sie ist verhält sich so, dass $g(f(x))=x$ für jedes $x\in X$ gilt,
denn mit $x\in X$ ist $f(x)\in f(X)$. Somit existiert mit $g$ eine
Linksinverse.\,\qedsymbol
\end{Beweis}

\begin{Definition}[Surjektion]\newlinefirst
Eine Abbildung $f\colon X\to Y$ heißt surjektiv\index{surjektiv},
wenn $f(X)=Y$ ist.
\end{Definition}

\noindent
Weil $f(X)\subseteq Y$ allgemeingültig ist, genügt es generell,
$Y\subseteq f(X)$ zu zeigen.

\begin{Definition}[Bijektion]\newlinefirst
Eine Abbildung heißt bijektiv, wenn sie sowohl injektiv als auch
surjektiv ist.
\end{Definition}

\begin{Satz}
Jede Bijektion $f$ besitzt eine eindeutig bestimmte Abbildung, welche
sowohl ihre einzige Linksinverse als auch ihre einzige Rechtsinverse
ist. Man nennt sie die Umkehrabbildung $f^{-1}$.
\end{Satz}
\begin{Beweis}
Sei $f\colon X\to Y$ bijektiv. Es existiert somit mindestens eine
Linksinverse $g$ und mindestens eine Rechtsinverse $h$. Weil die
Verkettung das Assoziativgesetz erfüllt, darf man rechnen
\[g = g\circ\id_Y = g\circ (f\circ h) = (g\circ f)\circ h
= {\id_X}\circ h = h.\]
Sei nun $g'$ eine weitere Linksinverse und $h'$ eine weitere
Rechtsinverse. Wiederholt man die obige Rechnung abermals, erhält man
$g'=h$ und $g'=h'$. Ergo gilt $g = h = g' = h'$.\,\qedsymbol
\end{Beweis}


