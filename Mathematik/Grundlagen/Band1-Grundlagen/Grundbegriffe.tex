
\chapter{Grundbegriffe der Mathematik}

\section{Aussagenlogik}

\subsection{Aussagenlogische Formeln}

Aussagen in der Aussagenlogik sind entweder wahr oder falsch,
etwas dazwischen gibt es nicht, das nennt man auch das \emph{Prinzip
der Zweiwertigkeit}\index{Prinzip der Zweiwertigkeit}.
Wir schreiben $0=\text{falsch}$ und $1=\text{wahr}$, das ist schön
kurz und knapp.

Für die Aussage »$n$ ist ohne Rest durch $m$ teilbar« bzw.
»$m$ teilt $n$«, schreibt man kurz $m|n$. Aus Aussagen lassen sich
in der Aussagenlogik zusammengesetzte Aussagen bilden, z.\,B.
\[\text{Aus $2|n$ und $3|n$ folgt, dass $6|n$},\]
als Formel:
\[2|n\land 3|n \implies 6|n.\]
Streng genommen handelt es sich hierbei um eine Aussageform, da die
Aussage von einer Variable abhängig ist. Nachdem für $n$ eine Zahl
eingesetzt wurde, ergibt sich daraus eine Aussage, in diesem Fall
immer eine wahre Aussage.

Eine zusammengesetzte Aussage wird auch \emph{aussagenlogische Formel}
genannt. Aussagenlogische Formeln haben eine innere Struktur. Um diese
untersuchen zu können, werden logische Variablen betrachtet,
das sind solche Variablen, die für eine Aussage stehen. Eine
logische Variable wird durch einen lateinischen Großbuchstaben
am Anfang des Alphabetes beschrieben und kann nur mit den
Wahrheitswerten falsch oder wahr belegt werden. Die genannte Formel
besitzt die Struktur
\[A\land B \implies C.\]
In der Formel treten Verknüpfungen von Aussagen auf, das sind
$\land$ und $\Rightarrow$. Es gibt die grundlegenden Verknüpfungen
$\neg,\land,\lor,\Rightarrow,\Leftrightarrow$. Die Bindungsstärke
der gelisteten Verknüpfungen ist absteigend, so wie Punktrechnung
vor Strichrechnung gilt. Das $\neg$ bindet stärker als $\land$,
bindet stärker als $\lor$, bindet stärker als $\Rightarrow$,
bindet stärker als $\Leftrightarrow$. Die Verknüpfungen sind
in Tabelle \ref{tab:logische-Verknuepfungen} definiert.
Anstelle von $\neg A$ schreibt man auch $\overline A$.

\begin{table}
\centering
\begin{tabular}{cc}
\begin{tabular}{c|c}
$A$ & $\neg A$\\
\hline
$0$ & $1$\\
$1$ & $0$
\end{tabular}
&\qquad \begin{tabular}{c|c|c|c|c|c}
$A$ & $B$ & $A\land B$ & $A\lor B$ & $A\Rightarrow B$ & $A\Leftrightarrow B$\\
\hline
$0$ & $0$ & $0$ & $0$ & $1$ & $1$\\
$1$ & $0$ & $0$ & $1$ & $0$ & $0$\\
$0$ & $1$ & $0$ & $1$ & $1$ & $0$\\
$1$ & $1$ & $1$ & $1$ & $1$ & $1$
\end{tabular}
\end{tabular}
\caption{Definition der grundlegenden logischen Verknüpfungen.}
\label{tab:logische-Verknuepfungen}
\end{table}

\begin{table}
\centering
\begin{tabular}{c|c|c|c|c}
$A$ & $B$ & $A\land B$ & $B\land A$ & $A{\land}B\Rightarrow B{\land}A$\\
\hline
$0$ & $0$ & $0$ & $0$ & $1$\\
$1$ & $0$ & $0$ & $0$ & $1$\\
$0$ & $1$ & $0$ & $0$ & $1$\\
$1$ & $1$ & $1$ & $1$ & $1$
\end{tabular}
\caption{Wahrheitstafel zu $A\land B\Rightarrow B\land A$.}
\label{tab:Wahrheitstafel1}
\end{table}

Es gibt Formeln, die immer wahr sind, unabhängig davon, mit
welchen Wahrheitswerten die Variablen belegt werden.
\begin{Definition}[Tautologie]\index{Tautologie}\mbox{}\\*
Ist $\varphi$ eine Formel, die bezüglich jeder möglichen
Variablenbelegung erfüllt ist, dann nennt man $\varphi$ eine Tautologie
und schreibt dafür kurz $\models\varphi$.
\end{Definition}
Z.\,B. gilt
\[\models A\land B\implies B\land A.\]
Es lässt sich leicht überprüfen, ob eine Formel tautologisch ist.
Dazu wird einfach die Wahrheitstafel zu dieser Formel aufgestellt,
hier Tabelle $\ref{tab:Wahrheitstafel1}$.
Die Wahrheitstafel\index{Wahrheitstafel} ist eine Wertetabelle,
die zu jeder Variablenbelegung den Wahrheitswert der Formel angibt.
Bei einer tautologischen Formel enthält die Ergebnisspalte in jeder
Zeile den Wert $1$.

Zwei wichtige Metaregeln, die Einsetzungsregel und die
Ersetzungsregel, ermöglichen das Rechnen mit aussagenlogischen
Formeln. Die Einsetzungsregel ermöglicht es, aus schon bekannten
Tautologien neue bilden zu können, ohne jedes mal eine Wahrheitstafel
aufstellen zu müssen. Die Ersetzungsregel ermöglicht die Umformung
von Formeln.

\begin{Satz}[Einsetzungsregel]\index{Einsetzungsregel}\mbox{}\\*
Sei $v$ eine logische Variable. Ist $\varphi$ eine tautologische
Formel, dann ergibt sich wieder eine tautologische Formel, wenn man
jedes Vorkommen von $v$ in $\varphi$ durch eine Formel $\psi$ ersetzt.
Kurz:
\[(\models \varphi )\implies (\models \varphi [v:=\psi]).\]
Das gilt auch für die simultane Substitution:
\[(\models \varphi )\implies
(\models \varphi [v_1:=\psi_1,\ldots ,v_n:=\psi_n]).\]
\end{Satz}
\strong{Begründung.} Die Variable $v$ kann in $\varphi$
frei mit einem Wahrheitswert belegt werden, nach Voraussetzung
ist $\varphi$ dabei immer erfüllt. Somit ist $\varphi$ auch
erfüllt, wenn $v$ mit dem Wahrheitswert von $\psi$ belegt wird.
Dann muss aber auch $\varphi[v:=\psi]$ unter einer beliebigen Belegung
wahr sein.\;\qedsymbol

\newpage
\begin{Satz}[Ersetzungsregel]\index{Ersetzungsregel}%
\label{Ersetzungsregel}\mbox{}\\*
Sei $F(\varphi)$ eine Formel, welche von der Teilformel $\varphi$
abhängig ist. Sei außerdem $\varphi$ äquivalent zu $\psi$.
Dann sind auch $F(\varphi)$ und $F(\psi)$ äquivalent. Kurz:
\[(\models\varphi\Leftrightarrow\psi)
\implies (\models F(\varphi)\Leftrightarrow F(\psi)).\]
\end{Satz}
\strong{Begründung.}
Die Äquivalenz von $\varphi$ und $\psi$ erzwingt, dass $\psi$
unter einer beliebigen Belegung den gleichen Wahrheitswert besitzt
wie $\varphi$. Da $F(0)\Leftrightarrow F(0)$ und
$F(1)\Leftrightarrow F(1)$ gilt, muss also
$F(\varphi)\Leftrightarrow F(\psi)$ gelten.\;\qedsymbol

\begin{Satz}[Kleine Metaregel]\mbox{}\\*
Es gilt $\models\varphi$ und $\models\psi$
genau dann, wenn $\models\varphi\land\psi$.
\end{Satz}
\strong{Beweis.}
Sind $\varphi,\psi$ tautologisch, dann dürfen sie durch
den Wahrheitswert wahr ersetzt werden. Unter dieser Voraussetzung
ist $\varphi\land\psi$ gleichbedeutend mit $1\land 1$, demnach
auch tautologisch.

Sei nun umgekehrt $\varphi\land\psi$ tautologisch. Es müssen
zwingend auch $\varphi$ und $\psi$ wahr sein, denn sonst wäre
$\varphi\land\psi$ falsch.\;\qedsymbol

\begin{Satz}[Kleine Abtrennungsregel]\mbox{}\\*
Aus $\models\varphi$ und $\models\varphi\Rightarrow\psi$
folgt $\models\psi$.\\
Aus $\models\varphi$ und $\models\varphi\Leftrightarrow\psi$
folgt $\models\psi$.
\end{Satz}
\strong{Beweis.}
Ist $\varphi$ tautologisch, dann darf es durch den Wahrheitswert
wahr ersetzt werden. Unter dieser Voraussetzung ist
$\varphi\Rightarrow\psi$ gleichbedeutend mit $1\Rightarrow\psi$.
Diese Formel kann nur erfüllt sein, wenn auch $\psi$ wahr ist.
Da aber $\varphi\Rightarrow\psi$ tautologisch sein soll,
muss damit zwingend auch $\psi$ tautologisch sein.
Für $\varphi\Leftrightarrow\psi$ ist die Argumentation
analog.\;\qedsymbol

\begin{Satz}[Abtrennung von Implikationen]\mbox{}\\*
Aus $\models\varphi\Leftrightarrow\psi$
folgt $\models\varphi\Rightarrow\psi$.
\end{Satz}
\strong{Beweis.}
Man zeigt
\[\models (A\Leftrightarrow B)
\Leftrightarrow (A\Rightarrow B)\land (B\Rightarrow A)\]
mittels Wahrheitstafel. Gemäß der Einsetzungsregel gilt dann auch
\[\models (\varphi\Leftrightarrow\psi)
\Leftrightarrow (\varphi\Rightarrow\psi)\land (\psi\Rightarrow\varphi).\]
Mit der kleinen Abtrennungsregel und der Voraussetzung erhält man
\[\models (\varphi\Rightarrow\psi)\land (\psi\Rightarrow\varphi).\]
Gemäß der kleinen Metaregel ergibt sich schließlich
$\models \varphi\Rightarrow\psi$.\;\qedsymbol

\newpage
\begin{Definition}[Äquivalente Formeln]\mbox{}\\*
Zwei Formeln $\varphi,\psi$ heißen äquivalent, wenn die
Äquivalenz $\varphi\Leftrightarrow\psi$ tautologisch ist, kurz
\[(\varphi\equiv\psi)\defiff(\models\varphi\Leftrightarrow\psi).\]
\end{Definition}

\begin{Satz}
Die Relation $\varphi\equiv\psi$ ist eine Äquivalenzrelation, d.\,h.
es gilt
\begin{align}
& \varphi\equiv\varphi, && (\text{Reflexivität})\\
& (\varphi\equiv\psi)\implies (\psi\equiv\varphi), && (\text{Symmetrie})\\
& (\varphi\equiv\psi)\land (\psi\equiv\chi)\implies (\varphi\equiv\chi). && (\text{Transitivität})
\end{align}
\end{Satz}

\subsection{Boolesche Algebra}%
\index{boolesche Algebra}

\begin{table}
\begin{center}
\begin{tabular}{c@{\qquad}c@{\qquad}l}
\toprule
\strong{UND}&
\strong{ODER}&
\strong{Bezeichnung}\\
\midrule
$A\land 0\equiv 0$ &
$A\lor 1\equiv 1$ &
Extremalgesetze\\

$A\land\overline A\equiv 0$ &
$A\lor\overline A\equiv 1$ &
Komplementärgesetze\\

$A\land A\equiv A$ &
$A\lor A\equiv A$ &
Idempotenzgesetze\\

$A\land 1\equiv A$ &
$A\lor 0\equiv A$ &
Neutralitätsgesetze\\
\midrule
$A\land B\equiv B\land A$ &
$A\lor B\equiv B\lor A$ &
Kommutativgesetze\\

$A\land (B\land C)\equiv (A\land B)\land C$ &
$A\lor(B\lor C)\equiv (A\lor B)\lor C$ &
Assoziativgesetze\\

$\overline{A\land B}\equiv\overline A\lor\overline B$ &
$\overline{A\lor B}\equiv\overline A\land\overline B$ &
De morgansche Gesetze\\

$A\land (A\lor B)\equiv A$ &
$A\lor (A\land B)\equiv A$ &
Absorptionsgesetze\\
\bottomrule
\end{tabular}
\caption{Die Regeln der booleschen Algebra.}
\label{tab:boolesche-Algebra}
\end{center}
\end{table}

Die Regeln in Tabelle \ref{tab:boolesche-Algebra} gewinnt man
alle mittels Wahrheitstafel. Gemäß der Einsetzungsregel dürfen für
die Variablen auch Formeln eingesetzt werden, die griechischen
Formelvariablen benötigt man somit nicht mehr.

Weiterhin gelten die Distributivgesetze
\begin{align}
A\land(B\lor C) &\equiv (A\land B)\lor (A\land C),\\
A\lor(B\land C) &\equiv (A\lor B)\land (A\lor C).
\end{align}
Schließlich gibt es noch das Involutionsgesetz
\begin{equation}
\overline {\overline A}\equiv A.
\end{equation}
Die Implikation und die Äquivalenz lassen sich auf NICHT, UND, ODER
zurückführen:%
\begin{align}
A\Rightarrow B &\equiv \overline A\lor B,\\
A\Leftrightarrow B &\equiv (A\Rightarrow B)\land (B\Rightarrow A).
\end{align}
Mit den bisher genannten Regeln lassen sich aussagenlogische Formeln
auf einfache Art umformen. Z.\,B. ist die Formel $1\Rightarrow A$
äquivalent zu $A$. Man findet
\[1\Rightarrow A\enspace\equiv\enspace\overline 1\lor A\enspace\equiv\enspace 0\lor A\enspace\equiv\enspace A.\]
Natürlich kann man alternativ mittels Wahrheitstafel auch
\[\models(1\Rightarrow A)\Leftrightarrow A\]
überprüfen.

\begin{Satz}[Formel zum Modus ponens]%
\label{Formel-Modus-ponens}\mbox{}\\*
Es gilt $\models A\land (A\Rightarrow B)\Rightarrow B$.
\end{Satz}
\strong{Beweis.} Gemäß den Regeln der booleschen Algebra ergibt sich
\begin{align}
& A\land (A\Rightarrow B)\Rightarrow B\\
& \equiv A\land (\overline A\lor B)\Rightarrow B && \text{(Zerlegung von »$\Rightarrow$«)}\\
& \equiv \overline{A\land (\overline A\lor B)}\lor B && \text{(Zerlegung von »$\Rightarrow$«)}\\
& \equiv \overline A\lor\overline{\overline A\lor B}\lor B && \text{(De Morgan)}\\
& \equiv \overline A\lor (\overline{\overline A}\land\overline B)\lor B && \text{(De Morgan)}\\
& \equiv \overline A\lor (A\land\overline B)\lor B && \text{(Involutionsgesetz)}\\
& \equiv ((\overline A\lor A)\land(\overline A\lor\overline B))\lor B && \text{(Distributivgesetz)}\\
& \equiv (1\land(\overline A\lor\overline B))\lor B && \text{(Komplementärgesetz)}\\
& \equiv (\overline A\lor\overline B)\lor B && \text{(Absorptionsgesetz)}\\
& \equiv \overline A\lor(\overline B\lor B) && \text{(Assoziativgesetz)}\\
& \equiv \overline A\lor 1 && \text{(Komplementärgesetz)}\\
& \equiv 1.\;\qedsymbol && \text{(Absorptionsgesetz)}
\end{align}
Von der Ersetzungsregel (Satz \ref{Ersetzungsregel}), also
\[\varphi\equiv\psi\enspace
\text{impliziert}\enspace F(\varphi)\equiv F(\psi),\]
wurde ständig stillschweigend Gebrauch gemacht, nämlich bei jeder
Umformung einer Teilformel.

\begin{Satz}[Regel zur Kontraposition]\index{Kontraposition}\mbox{}\\*
Es gilt $A\Rightarrow B\equiv \overline B\Rightarrow\overline A$.
\end{Satz}
\strong{Beweis.} Man findet
\begin{align}
&A\Rightarrow B\\
&\equiv \overline A\lor B && (\text{Zerlegung von »$\Rightarrow$«})\\
&\equiv B\lor\overline A && (\text{Kommutativgesetz})\\
&\equiv \overline{\overline B}\lor\overline A && (\text{Involutionsgesetz})\\
&\equiv \overline B\Rightarrow\overline A.\;\qedsymbol
  && (\text{Zerlegung von »$\Rightarrow$«)}
\end{align}

\newpage
\subsection{Formale Beweise}
\begin{Definition}[Semantische Implikation]\mbox{}\\*
Sei $M=\{\varphi_1,\varphi_2,\ldots,\varphi_n\}$ eine Menge von
Formeln und sei $\psi$ eine weitere Formel. Man sagt dann, $M$
impliziert $\psi$, kurz $M\models\psi$, wenn jede Belegung von
logischen Variablen, die alle Formeln in $M$ erfüllt, auch $\psi$
erfüllt.
\end{Definition}
Das klingt etwas kompliziert, ist es aber eigentlich nicht. Man schaut
sich die große Wahrheitstafel an, in der alle Formeln vorkommen,
jede Formel in einer neuen Spalte.
Ergibt sich in einer Zeile bei allen Formeln in $M$ eine 1, dann muss
auch $\psi$ in dieser Zeile den Wahrheitswert 1 besitzen.

Die Aussage $\models\varphi$ ist mit $\{\}\models\varphi$
gleichbedeutend, denn bei einer leeren Formelmenge werden keine
Belegungen ausgeschlossen, $\varphi$ muss also jede Belegung
erfüllen. Der Definition nach ist $\varphi$ dann eine Tautologie.

Man beobachtet außerdem, dass $\{\varphi\}\models\psi$ mit
$\models\varphi\Rightarrow\psi$ übereinstimmt. Hat nämlich
$\varphi$ den Wahrheitswert 0, dann ist $\varphi\Rightarrow\psi$
immer erfüllt, ohne dass der Wahrheitswert von $\psi$ dabei eine
Rolle spielt. Solche Belegungen entfallen auch bei
$\{\varphi\}\models\psi$. Nun darf $\varphi$ als wahr vorausgesetzt
werden. Wäre $\psi$ nun falsch, dann ist $\varphi\Rightarrow\psi$
nicht mehr erfüllt, also auch $\models\varphi\Rightarrow\psi$ falsch.
In diesem Fall ist aber auch $\{\varphi\}\models\psi$ falsch.
Es verbleibt nun die Situation, dass sowohl $\varphi$ also auch
$\psi$ wahr sind. Mit diesen Belegungen bleibt dann auch
$\{\varphi\}\models\psi$ unverletzt.

\begin{Satz}[Deduktionstheorem]\index{Deduktionstheorem}\mbox{}\\*
Es gilt $M\cup\{\varphi\}\models\psi$ genau dann, wenn
$M\models\varphi\Rightarrow\psi$.
\end{Satz}
\strong{Beweis.} Man hat
\begin{equation}
M\cup\varphi = \{\varphi_1,\ldots,\varphi_n,\varphi\}.
\end{equation}
Dass alle diese Formeln unter einer Belegung erfüllt sein sollen,
ist aber gleichbedeutend damit, dass die Aussage%
\begin{equation}
\varphi_1\land\ldots\land\varphi_n\land\varphi
\end{equation}
unter dieser Belegung erfüllt ist. Wie bereits erläutert, gilt%
\begin{equation}
(\{\varphi_1\land\ldots\land\varphi_n\land\varphi\}\models\psi)
\iff (\models \varphi_1\land\ldots\land\varphi_n\land\varphi\Rightarrow\psi).
\end{equation}
Mittels boolescher Algebra findet man nun
\begin{align}
& \varphi_1\land\ldots\land\varphi_n\land\varphi\Rightarrow\psi\\
& \equiv \overline{\varphi_1\land\ldots\land\varphi_n\land\varphi}\lor\psi\\
& \equiv \overline{\varphi_1\land\ldots\land\varphi_n}\lor\overline\varphi\lor\psi\\
& \equiv \overline{\varphi_1\land\ldots\land\varphi_n}\lor(\varphi\Rightarrow\psi)\\
& \equiv \varphi_1\land\ldots\land\varphi_n\Rightarrow (\varphi\Rightarrow\psi)
\end{align}
Schließlich gilt aber auch wieder
\begin{equation}
(\models \varphi_1\land\ldots\land\varphi_n\Rightarrow(\varphi\Rightarrow\psi))
\iff (\{\varphi_1\land\ldots\land\varphi_n\}\models\varphi\Rightarrow\psi).\;\qedsymbol
\end{equation}

\newpage
\begin{Definition}[Schlussregel]\index{Schlussregel}\mbox{}\\*
Sei $M$ eine Menge von Formeln, die Formelvariablen enthalten
und $\psi$ eine Formelvariable. Ist die Aussage $M\models\psi$ wahr,
unabhängig davon, welche
Formeln für die Formelvariablen eingesetzt werden, dann spricht man
von einer Schlussregel.
\end{Definition}

\begin{Satz}[Modus ponens]\index{Modus ponens}\mbox{}\\*
Es gilt die Schlussregel $\{\varphi,\varphi\Rightarrow\psi\}\models\psi$.
\end{Satz}
\strong{Beweis.} Gemäß Deduktionstheorem gilt
\[(\{\varphi,\varphi\Rightarrow\psi\}\models\psi)
\iff (\models \varphi\land(\varphi\Rightarrow\psi)\Rightarrow\psi).\]
Gemäß Satz \ref{Formel-Modus-ponens} ist die rechte
Seite wahr.\;\qedsymbol

Schlussregeln ermöglichen es uns, aus wahren Aussagen weitere
wahre Aussagen zu gewinnen. Die Belegung mit logischen Variablen
tritt nun in den Hintergrund, besonders dann, wenn die Formeln keine
logischen Variablen mehr enthalten. Sind $A$ und $A\Rightarrow B$
wahre Aussagen, dann muss gemäß Modus ponens auch $B$ eine wahre
Aussage sein.

Ein Beispiel dazu. Sei $A(n):=(2|n)$ die Aussage »$2$ teilt $n$«
und $B(n):=(4|n^2)$ die Aussage »$4$ teilt $n^2$«.
Nun gilt $A(n)\Rightarrow B(n)$ für jede beliebige ganze
Zahl, welche für $n$ eingesetzt wird. Gemäß Modus ponens ist der Schluss%
\[\{A(n), A(n)\Rightarrow B(n)\}\models B(n)\]
richtig. Ausgehend von »$2$ teilt $10$« können wir
damit »$4$ teilt $100$« schlussfolgern.

\begin{Definition}[Beweis]\index{Beweis}\mbox{}\\*
Eine Aussage ist sicher dann wahr, wenn sie mittels Schlussregeln
aus schon bekannten wahren Aussagen gefolgert werden kann. Die Kette
von Schlüssen heißt Beweis dieser Aussage.
\end{Definition}
Ein Beispiel dazu. Angenommen wir wissen, dass die Aussage $A$ wahr
ist. Außerdem ist bekannt, dass $A\Rightarrow B$ und $B\Rightarrow C$
wahr sind. Gemäß Modus ponens ist dann auch $B$ wahr. Nochmalige
Anwendung des Modus ponens liefert die Wahrheit von $C$.

Der formale Beweis von $C$ schaut so aus:
\[
\begin{tabular}{ll}
1.\;$A$, & (Prämisse)\\
2.\;$A\Rightarrow B$, & (Prämisse)\\
3.\;$B\Rightarrow C$, & (Prämisse)\\
4.\;$B$, & (MP, 1, 2)\\
5.\;$C$ & (MP, 4, 3)
\end{tabular}
\]
In Klammern steht immer die Begründung für die jeweilige Aussage.
Der Modus ponens wurde mit MP abgekürzt.

\newpage
\subsection{Notwendige und hinreichende Bedingungen}

Manchmal sagt man, eine Bedingung ist für eine bestimmte Aussage
notwendig. Das ist ein schon bekannter logischer Zusammenhang.
Sei $B$ die Bedingung und $A$ die Aussage. Ist $B$ falsch, dann
kann $A$ niemals wahr sein. Ist $B$ wahr, dann ist $A$ beliebig,
denn nur weil die notwendige Bedingung $B$ zutrifft, heißt das nicht,
dass die Aussage $A$ zwingend wahr sein muss. Dieser Zusammenhang
wird nun gerade genau durch die Wahrheitstafel von $A\Rightarrow B$
wiedergegeben. Man erhält%
\[(\text{$B$ ist notwendig für $A$})\;\equiv\; (A\Rightarrow B).\]
Die Sprechweise »$B$ ist hinreichend für $A$« drückt dagegen aus,
dass die Wahrheit von $A$ mit der Wahrheit von $B$ sichergestellt
ist. Falls $B$ jedoch falsch ist, ist der Wahrheitsgehalt von $A$
beliebig. Dieser Zusammenhang wird gerade durch die Wahrheitstafel
von $B\Rightarrow A$ wiedergegeben. Man erhält%
\[(\text{$B$ ist hinreichend für $A$})\;\equiv\; (B\Rightarrow A).\]
Um sich pedantischer ausdrücken, sprechen manche von notwendigen,
aber nicht hinreichenden Bedingungen, bzw. von hinreichenden,
aber nicht notwendigen Bedingungen.

Gemäß
$(A\Leftrightarrow B)\equiv (A\Rightarrow B)\land (B\Rightarrow A)$
ergibt sich
\[(\text{$B$ ist notwendig und hinreichend für $A$})\;\equiv\;(B\Leftrightarrow A).\]

\noindent
Weitere Sprechweisen für $A\Rightarrow B$ sind »$A$ impliziert $B$«
und »$A$ zieht $B$ nach sich« sowie »aus $A$ folgt $B$«.

Ist $B$ hinreichend für $A$, dann kann man sich bei $A$ sicher sein,
sofern die Bedingung $B$ überprüft wurde.

Ist $B$ nur notwendig für $A$, dann ist durch eine Überprüfung von $B$
nicht viel Wissen über $A$ gewonnen, man darf sich nicht sicher sein,
dass $A$ wahr ist. Lediglich falls $B$ falsch
ist, lässt sich mittels Kontraposition%
\[A\Rightarrow B\;\equiv\;\overline B\Rightarrow\overline A\]
ableiten, dass dann auch $A$ falsch sein muss.

Man gewinnt den folgenden Zusammenhang:
\[(\text{$B$ ist notwendig für $A$})\;\equiv\;
(\text{$\overline B$ ist hinreichend für $\overline A$}).\]
Sind für eine Aussage $A$ mehrere Bedingungen $B_k$ notwendig,
dann heißt das, $A$ ist schon falsch, wenn nur eine der $B_k$
falsch ist. Die Formel dazu ist
\[A\Rightarrow B_1\land B_2\land\ldots\land B_n.\]
Sind für eine Aussage $A$ mehrere Bedingungen $B_k$ hinreichend,
dann heißt das, $A$ ist schon dann richtig, wenn nur eine der $B_k$
richtig ist. Die Formel dazu ist
\[B_1\lor B_2\lor\ldots\lor B_n\Rightarrow A.\]

\newpage
\subsection{Widerspruchsbeweise}
Mittels boolescher Algebra oder einer Wahrheitstafel überzeugt man
sich leicht von
\[\models (A\Rightarrow B)\land (A\Rightarrow\overline B)\Rightarrow\overline A.\]
Unter Heranziehung des Deduktionstheorems ist das äquivalent zu
\[\{A\Rightarrow B,\;A\Rightarrow\overline B\}\models\overline A.\]
Angenommen, man konnte die Aussagen $B$ und $\overline B$
unter Annahme von $A$ beweisen, dann gilt $\{A\}\models B$
und $\{A\}\models\overline B$. Gemäß Deduktionstheorem
bedeutet das jedoch $\models A\Rightarrow B$ und
$\models A\models\overline B$. Da diese Bedingungen tautologisch
sind, können sie entfallen, übrig bleibt $\models\overline A$.

Wir gelangen zur folgenden Schlussregel.

\begin{Satz}[Reductio ad absurdum]\mbox{}\\*
Kann man unter Annahme einer Prämisse $\varphi$ sowohl
$\psi$ als auch $\overline\psi$ beweisen, dann muss
die Negation von $\varphi$ tautologisch sein:
\[\text{$\{\varphi\}\models\psi$
und $\{\varphi\}\models\overline\psi$
impliziert $\models\overline\varphi$}.\]
\end{Satz}

\noindent
Diese Schlussregel lässt sich noch ein wenig verallgemeinern.
Man überzeugt sich mittels boolescher Algebra oder Wahrheitstafel von
\[\models (K\land A\Rightarrow B)\land (K\land A\Rightarrow\overline B)
\Rightarrow (K\Rightarrow\overline A).\]
Nochmals wird das Deduktionstheorem angewendet:
\[\{K\land A\Rightarrow B,\;K\land A\Rightarrow\overline B\}
\models K\Rightarrow\overline A.\]
Für $K$ lässt sich eine konjunktive Aussage
$\varphi_1\land\ldots\land\varphi_n$ einsetzen.
Definiert man $M:=\{\varphi_1,\ldots,\varphi_n\}$, dann gilt
\[(M\cup\{A\}\models\psi)\iff (\models K\land A\Rightarrow\psi)\]
gemäß Deduktionstheorem. Die restliche Überlegung gestaltet
sich wie zuvor. Insgesamt erhält man das folgende Ergebnis.
\begin{Satz}[Reductio ad absurdum]\mbox{}\\*
Sei $M$ eine endliche Formelmenge. Es gilt:
\[\text{$M\cup\{\varphi\}\models\psi$
und $M\cup\{\varphi\}\models\overline\psi$
impliziert $M\models\overline\varphi$}.\]
\end{Satz}

\noindent
Aus der Reductio ad absurdum lässt sich nun ein
Beweisverfahren erstellen. Man setzt $\varphi\equiv\overline A$ ein
und beachtet $A\equiv\neg\neg A$. Aus $\overline A\models\psi$
und $\overline A\models\overline\psi$ lässt sich wie gezeigt
$\models A$ schlussfolgern. Nimmt man also $\overline A$ an,
und zeigt damit den Widerspruch, dass sowohl $\psi$ als auch
$\overline\psi$, dann hat man einen Beweis für $A$.

\newpage
\section{Prädikatenlogik}\index{Prädikatenlogik}
\subsection{Endliche Bereiche}
In diesem Abschnitt wird der Übergang von der Aussagenlogik in
die Prädikatenlogik beschrieben. Eine Prädikat $P$ ist eine Aussageform,
die einem Objekt $x$ einen Wahrheitswert $P(x)$ zuordnet. Z.\,B.
ist $P(x)\equiv (x<4)$ ein Prädikat. Je nachdem was für eine Zahl
für $x$ eingesetzt wird, ergibt sich entweder wahr oder falsch.

\begin{Definition}[Allquantor]\index{Allquantor}\mbox{}\\*
Der Allquantor für endliche Objektbereiche
ist rekursiv definiert gemäß%
\[\bigwedge_{k=1}^0 P(x_k) :\equiv 1,\qquad
\bigwedge_{k=1}^n P(x_k) :\equiv P(x_n)\land\bigwedge_{k=1}^{n-1} P(x_k).\]
\end{Definition}

\begin{Definition}[Existenzquantor]\index{Existenzquantor}\mbox{}\\*
Der Existenzquantor für endliche Objektbereiche
ist rekursiv definiert gemäß%
\[\bigvee_{k=1}^0 P(x_k) :\equiv 0,\qquad
\bigvee_{k=1}^n P(x_k) :\equiv P(x_n)\lor\bigvee_{k=1}^{n-1} P(x_k).\]
\end{Definition}

\noindent
Das allquantifizierte Prädikat ist nur dann wahr, wenn $P(x_k)$ für
jedes $x_k$ erfüllt ist. Man bekommt die aussagenlogische Formel%
\[\bigwedge_{k=1}^n P(x_k)
\enspace\equiv\enspace P(x_1)\land P(x_2)\land\ldots\land P(x_n).\]
Meistens benutzen wir die Schreibweisen
\[(\forall x\in M)P(x) \equiv \bigwedge_{k=1}^n P(x_k),\qquad
(\exists x\in M)P(x) \equiv \bigvee_{k=1}^n P(x_k),\]
wobei $M=\{x_1,x_2,\ldots,x_n\}$ die Zusammenfassung
der Objekte ist. Auch Kurzformen wie $\forall xP(x)$ oder
$\forall_x P_x$ sind üblich, sie sparen vor allem Schreibaufwand
beim Rechnen.

Nun muss man für diese Operatoren auch eine Operatorrangfolge
festlegen. Da die Operatoren präfix sind, ist dabei leglich die
rechte Seite zu berücksichtigen. Alle bisher genannten Schreibweisen
haben die höchste Rangfolge, werden also gelesen wie die Negation.
D.\,h. $(\forall x)P(x)$ wird gelesen wie $\neg P(x)$. Z.\,B. wird
die Formel
\[(\forall x\in M)P(x)\land A\quad
\text{gelesen als}\quad
((\forall x\in M)P(x))\land A,\]
Davon zu unterscheiden ist die Formel
\[(\forall x\in M)(P(x)\land A).\]
Daneben gibt es noch die Schreibweisen $\forall x\colon P(x)$ und
$\exists x\colon P(x)$, die in der Mathematik außerhalb der Logik
üblicher sind. Eine gängige Festlegung ist hierbei, dass alles hinter
dem Doppelpunkt in den Wirkungsbereich des Quantors fällt. Weil das
der ersten Festlegung widerspricht und sich nicht jeder daran hält,
werden wir diese Schreibweise nur dann benutzen, wenn es nicht
zu Zweideutigkeiten kommt. Bei all der Umständlichkeit geht es nur um
das Einsparen von Klammern, einen tieferen Grund gibt es nicht.

\newpage
\begin{Satz}[Distributivgesetze]\mbox{}\\*
Ist $M$ endlich, $A$ eine Aussage und $P(x)$ ein Prädikat auf $M$,
dann gilt
\begin{align*}
A\lor(\forall x\in M)P(x) &\equiv (\forall x\in M)(A\lor P(x)),\\
A\land(\exists x\in M)P(x) &\equiv (\exists x\in M)(A\land P(x)).
\end{align*}
\end{Satz}
\strong{Beweis.} Induktiv mittels boolescher Algebra. Induktionsanfang:
\begin{gather*}
A\lor\bigwedge_{k=1}^0 P(x_k) \equiv A\lor 1 \equiv 1 \equiv \bigwedge_{k=1}^0 (A\lor P(x_k)).
\end{gather*}
Induktionsschritt:
\begin{gather*}
A\lor\bigwedge_{k=1}^n P(x_k) \equiv
A\lor (P(x_n)\land\bigwedge_{k=1}^{n-1} P(x_k))
\equiv (A\lor P(x_n))\land (A\lor\bigwedge_{k=1}^{n-1} P(x_k))\\
\equiv (A\lor P(x_n))\land \bigwedge_{k=1}^{n-1} (A\lor P(x_k))
\equiv \bigwedge_{k=1}^n (A\lor P(x_k)).
\end{gather*}
Für den Existenzquantor ist die Argumentation analog.\;\qedsymbol

\begin{Satz}[De morgansche Gesetze]\mbox{}\\*
Ist $M$ endlich und $P(x)$ ein Prädikat auf $M$, dann gilt
\begin{align*}
\neg(\forall x\in M)P(x) &\equiv (\exists x\in M)\;\neg P(x),\\
\neg(\exists x\in M)P(x) &\equiv (\forall x\in M)\;\neg P(x).
\end{align*}
\end{Satz}
\strong{Beweis.} Induktionsanfang:
\begin{gather*}
\neg\bigwedge_{k=1}^0 P(x_k) \equiv \neg 1 \equiv 0 \equiv\bigvee_{k=1}^0 \neg P(x_k).
\end{gather*}
Induktionsschritt:
\begin{gather*}
\neg\bigwedge_{k=1}^n P(x_k)
\equiv \neg(P(x_n)\land\bigwedge_{k=1}^{n-1} P(x_k))
\equiv \neg P(x_n)\lor\neg\bigwedge_{k=1}^{n-1} P(x_k)\\
\equiv \neg P(x_n)\lor\bigvee_{k=1}^{n-1} \neg P(x_k)
\equiv \bigvee_{k=1}^n \neg P(x_k).
\end{gather*}
Für den Existenzquantor ist die Argumentation analog.\;\qedsymbol

\newpage
\begin{Satz}[Verträglichkeitsgesetze]%
\label{finite-quantifier-compatibility}\mbox{}\\*
Ist $M$ endlich und sind $P(x),Q(x)$ Prädikate auf $M$, dann gilt
\begin{align*}
(\forall x\in M)(P(x)\land Q(x)) \equiv (\forall x\in M)P(x)\land(\forall x\in M)Q(x),\\
(\exists x\in M)(P(x)\lor Q(x)) \equiv (\exists x\in M)P(x)\lor(\exists x\in M)Q(x).
\end{align*}
\end{Satz}
\strong{Beweis.} Induktionsanfang:
\begin{gather*}
\bigwedge_{k=1}^0 (P(x_k)\land Q(x_k)) \equiv 1 \equiv 1\land 1
\equiv \bigwedge_{k=1}^0 P(x_k)\land\bigwedge_{k=1}^0 Q(x_k).
\end{gather*}
Induktionsschritt:
\begin{gather*}
\bigwedge_{k=1}^n (P(x_k)\land Q(x_k))
\equiv (P(x_n)\land Q(x_n))\land\bigwedge_{k=1}^{n-1} (P(x_k)\land Q(x_k))\\
\equiv P(x_n)\land Q(x_n)\land\bigwedge_{k=1}^{n-1} P(x_k)\land\bigwedge_{k=1}^{n-1} Q(x_k)\\
\equiv P(x_n)\land\bigwedge_{k=1}^{n-1} P(x_k)\land Q(x_n)\land\bigwedge_{k=1}^{n-1} Q(x_k)
\equiv \bigwedge_{k=1}^n P(x_k)\land\bigwedge_{k=1}^n Q(x_k).
\end{gather*}
Die Argumentation für den Existenzquantor ist analog.\;\qedsymbol

% \newpage
\begin{Satz}[Vertauschbarkeit gleichartiger Quantoren]\mbox{}\\*
Sind $M,N$ endlich, dann gilt
\begin{align*}
(\forall x\in M)(\forall x\in N)P(x,y)&\equiv (\forall x\in N)(\forall x\in M)P(x,y),\\
(\exists x\in M)(\exists x\in N)P(x,y)&\equiv (\exists x\in N)(\exists x\in M)P(x,y).
\end{align*}
\end{Satz}
\strong{Beweis.}
Induktionsanfang:
\[\bigwedge_{i=1}^0\bigwedge_{j=1}^n P(x_i,y_j)
\equiv 1 \equiv \bigwedge_{j=1}^n 1 \equiv
\bigwedge_{j=1}^n\bigwedge_{i=1}^0 P(x_i,y_j).\]
Induktionsschritt:
\begin{gather*}
\bigwedge_{i=1}^m\bigwedge_{j=1}^n P(x_i,y_j)
\equiv \bigwedge_{j=1}^n P(x_m,y_j)\land\bigwedge_{i=1}^{m-1}\bigwedge_{j=1}^n P(x_i,y_j)\\
\equiv \bigwedge_{j=1}^n P(x_m,y_j)\land\bigwedge_{j=1}^n \bigwedge_{i=1}^{m-1} P(x_i,y_j)\\
\stackrel{(*)}\equiv \bigwedge_{j=1}^n \bigg(P(x_m,y_j)\land\bigwedge_{i=1}^{m-1} P(x_i,y_j)\bigg)
\equiv \bigwedge_{j=1}^n \bigwedge_{i=1}^m P(x_i,y_j).
\end{gather*}
Die Äquivalenz $(*)$ gilt gemäß Satz \ref{finite-quantifier-compatibility}.

Für den Existenzquantor ist die Argumentation analog.\;\qedsymbol

\subsection{Allgemeine Regeln}

Man denkt sich nun ein Universum $U$, das alle denkbaren Objekte
enthält. Das Prädikat $P(x)$ sei für jedes $x\in U$ definiert.
Anstelle von $(\forall x\in U)P(x)$ schreibt man kürzer
$(\forall x)P(x)$. Anstelle von $(\exists x\in U)P(x)$ schreibt
man kürzer $(\exists x)P(x)$. Das Universum darf unendlich sein,
aber nicht leer, es muss immer mindestens ein Element enthalten.
\begin{Definition}[Allquantor]\mbox{}\\*
Es gilt $(\forall x)P(x)$ genau dann, wenn $P(x)$ für jedes
beliebige $x$ wahr ist.
\end{Definition}
\begin{Definition}[Existenzquantor]\mbox{}\\*
Es gilt $(\exists x)P(x)$ genau dann, wenn ein $x$ gefunden
werden kann, das $P(x)$ erfüllt.
\end{Definition}
Das Problem das sich jetzt stellt, ist, dass zur Überprüfung
von prädikatenlogischen Formeln unendlich viele Wahrheitstafeln
aufgestellt werden müssten, nämlich für jedes der unendlich vielen
Objekte, welche für eine Objektvariable eingesetzt werden können, und das
auch noch für jedes Prädikat, welches in eine Prädikatvariable
eingesetzt werden kann. Wir müssen also anders vorgehen.

Zunächst überzeugt man sich davon, dass die Einsetzungsregel und die
Ersetzungsregel gültig bleiben. Außerdem definiert man für zwei
prädikatenlogische Formeln $\varphi,\psi$ die Äquivalenz als
\[(\varphi\equiv\psi)\defiff (\{\varphi\}\models\psi)\land (\{\psi\}\models\varphi).\]
Bei der semantischen Implikation werden nun nicht nur Aussagenvariablen mit
Wahrheitswerten belegt. Auch Prädikatvariablen werden mit Prädikaten
belegt. Da es unendlich viele Prädikate gibt, lässt sich das natürlich
praktisch nicht mehr durchführen.
\begin{Satz}
Es gilt $A\equiv (\forall x)A$ und $A\equiv(\exists x)A$.
\end{Satz}
\strong{Beweis.} Im Fall $A\equiv 0$ ist auch
$(\forall x)0$ falsch, da $0$ für kein $x$ erfüllt ist.
Im Fall $A\equiv 1$ ist auch $(\forall x)1$ wahr, da $1$ für jedes
beliebige $x$ erfüllt ist. Für den Existenzquantor ist die
Argumentation analog.\;\qedsymbol

Vorsicht, das Universum darf nicht leer sein,
denn $(\forall x{\in}\{\})\,0\equiv 1$.

\begin{Satz}[Verallgemeinerte Distributivgesetze]\mbox{}\\*
Es gilt
\begin{align*}
A\lor (\forall x)P(x) &\equiv (\forall x)(A\lor P(x)),\\
A\land(\exists x)P(x) &\equiv (\exists x)(A\land P(x)).
\end{align*}
\end{Satz}
\strong{Beweis.} Im Fall $A\equiv 0$ ergibt sich
\[A\lor(\forall x)P(x) \equiv 0\lor(\forall x)P(x)
\equiv (\forall x)P(x)\equiv (\forall x)(0\lor P(x))\equiv (\forall x)(A\lor P(x)).\]
Im Fall $A\equiv 1$ ergibt sich
\[A\lor(\forall x)P(x)\equiv 1\lor(\forall x)P(x) \equiv 1 \equiv (\forall x)1
\equiv (\forall x)(1\lor P(x))\equiv (\forall x)(A\lor P(x)).\]
Für den Existenzquantor ist die Argumentation analog.\;\qedsymbol

\begin{Satz}[Verallgemeinerte de morgansche Gesetze]\mbox{}\\*
Es gilt
\begin{align*}
\neg (\forall x)P(x) &\equiv (\exists x)\;\neg P(x),\\
\neg (\exists x)P(x) &\equiv (\forall x)\;\neg P(x).
\end{align*}
\end{Satz}
\strong{Beweis.} Gilt $(\forall x)P(x)$, dann ist $P(x)\equiv 1$.
Es ergibt sich
\begin{equation}
\neg(\forall x)P(x) \equiv \neg 1 \equiv 0 \equiv (\exists x)0
\equiv (\exists x)\;\neg 1\equiv (\exists x)\;\neg P(x).
\end{equation}
Gilt $(\forall x)P(x)$ nicht, dann muss es ein $x$ mit
$\neg P(x)\equiv 1$ geben und es gilt
\begin{equation}
\neg(\forall x)P(x) \equiv \neg 0\equiv 1\equiv (\exists x)1
\equiv (\exists x)\;\neg P(x).
\end{equation}
Die Argumentation für den Existenzquantor ist analog.\;\qedsymbol

\begin{Satz}[Verträglichkeitsgesetze]\mbox{}\\*
Es gilt
\begin{align*}
(\forall x)(P(x)\land Q(x)) &\equiv (\forall x)P(x)\land (\forall x)Q(x),\\
(\exists x)(P(x)\lor Q(x)) &\equiv (\exists x)P(x)\lor (\exists x)Q(x).
\end{align*}
\end{Satz}
\strong{Beweis.} Angenommen, die linke Seite ist wahr. Dann muss
$P(x)\land Q(x)\equiv 1$ sein, und daher auch $P(x)\equiv 1$ und
$Q(x)\equiv 1$. Dann ist aber auch
$(\forall x)P(x)\equiv 1$ und $(\forall x)Q(x)\equiv 1$. Somit gilt
\begin{equation}
(\forall x)(P(x)\land Q(x)) \equiv 1 \equiv
1\land 1 \equiv (\forall x)P(x)\land (\forall x)Q(x).
\end{equation}
Angenommen, die linke Seite ist falsch. Dann gibt es
ein $x$, für welches $P(x)\land Q(x)\equiv 0$ ist. Für dieses $x$
muss also $P(x)\equiv 0$ oder $Q(x)\equiv 0$ sein, oder beides.
Dann ist auch $(\forall x)P(x)\equiv 0$ oder $(\forall x)Q(x)\equiv 0$.
Somit ist
\begin{equation}
(\forall x)P(x)\land(\forall x)Q(x)\equiv 0.
\end{equation}
Für den Existenzquantor ist die Argumentation analog. Alternativ
ergibt sich nach den de morganschen und verallgemeinerten de morganschen
Gesetzen
\begin{gather}
(\exists x)(P(x)\lor Q(x))
\equiv \neg(\forall x)\;\neg (P(x)\lor Q(x))\\
\equiv \neg(\forall x)(\neg P(x)\land \neg Q(x))
\equiv \neg((\forall x)\;\neg P(x)\land (\forall x)\;\neg Q(x))\\
\equiv \neg(\forall x)\;\neg P(x)\lor\neg(\forall x)\;\neg Q(x)
\equiv (\exists x) P(x)\lor(\exists x) Q(x).\;\qedsymbol
\end{gather}


\newpage
\subsection{Beschränkte Quantifizierung}
\begin{Definition}[Beschränkte Quantifizierung]\mbox{}\\*
Ist $P$ ein Prädikat auf $U$ und $M\subseteq U$ eine Teilmenge von
$U$, dann definiert man
\begin{align*}
(\forall x\in M)P(x) &:\equiv (\forall x)(x\in M\Rightarrow P(x)),\\
(\exists x\in M)P(x) &:\equiv (\exists x)(x\in M\land P(x)).
\end{align*}
\end{Definition}
Zuweilen schreibt man auch
\begin{align}
(\forall R(x))P(x) &:\equiv (\forall x)(R(x)\Rightarrow P(x)),\\
(\exists R(x))P(x) &:\equiv (\exists x)(R(x)\land P(x)),
\end{align}
solange klar bleibt, dass $x$ die gebundene Variable ist.
Z.\,B. $(\forall x{<}4)P(x)$ und ähnlich.

\begin{Satz}[Verallgemeinerte Distributivgesetze]%
\label{logical-dist-general}\mbox{}\\*
Es gilt
\begin{align*}
A\lor (\forall x\in M)P(x) &\equiv (\forall x\in M)(A\lor P(x)),\\
A\land(\exists x\in M)P(x) &\equiv (\exists x\in M)(A\land P(x)).
\end{align*}
\end{Satz}
\strong{Beweis.} Für den Allquantor gilt
\begin{gather}
A\lor (\forall x\in M)P(x)
\equiv A\lor(\forall x)(x\in M\Rightarrow P(x))\\
\equiv A\lor(\forall x)(\neg x\in M\lor P(x))
\equiv (\forall x)(A\lor\neg x\in M\lor P(x))\\
\equiv (\forall x)(x\in M\Rightarrow A\lor P(x))
\equiv (\forall x\in M)(A\lor P(x)).
\end{gather}
Für den Existenzquantor gilt
\begin{gather}
A\land (\exists x\in M)P(x)
\equiv A\land(\exists x)(x\in M\land P(x))\\
\equiv (\exists x)(A\land x\in M\land P(x))
\equiv (\exists x)(x\in M\land A\land P(x))\\
\equiv (\exists x\in M)(A\land P(x)).\;\qedsymbol
\end{gather}

\begin{Satz}[Verallgemeinerte de morgansche Gesetze]\mbox{}\\*
Es gilt
\begin{align*}
\neg (\forall x\in M)P(x) &\equiv (\exists x\in M)\;\neg P(x),\\
\neg (\exists x\in M)P(x) &\equiv (\forall x\in M)\;\neg P(x).
\end{align*}
\end{Satz}
\strong{Beweis.} Es gilt
\begin{gather}
\neg(\forall x\in M)P(x) \equiv \neg(\forall x)(x\in M\Rightarrow P(x))
\equiv \neg(\forall x)(\neg x\in M\lor P(x))\\
\equiv (\exists x)(x\in M\land \neg P(x))
\equiv (\exists x\in M)\;\neg P(x).
\end{gather}
Die Argumentation für den Existenzquantor ist analog.\;\qedsymbol

\newpage
\section{Mengenlehre}

\subsection{Der Mengenbegriff}\index{Menge}

Eine Menge ist im Wesentlichen ein Beutel, der unterschiedliche
Objekte enthält. Es gibt die leere Menge, das ist der leere Beutel.
Das besondere an einer Menge ist nun, dass das selbe Objekt immer
nur ein einziges mal im Beutel enthalten ist. Legt man zweimal
das selbe Objekt in den Beutel, dann ist dieses darin trotzdem nur
einmal zu finden.

Man kann sich dabei z.\,B. einen Einkaufsbeutel vorstellen,
in welchem sich nur ein Apfel, eine Birne, eine Weintraube usw.
befinden darf. Möchte man mehrere Birnen im Einkaufsbeutel haben,
dann müssen diese unterschieden werden, z.\,B. indem jede Birne
eine unterschiedliche Nummer bekommt.

Möchte man eine Menge aufschreiben, werden die Objekte einfach
in einer beliebigen Reihenfolge aufgelistet und diese Liste in
geschweifte Klammern gesetzt. Z.\,B.:%
\[\{\mathrm{Afpel}, \mathrm{Birne}, \mathrm{Weintraube}\}.\]
Nennen wir den Apfel $A$, die Birne $B$
und die Weintraube $W$. Eine Menge mit zwei Äpfeln und drei
Birnen würde man so schreiben:%
\[\{A_1, A_2, B_1, B_2, B_3\}.\]
Erlaubt sind auch Beutel in Beuteln. Eine Menge mit zwei Äpfeln
und einer Menge mit vier Weintrauben wird beschrieben durch%
\[\{A_1, A_2, \{W_1,W_2,W_3,W_4\}\}.\]
Die Reihenfolge spielt wie gesagt keine Rolle:%
\[\{A_1,A_2\} = \{A_2,A_1\}.\]
Ein leerer Beutel ist etwas anderes als ein Beutel, welcher einen
leeren Beutel enthält:%
\[\{\} \ne \{\{\}\}.\]
Die Notation $x\in M$ bedeutet, dass $x$ in der Menge $M$ enthalten
ist. Man sagt, $x$ ist ein Element von $M$. Z.\,B. ist
\[A_1\in\{A_1,A_2\}.\]

\newpage
\subsection{Teilmengen}

\begin{Definition}[Teilmengenrelation]\index{Teilmenge}\mbox{}\\*
Hat man zwei Mengen $M,N$, dann nennt man $M$ eine Teilmenge von $N$,
wenn jedes Element von $M$ auch ein Element von $N$ ist.
Als Formel:
\[M\subseteq N\defiff \text{für jedes $x\in M$ gilt $x\in N$}.\]
Anders formuliert, aber gleichbedeutend:
\[M\subseteq N\defiff \text{für jedes $x$ gilt:}\; (x\in M\implies x\in N).\]
\end{Definition}
Z.\,B. ist die Aussage $\{1,2\}\subseteq\{1,2,3\}$ wahr.
Die Aussage $\{1,2,3\}\subseteq\{1,2\}$ ist jedoch falsch,
weil $3$ kein Element von $\{1,2\}$ ist. Für jede Menge $M$ gilt
$M\subseteq M$, denn die Aussage
\[x\in M\implies x\in M\]
ist immer wahr, da die Formel »$\varphi\Rightarrow\varphi$«
tautologisch ist.

\subsection{Mengen von Zahlen}
\index{Zahlenbereiche}\index{Natürliche Zahlen}\index{ganze Zahlen}%
\index{reelle Zahlen}\index{Dezimalzahl}

Einige Mengen kommen häufiger vor, was dazu führte, dass man für
diese Mengen kurze Symbole definiert hat.

Die Menge der natürlichen Zahlen mit der Null, kurz
\emph{nichtnegative} ganze Zahlen:
\[\N_0 := \{0,1,2,3,4,\ldots\}.\]
Die Menge der natürlichen Zahlen ohne die Null, kurz
\emph{positive} ganze Zahlen:
\[\N_1 := \{1,2,3,4,\ldots\}.\]
Die Menge der ganzen Zahlen:
\[\Z := \{\ldots,-4,-3,-2,-1,0,1,2,3,4,\ldots\}.\]
Dann gibt es noch die rationalen Zahlen $\Q$, das sind alle
Brüche der Form $m/n$, wobei $m,n$ ganze Zahlen sind
und $n\ne 0$ ist. Rationale Zahlen lassen sich immer als
Dezimalbruch schreiben, dessen Ziffern irgendwann periodisch
werden.

\begin{table}[h]
\centering
\begin{tabular}{cll}
\toprule
\strong{Zahl} & \strong{als Dezimalzahl} & \strong{kurz}\\
$1/2$ & $0.5000000000\ldots$ & $0.5\overline{0}$\\
$1/3$ & $0.3333333333\ldots$ & $0.\overline{3}$\\
$1241/1100$ & $1.1281818181\ldots$ & $0.12\overline{81}$\\
\bottomrule
\end{tabular}
\caption{Jeder Bruch lässt sich als Dezimalzahl
schreiben, deren Ziffern in eine periodische Zifferngruppe münden.
Über die periodische Zifferngruppe setzt man einen waagerechten
Strich.}
\end{table}

\noindent
Schließlich gibt es noch die reellen Zahlen $\R$. Darin enthalten sind
alle Dezimalzahlen -- auch solche, deren Ziffern niemals in eine
periodische Zifferngruppe münden. Die reellen Zahlen haben
eine recht komplizierte Struktur, und wir benötigen Mittel
der Analysis um diese verstehen zu können. Solange diese Werkzeuge
noch nicht bekannt sind, kann man die reellen Zahlen einfach
als kontinuierliche Zahlengerade betrachten. Die rationalen
Zahlen haben Lücken in dieser Zahlengerade, z.\,B. ist die Zahl
$\sqrt{2}$ nicht rational, wie sich zeigen lässt. Die reellen
Zahlen schließen diese Lücken.

\subsection{Vergleich von Mengen}\index{Menge!Vergleich von Mengen}

Wie können wir denn wissen, wann zwei Mengen $A,B$, gleich sind?
Zwei Mengen sind ja gleich, wenn sie beide die gleichen Elemente
enthalten. Aber wie lässt sich das als mathematische Aussage
formulieren?

Jedes Element von $A$ muss doch auch ein Element von $B$ sein,
sonst gäbe es Elemente in $A$, die nicht in $B$ enthalten wären.
Umgekehrt muss auch jedes Element von $B$ ein Element von $A$ sein.
Also ist $A\subseteq B$ und $B\subseteq A$ eine notwendige Bedingung.
Diese Bedingung ist sogar hinreichend.

Gehen wir mal von der Kontraposition aus -- sind die beiden Mengen
$A,B$ verschieden, dann muss es ein Element in $A$ geben, welches nicht
in $B$ enthalten ist, oder eines in $B$, welches nicht $A$ enthalten
ist. Als Formel:%
\[A\ne B \implies (\exists x\in A)(x\notin B)\lor(\exists x\in B)(x\notin A).\]
Hiervon bildet man wieder die Kontraposition. Gemäß den
de morganschen Gesetzen und den verallgemeinerten
de morganschen Gesetzen ergibt sich%
\[(\forall x\in A)(x\in B)\land(\forall x\in B)(x\in A)\implies A=B.\]
Auf der linken Seite stehen aber nach Definition
Teilmengenbeziehungen, es ergibt sich%
\[A\subseteq B\land B\subseteq A\implies A=B.\]
\begin{Definition}[Gleichheit von Mengen]%
\index{Gleichheit!von Mengen}\mbox{}\\*
Zwei Mengen $A,B$ sind genau dann gleich, wenn jedes Element von
$A$ auch in $B$ enthalten ist, und jedes von $B$ auch in $A$ enthalten:%
\[A=B\defiff A\subseteq B\land B\subseteq A.\]
\end{Definition}
\begin{Satz}\label{set-eq}
Es gilt
\[A=B\iff (\forall x)(x\in A\iff x\in B).\]
\end{Satz}
\strong{Beweis.} Wir müssen ein wenig Prädikatenlogik bemühen:%
\begin{align*}
A\subseteq B\land B\subseteq A
&\iff (\forall x\in A)(x\in B)\land(\forall x\in B)(x\in A)\\
&\iff (\forall x)(x\in A\implies x\in B)\land(\forall x)(x\in B\implies x\in A)\\
&\iff (\forall x)((x\in A\implies x\in B)\land (x\in B\implies x\in A))\\
&\iff (\forall x)(x\in A\iff x\in B).
\end{align*}
Im letzten Schritt wurde ausgenutzt, dass die Äquivalenz
$\varphi\Leftrightarrow\psi$ gleichbedeutend
mit der Formel $(\varphi\Rightarrow\psi)\land(\psi\Rightarrow\varphi)$
ist.\;\qedsymbol

%\newpage
\subsection{Beschreibende Angabe von Mengen}

Umso mehr Elemente eine Menge enthält, umso umständlicher wird
die Auflistung all dieser Elemente. Außerdem hantiert man in der
Mathematik normalerweise auch ständig mit Mengen herum, die
unendlich viele Elemente enthalten. Eine explizite Auflistung ist
demnach unmöglich.

Wir entgehen der Auflistung aller Elemente durch eine Beschreibung
der Menge. Die Menge der ganzen Zahlen, welche kleiner als vier sind,
wird so beschrieben:%
\[\{n\in\Z\mid n<4\}.\]
In Worten: Die Menge der $n\in\Z$, für die gilt: $n<4$.

Mit dieser Notation kann man nun z.\,B. schreiben:%
\begin{align*}
\N_0 &= \{n\in\Z\mid n\ge 0\},\\
\N_1 &= \{n\in\Z\mid n>0\}.
\end{align*}
Mit der folgenden formalen Definition wird die beschreibende Angabe
auf ein festes Fundament gebracht.

\begin{Definition}[Beschränkte Beschreibung einer Menge]%
\label{def:set-builder-bounded}\index{Menge!Comprehension}\mbox{}\\*
Die Menge der $x\in M$, welche die Aussage $P(x)$ erfüllen,
ist definiert durch die folgende logische Äquivalenz:%
\[a\in\{x\in M\mid P(x)\} \defiff a\in M\land P(a).\]
\end{Definition}
Das schaut ein wenig kompliziert aus, ist aber ganz einfach zu
benutzen. Sei z.\,B. $A:=\{n\in\Z\mid n<4\}$. Zu beantworten ist
die Frage, ob $2\in A$ gilt. Eingesetzt in die Definition
ergibt sich%
\[2\in\{n\in\Z\mid n<4\}\iff 2\in\Z\land 2<4.\]
Da $2\in\Z$ und $2<4$ wahre Aussagen sind, ist die rechte Seite
erfüllt, und damit auch die linke Seite der Äquivalenz.

Die geraden Zahlen lassen sich so definieren:%
\[2\Z:=\{n\in\Z\mid\text{es gibt ein $k\in\Z$ mit $n=2k$}\}.\]
Es lässt sich zeigen:
\[a\in 2\Z\implies a^2\in 2\Z.\]
Nach Definition von $2\Z$ gibt es $k\in\Z$ mit $a=2k$.
Dann ist $a^2=(2k)^2=4k^2=2(2k^2)$. Benennt man $k':=2k^2$, dann
gilt also $a^2=2k'$. Also gibt es es ein $k'\in\Z$
mit $a^2=2k'$, und daher ist $a^2\in 2\Z$.

Die geraden Zahlen sind ganze Zahlen, welche ohne Rest durch zwei
teilbar sind. Die ganzen Zahlen, welche ohne Rest durch $m$ teilbar
sind, lassen sich formal so definieren:%
\[m\Z:=\{n\in\Z\mid\text{es gibt ein $k\in\Z$ mit $n=mk$}\}.\]
Man zeige:
\begin{align*}
& (1.)\;\;a\in 2\Z\implies a^2\in 4\Z, && (3.)\;\;2\Z\subseteq\Z,\\
& (2.)\;\;a\in 4\Z\implies a\in 2\Z,   && (4.)\;\;4\Z\subseteq 2\Z.
\end{align*}


\begin{Definition}[Beschreibende Angabe einer Menge]%
\label{def:set-builder}\mbox{}\\*
Stellt man sich unter $G$ die Grundmenge vor, welche
alle Elemente enthält, die überhaupt in Betracht kommen können,
dann schreibt man kurz%
\[\{x\mid P(x)\} := \{x\in G\mid P(x)\}\]
und nennt dies die Beschreibung einer Menge.
\end{Definition}
\begin{Satz}
Es gilt
\begin{gather}
\label{eq:set-builder}
a\in\{x\mid P(x)\}\iff P(a),\\
\label{eq:bound-conversion}
\{x\in A\mid P(x)\} = \{x\mid x\in A\land P(x)\}.
\end{gather}
\end{Satz}
\strong{Beweis.} Gemäß Definition \ref{def:set-builder}
und \ref{def:set-builder-bounded} gilt%
\[a\in\{x\mid P(x)\} \iff a\in\{x\in G\mid P(x)\}
\iff a\in G\land P(a)\iff P(a),\]
denn $a\in G$ ist immer erfüllt, wenn $G$ die Grundmenge ist.
Die Aussage $a\in G$ kann daher in der Konjunktion gemäß dem
Neutralitätsgesetz der booleschen Algebra entfallen.

Aussage \eqref{eq:bound-conversion} wird mit Satz \ref{set-eq}
expandiert. Zu zeigen ist nun
\[a\in\{x\in A\mid P(x)\}\iff a\in\{x\mid x\in A\land P(x)\},\]
was gemäß Definition \ref{def:set-builder-bounded} und der schon
bewiesenen Aussage \eqref{eq:set-builder} aber vereinfacht
werden kann zu
\[a\in A\land P(a)\iff a\in A\land P(a).\;\qedsymbol\]


\subsection{Bildmengen}\index{Bildmenge}

Oft kommt auch die Angabe einer Menge als Bildmenge vor, dabei
handelt es sich um eine spezielle Beschreibung der Menge. Ist
$T(x)$ ein Term und $A:=\{a_1,a_2,\ldots,a_n\}$ eine endliche
Menge, dann wird das Bild von $A$ unter $T(x)$ so beschrieben:
\[\{T(x)\mid x\in A\} := \{T(a_1),T(a_2),\ldots, T(a_n)\}.\]
Lies: Die Menge der $T(x)$, für die $x\in A$ gilt.
Für $T(x):=x^2$ und $A:=\{1,2,3,4\}$ ist z.\,B.
\[\{T(x)\mid x\in A\} = \{T(1), T(2), T(3), T(4)\}
= \{1^2,2^2,3^2,4^2\} = \{1,4,9,16\}.\]
Nun kann es aber sein, dass die Menge $A$ unendlich viele Elemente
enthält, eine Auflistung dieser somit unmöglich ist. Eine Auflistung
lässt sich umgehen, indem man nur logisch die Existenz eines Bildes
zu jedem $x\in A$ verlangt, dieses aber nicht mehr explizit angibt.
Man definiert also allgemein
\[\{T(x)\mid x\in A\} := \{y\mid\text{es gibt ein $x\in A$, für das gilt: $y=T(x)$}\}.\]
Das hatten wir bei den geraden Zahlen
\[2\Z := \{2k\mid k\in\Z\} = \{n\mid\text{es gibt ein $k\in\Z$, für das gilt: $n=2k$}\}\]
schon kennengelernt. Hierbei ist es unwesentlich, ob man $n\in\Z$ verlangt
oder nicht, denn dies wird bereits durch $k\in\Z$ erzwungen.

Man spricht auch von einer sogenannten \emph{Komprehension},
die Bildung einer Bildmenge ist ein Spezialfall davon.
\begin{Definition}[Komprehension]
Für ein beliebiges Prädikat $P$ ist
\[\{T(x)\mid P(x)\} := \{y\mid(\exists x)(P(x)\land y=T(x))\}.\]
\end{Definition}
Die zuvor angegebene Bildmenge erhält man mit $P(x):=(x\in A)$.

In dieser Definition muss $P(x)$ auf der gesamen betrachteten Grundmenge
$G$ definiert sein und $T(x)$ muss auf $\{x\in G\mid P(x)\}$ einen
Sinn ergeben. Möchte man sich auf die Menge $M$ beschränken,
dann betrachtet man
\[\{T(x)\mid x\in M\land P(x)\} = \{y\mid(\exists x\in M)(P(x)\land y=T(x))\}.\]
D.\,h. für ein auf $M$ definiertes Prädikat $P$ ergibt sich ein
auf ganz $G$ definiertes Prädikat $Q$ mit $P(x)=Q(x)$ auf $M$ und
sonst $Q(x)=0$, indem man $Q(x):=(x\in M\land P(x))$ setzt.

\newpage
\subsection{Mengenoperationen}

Mengen sind mathematische Objekte, mit denen sich rechnen lässt.
So wie es für Zahlen Rechenoperationen gibt, gibt es auch für
Mengen Rechenoperationen.
\begin{Definition}[Vereinigungsmenge]%
\index{Vereinigungsmenge}\index{Menge!Vereinigung}\mbox{}\\*
Die Vereinigungsmenge von zwei Mengen $A,B$ ist die Menge aller Elemente,
welche in $A$ oder in $B$ vorkommen:
\[A\cup B := \{x\mid x\in A\lor x\in B\}.\]
\end{Definition}
Man nimmt also einen neuen Beutel und schüttet den Inhalt von $A$
und $B$ in diesen Beutel.

Beispiele:
\begin{gather*}
\{1,2\}\cup\{5,7,9\} = \{1,2,5,7,9\},\\
\{1,2\}\cup\{1,3,5\} = \{1,2,3,5\}.
\end{gather*}

\begin{Definition}[Schnittmenge]%
\index{Schnittmenge}\index{Menge!Schnitt}\mbox{}\\*
Die Schnittmenge von zwei Mengen $A,B$ ist die Menge aller Elemente,
welche sowohl in $A$ also auch in $B$ vorkommen:
\[A\cap B := \{x\mid x\in A\land x\in B\}.\]
\end{Definition}
\begin{Satz}
Bei der Beschreibung der Schnittmenge $A\cap B$ genügt es, $A\cup B$ als Grundmenge
zu verwenden, denn es gilt
\[A\cap B = \{x\in A\cup B\mid x\in A\land x\in B\}\]
\end{Satz}
\strong{Beweis.}
Die Formel wird mit Satz \ref{set-eq} expandiert. Zu zeigen ist demnach
\[a\in A\cap B\iff a\in \{x\in A\cup B\mid x\in A\land x\in B\}.\]
Das ist nach \eqref{eq:set-builder} und Definition
\ref{def:set-builder-bounded} gleichbedeutend mit
\begin{align*}
a\in A\land a\in B&\iff a\in A\cup B\land a\in A\land a\in B\\
&\iff (a\in A\lor a\in B)\land a\in A\land a\in B.
\end{align*}
Nun gilt für beliebige Aussagen $\varphi,\psi$ gemäß boolescher Algebra aber
\begin{align*}
(\varphi\lor\psi)\land\varphi\land\psi
&\iff (\varphi\land\varphi\land\psi)\lor(\psi\land\varphi\land\psi)\\
&\iff (\varphi\land\psi)\lor(\varphi\land\psi)\\
&\iff \varphi\land\psi.
\end{align*}
Auf beiden Seiten der Äquivalenz steht jetzt die gleiche Aussage:%
\[a\in A\land a\in B\iff a\in A\land a\in B.\;\qedsymbol\]

\begin{Definition}[Vereinigung beliebig vieler Mengen]\mbox{}\\*
Sei $M$ eine Menge von Mengen. Die Vereinigung der $A\in M$ ist
definiert gemäß
\[\bigcup M = \bigcup_{A\in M} A := \{x\mid (\exists A)(A\in M\land x\in A)\}.\]
\end{Definition}
Für $M=\{\}$ ist $\bigcup_{A\in M} A = \{\}$.

Das logische ODER findet seine Entsprechung genau in der Vereinigung
von zwei Mengen. Dazu passend findet der Existenzquantor seine
Entsprechung genau in der Vereinigung beliebig vieler Mengen.
Aus diesem Grund lassen sich Regeln der booleschen Algebra direkt
auf die Mengenoperationen übertragen. Z.\,B. lautet das
Distributivgesetz für Mengen
\[B\cap\bigcup_{A\in M} A = \bigcup_{A\in M}(B\cap A).\]
Diese Gleichung lässt sich nämlich expandieren in die logische Formel
\[x\in B\land(\exists A\in M)(x\in A) \iff (\exists A\in M)(x\in B\land x\in A).\]
Die Äquivalenz ist wie gesagt gültig gemäß Satz
\ref{logical-dist-general}.

\begin{Definition}[Schnitt beliebig vieler Mengen]\mbox{}\\*
Sei $M$ eine nichtleere Menge von Mengen. Der Schnitt der $A\in M$
ist definiert gemäß
\[\bigcap M = \bigcap_{A\in M} A := \{x\mid(\forall A)(A\in M\Rightarrow x\in A)\}.\]
\end{Definition}
Im Gegensatz zur Vereinigung wurde der Schnitt $\bigcap_{A\in M} A$ 
für $M=\{\}$ undefiniert gelassen. Hier gibt es zwei Möglichkeiten.
Zum einen könnte man die Bedingung $M\ne\{\}$ einfach fallen
lassen, dann ergibt sich beim leeren Schnitt immer die Grundmenge
$G=\{x\mid 1\}$. Im allgemeinen Mengenuniversum ist $G$ die
Allklasse. Diese ist nach den ZFC"=Axiomen jedoch keine Menge mehr.

Aus diesen Grund gibt es noch die alternative Definition
\[\bigcap_{A\in M} A :=
\{x\in\bigcup_{A\in M} A\mid(\forall A)(A\in M\Rightarrow x\in A)\}.\]
Eine Familie $(A_i)$ von Mengen $A_i$ mit $i\in I$ ist eine Abbildung
$A\colon I\to Z$, wobei $Z$ eine Zielmenge ist, welche die
$A_i$ als Elemente enthält. Die Menge $I$ wird in diesem Zusammenhang
auch Indexmenge genannt. Man definiert dafür
\[\bigcup_{i\in I} A_i := \bigcup A(I)
= \bigcup\{X\mid(\exists i\in I)(X=A_i)\} = \{x\mid (\exists i\in I)(x\in A_i)\},\]
wobei mit $A(I)$ das Bild von $I$ unter $A$ gemeint ist. Gemäß Def. \ref{def:img} bekommt man
\begin{align*}
\bigcup_{i\in I} A_i
&= \{x\mid (\exists X)(X\in \{X\mid(\exists i\in I)(X=A_i)\}\land x\in X)\}\\
&= \{x\mid (\exists X)((\exists i\in I)(X=A_i)\land x\in X)\}
= \{x\mid (\exists X)(\exists i\in I)(X=A_i\land x\in X)\}\\
&= \{x\mid (\exists X)(\exists i\in I)(x\in A_i)\}
= \{x\mid (\exists i\in I)(x\in A_i)\}.
\end{align*}
Für $I\ne\{\}$ definiert man entsprechend
\[\bigcap_{i\in I} A_i := \bigcap A(I) = \{x\mid (\exists i\in I)(x\in A_i)\}.\]

\newpage
\begin{Definition}[Differenzmenge]\mbox{}\\*
Für zwei Mengen $A,B$ ist
$A\setminus B := \{x\mid x\in A\land x\notin B\}$.
\end{Definition}
\begin{Definition}[Komplementärmenge]\mbox{}\\*
Ist $G$ eine festgelegte Grundmenge und $A\subseteq G$, dann ist
$A^\compc := G\setminus A$.
\end{Definition}
Die Komplementärmenge entspricht der logischen Negation, denn
\[A^\compc = \{x\mid x\in G\land x\notin A\}
= \{x\in G\mid x\notin A\}.\]
Hat man eine Grundmenge festgelegt, so dass alle betrachteten
Mengen Teilmengen dieser Grundmenge sind, dann genügen die
Operationen $A^{\mathrm c}$, $A\cap B$, $A\cup B$
den gleichen Regeln wie ihre logischen Entsprechungen $\neg A$,
$A\land B$, $A\lor B$. Nämlich bilden diese eine boolesche Algebra.
Definiert man axiomatisch, was unter einer booleschen Algebra
zu verstehen ist, dann lassen sich damit Regeln herleiten, die
sowohl für die Aussagenlogik als auch für die Mengenlehre
gültig sein müssen.

Um eine axiomatische Präzisierung kümmern wir uns später.
Zunächst übertragen wir weitere wichtige Rechenregeln ausgehend
von der Aussagenlogik.

Aus $\neg\neg A\equiv A$ für eine Aussage $A$ folgt
$(A^\compc)^\compc = A$ für eine Menge $A$, denn
\begin{gather*}
x\in (A^\compc)^\compc \iff x\in G\land \neg x\in\{x\mid x\in G\land \neg x\in A\}\\
\iff x\in G\land \neg (x\in G\land \neg x\in A)
\iff x\in G\land (\neg x\in G\lor \neg\neg x\in A)\\
\iff 0\lor x\in G\land x\in A
\iff x\in G\land x\in A
\iff x\in A.
\end{gather*}
Die letzte Äquivalenz gilt wegen $A\subseteq G$. Käme die Grundmenge
dabei nicht in den Weg, würde sich die Rechnung zu
\begin{gather*}
x\in (A^\compc)^\compc \iff \neg x\in\{x\mid \neg x\in A\}
\iff \neg\neg x\in A\iff x\in A
\end{gather*}
vereinfachen. Zum einen müsste man dann aber
die Allklasse als »Grundmenge« benutzen, zum anderen ist die Regel
so nicht für jede beliebige Grundmenge $G$ mit $A\subseteq G$
gezeigt.

Die trivialen Regeln $\{\}^\compc = G$ und $G^\compc=\{\}$
entsprechen $\neg 0\equiv 1$ und $\neg 1\equiv 0$.
Dem logischen Wert wahr entspricht demnach die Grundmenge
und dem logischen Wert falsch die leere Menge.

Der Leser zeige zur Übung auch die Übertragung der de morganschen
Gesetze
\begin{gather*}
(A\cup B)^\compc = A^\compc\cap B^\compc,\qquad
(A\cap B)^\compc = A^\compc\cap B^\compc.
\end{gather*}
Die Komplementärgesetze:
\begin{gather*}
A\cup A^\compc = G,\qquad A\cap A^\compc = \{\}.
\end{gather*}
Der Kontraposition entspricht die Formel
$A^\compc\cup B=(B^\compc)^\compc\cup A^\compc$. Im Zusammenhang
mit der Teilmengenrelation hat die Kontraposition aber auch noch
ein anderes Analogon, das ist%
\begin{gather*}
A\subseteq B \iff B^\compc\subseteq A^\compc.
\end{gather*}


\newpage
\subsection{Produktmengen}
Zwei Objekte $a,b$ kann man zu einem geordneten Paar $(a,b)$
zusammenfassen. Zwei Paare sind definitionsgemäß genau dann
gleich, wenn sie komponentenweise gleich sind:
\[(a_1,b_1) = (a_2,b_2) \defiff a_1=a_2\land b_1=b_2.\]

\begin{Definition}[Kartesisches Produkt]\mbox{}\\*
Das kartesische Produkt der Mengen $A,B$ ist die Menge der
Paare $(a,b)$, für die $a\in A$ und $b\in B$ ist, kurz
\[A\times B = \{(a,b)\mid a\in A\land b\in B\}.\]
\end{Definition}
Zu beachten ist, dass hier eine Bildmenge vorliegt, d.\,h. es gilt
\begin{align*}
A\times B &= \{t\mid(\exists a\in A)(\exists b\in B)(t=(a,b))\}\\
&= \{t\mid(\exists a)(\exists b)(a\in A\land b\in B\land t=(a,b))\}.
\end{align*}

\begin{Satz}
Für das kartesische Produkt mit der leeren Menge gilt $A\times\emptyset=\emptyset$
und $\emptyset\times B=\emptyset$.
\end{Satz}
\strong{Beweis.} Das kann man einfach nachrechnen.
Unter Anwendung von Satz \ref{set-eq} und \eqref{eq:set-builder}
bekommt man zunächst die äquivalente Aussage
\begin{gather*}
t\in A\times\emptyset \iff (\exists a)(\exists b)(a\in A\land b\in\emptyset\land t=(a,b)).
\end{gather*}
Nun ist aber $b\in\emptyset$ niemals wahr, da die leere Menge keine
Elemente enthält. Demnach ergibt sich
\begin{gather*}
(\exists a)(\exists b)(a\in A\land b\in\emptyset\land t=(a,b))
\iff (\exists a)(\exists b)\, 0 \iff (\exists a)\,0\iff 0.
\end{gather*}
Die Aussage $t\in A\times\emptyset$ ist also immer falsch,
daher kann $A\times\emptyset$ keine Elemente enthalten.\;\qedsymbol

\begin{Satz}
Ist $A\subseteq X$ und $B\subseteq Y$, dann ist
$A\times B\subseteq X\times Y$.
\end{Satz}
\strong{Beweis.} Sei $t$ ein Paar, das in
$A\times B$ enthalten ist. Dann gibt es nach Definition
$a\in A$ und $b\in B$, so dass $t=(a,b)$. Wegen
$A\subseteq X$ ist aber auch $a\in X$ und wegen $B\subseteq Y$
ist auch $b\in Y$. Daher gibt es $a\in X$ und $b\in Y$, so dass
$t=(a,b)$. Gemäß Definition heißt das $t\in X\times Y$. Gemäß
Definition ist $A\times B$ daher eine Teilmenge von $X\times Y$.\;\qedsymbol

\newpage
\section{Abbildungen}
\subsection{Grundbegriffe}
Seien zwei beliebige Mengen $A,B$ gegeben. Eine Abbildung
$f\colon A\to B$ ist eine Zuordnung, die jedem Element $x\in A$
genau ein Element $y\in B$ zuordnet. Man schreibt $y=f(x)$
oder $x\mapsto y$, um auszudrücken, dass dem Element $x$
das Element $y$ zugeordnet wird.

Ausgesprochen wird $f(x)$ als »$f$ von $x$«, oder auch
»das Bild von $x$ unter $f$«. Die Schreibweise $x\mapsto y$
wird ausgesprochen als »$x$ zu $y$«, oder auch
»$x$ wird abgebildet auf $y$«. Die Schreibweise
$f\colon A\to B$ wird ausgesprochen als »$f$ ist eine
Abbildung von $A$ nach $B$«.

Man nennt $A$ die Definitionsmenge oder den Definitionsbereich
der Abbildung und $B$ die Zielmenge der Abbildung. Gibt es zu
einem $y\in B$ ein $x\in A$, so dass $y=f(x)$, dann nennt man
$x$ ein Urbildelement zu $y$.

Abbildungen sind für die Mathematik fundamental. Eine
Formalisierung dieses Begriffs mittels Prädikatenlogik
und Mengenlehre erscheint deshalb erstrebenswert.

\begin{Definition}[Abbildung]\mbox{}\\*
Sei $G\subseteq A\times B$. Man nennt ein Tripel $f=(G,A,B)$ eine
Abbildung, wenn die folgenden zwei Bedingungen erfüllt sind.
1. Zu jedem $x\in A$ gibt es mindestens ein Bild:
\[(\forall x\in A)(\exists y\in B)((x,y)\in G).\]
2. Zu jedem $x\in A$ gibt es höchstens ein Bild:
\[(\forall (x_1,y_1),(x_2,y_2)\in G)(x_1=x_2\implies y_1=y_2).\]
Man definiert außerdem
\[y=f(x)\defiff (x,y)\in G.\]
\end{Definition}

\begin{Definition}[Bildmenge]\label{def:img}\mbox{}\\*
Sei $f\colon A\to B$ eine Abbildung.
Für eine Menge $M\subseteq A$ nennt man die Menge
\[f[M] := \{y\mid(\exists x\in M)(y=f(x))\}\]
das Bild von $M$ unter $f$.
\end{Definition}

\begin{Definition}[Urbildmenge]\mbox{}\\*
Sei $f\colon A\to B$ eine Abbildung. Für eine Menge $N$ nennt man
\[f^{-1}[N] := \{x\in A\mid f(x)\in N\}\]
das Urbild von $N$ bezüglich $f$.
\end{Definition}
Sofern keine Verwechslungsgefahr besteht, benutzt man auch die
Schreibweise $f(M)$ anstelle von $f[M]$ bzw. $f^{-1}(N)$ anstelle
von $f^{-1}[N]$.

\newpage

\noindent
Die Urbildoperation zeichnet sich durch Verträglichkeit mit
Mengenoperationen aus, wie im Folgenden nachgerechnet wird.
Man könnte nun denken, diese Verträglichkeiten müssten auch für
die Bildoperation gelten, was jedoch nur zum Teil stimmt.

\begin{Korollar}
Für jede beliebige Abbildung $f$ gilt:
\begin{align*}
f^{-1}[B_1\cup B_2] &= f^{-1}[B_1]\cup f^{-1}[B_2],\\
f^{-1}[B_1\cap B_2] &= f^{-1}[B_1]\cap f^{-1}[B_2],\\
f^{-1}[B_1\setminus B_2] &= f^{-1}[B_1]\setminus f^{-1}[B_2].
\end{align*}
\end{Korollar}
\strong{Beweis.} Es gilt
\begin{align*}x\in f^{-1}[B_1\cup B_2] &\iff f(x)\in B_1\cup B_2
\iff f(x)\in B_1\lor f(x)\in B_2\\
&\iff x\in f^{-1}[B_1]\lor x\in f^{-1}[B_2]
\iff x\in f^{-1}[B_1]\cup f^{-1}[B_2].
\end{align*}
Beim Schnitt ist die Rechnung analog. Und es gilt
\begin{align*}
x\in f^{-1}[B_1\setminus B_2] &\iff f(x)\in B_1\setminus B_2
\iff f(x)\in B_1\land\neg f(x)\in B_2\\
&\iff x\in f^{-1}[B_1]\land\neg x\in f^{-1}[B_2]
\iff x\in f^{-1}[B_1]\setminus f^{-1}[B_2].\;\qedsymbol
\end{align*}
Allgemeiner sind diese Verträglichkeiten sogar für Vereinigungen
und Schnitte von unendlich vielen Mengen gültig.
\begin{Korollar}
Für jede beliebige Abbildung $f$ gilt:
\begin{align*}
f^{-1}[\bigcup_{i\in I} B_i] &= \bigcup_{i\in I} f^{-1}[B_i],\\
f^{-1}[\bigcap_{i\in I} B_i] &= \bigcap_{i\in I} f^{-1}[B_i].
\end{align*}
\end{Korollar}
\strong{Beweis.} Es gilt
\begin{align*}
x\in f^{-1}[\bigcup_{i\in I} B_i]
&\iff f(x)\in \bigcup_{i\in I} B_i
\iff (\exists i\in I)(f(x)\in B_i)\\
&\iff (\exists i\in I)(x\in f^{-1}[B_i])
\iff x\in \bigcup_{i\in I} f^{-1}[B_i].
\end{align*}
Für den Schnitt ist das wieder analog.\;\qedsymbol

Diese Beweise waren ziemlich angenehm zu führen, vergleichsweise fast
ein Kinderspiel, braucht man doch ohne viel Nachdenken lediglich dem
Formalismus folgen. Wer besonders spitzfindig ist, mag darin
allerdings die fehlende Definition für »$f(x)\in B$« erkennen.
Wir haben zwar $y=f(x)$ definiert als $(x,y)\in f$, allerdings
nicht $f(x)$ als solches. Die Bedeutung von $f(x)$ mag klar sein,
aber wir wollen ja so gut es geht alle Formeln zu prädikatenlogischen
Ausdrücken reduzieren können, die nur vorher bereits definierte
Begriffe enthalten. Nun siehe da, aus dem Kaninchenbau kommen
neue Quantoren hervor, die die Argumentation ein wenig verkomplizieren:
\[f(x)\in B \defiff (\exists y\in B)(y=f(x)).\]
Wir müssen nun zeigen
\[f(x)\in B_1\cap B_2 \iff f(x)\in B_1\land f(x)\in B_2.\]
Expandiert man dies, ist zu zeigen
\[(\exists y)(y\in B_1\land y\in B_2\land y=f(x))
\iff (\exists y)(y\in B_1\land y=f(x))\land (\exists y)(y\in B_2\land y=f(x)).\]
Die Implikation von links nach rechts ist wahr, denn es gilt ganz allgemein
\[(\exists y)(P(y)\land Q(y)) \implies (\exists y)P(y)\land (\exists y)Q(y).\]
Zur Bestätigung der Implikation von rechts nach links muss man
allerdings die Bedingung $y=f(x)$ ausnutzen. Nur dadurch ist gesichert,
dass das $y\in B_1$ das gleiche ist wie das $y\in B_2$.

\subsection{Verkettung von Abbildungen}
\begin{Definition}[Verkettung]\mbox{}\\*
Sei $f\colon A\to B$ und $g\colon B\to C$. Die Abbildung
\[(g\circ f)\colon A\to C,\quad (g\circ f)(x):=g(f(x))\]
heißt Verkettung von $f$ und $g$, sprich »$g$ nach $f$«.
\end{Definition}

\noindent
Oft hat man die Situation vorliegen, bei der $f\colon A\to B$
und $g\colon B'\to C$, wobei $B\subseteq B'$ ist. Das ist aber
nicht so schlimm. Man nimmt die folgende unproblematische
Definitionserweiterung vor:
\[(g\circ f)\colon A\to C,\quad g\circ f := g|_B\circ f.\]
Mit $g|_B$ ist hierbei die Einschränkung der Abbildung $g$
auf den Definitionsbereich $B$ gemeint.

\begin{Definition}[Einschränkung]\mbox{}\\*
Für $f\colon A\to B$ und $M\subseteq A$ nennt man
\[f|_M\colon M\to B,\quad f|_M(x):=f(x)\]
die Einschränkung von $f$ auf $M$.
\end{Definition}

\noindent
Schwerwiegender ist die Situation $f\colon A\to B$
und $g\colon B'\to C$ mit $B'\subseteq B$. Hier dürfen nur
solche $x\in A$ im neuen Definitionsbereich vorkommen, bei
denen $f(x)\in B'$ ist. Gemäß der Definition des Urbildes
gilt wiederum
\[f(x)\in B'\iff x\in f^{-1}(B').\]
Man kann nun die Verkettung definieren gemäß
\[h\colon f^{-1}(B')\to C,\quad h(x):=g(f(x)).\]

\begin{Satz}[Bildmenge unter Verkettung]\label{img-comp}\mbox{}\\*
Seien $f\colon A\to B$ und $g\colon B\to C$, dann gilt
$(g\circ f)[M] = g[f[M]]$.
\end{Satz}
\strong{Beweis.} Die Gleichung gemäß Definition expandieren:
\[(\exists x)(x\in M\land z
= (g\circ f)(x))\iff (\exists y)(y\in f[M]\land z=g(y)).\]
Auf der rechten Seite ergibt sich nun
\begin{gather*}
(\exists y)(y\in f[M]\land z=g(y))
\equiv (\exists y)((\exists x)(x\in M\land y=f(x))\land z=g(y))\\
\equiv (\exists y)(\exists x)(x\in M\land y=f(x)\land z=g(y))\\
\equiv (\exists x)(x\in M\land (\exists y)(y=f(x)\land z=g(y)))\\
\equiv (\exists x)(x\in M\land z=g(f(x))).\;\qedsymbol
\end{gather*}

\noindent
Bei der Urbildoperation dreht sich die Reihenfolge um.

\begin{Satz}[Urbildmenge unter Verkettung]\mbox{}\\*
Seien $f\colon A\to B$ und $g\colon B\to C$, dann gilt
$(g\circ f)^{-1}[N] = f^{-1}[g^{-1}[N]]$.
\end{Satz}
\strong{Beweis.} Es gilt
\begin{align*}
x\in (g\circ f)^{-1}[N] &\iff (g\circ f)(x)\in N\iff g(f(x))\in N\\
&\iff f(x)\in g^{-1}[N] \iff x\in f^{-1}[g^{-1}[N]].\;\qedsymbol
\end{align*}


\subsection{Injektionen, Surjektionen, Bijektionen}

\begin{Definition}[Injektive Abbidlung]\mbox{}\\*
Eine Abbildung $f\colon A\to B$ heißt injektiv, wenn
\[(\forall x_1,x_2\in A)(f(x_1)=f(x_2)\implies x_1=x_2)\]
bzw.
\[(\forall x_1,x_2\in A)(x_1\ne x_2\implies f(x_1)\ne f(x_2)).\]
\end{Definition}

\begin{Definition}[Surjektive Abbildung]\mbox{}\\*
Eine Abbildung $f\colon A\to B$ heißt surjektiv,
wenn $f(A)=B$ ist.
\end{Definition}
Bemerkung: Da immer $f(A)\subseteq B$ ist, braucht man bloß $B\subseteq f(A)$
zu zeigen.

\begin{Definition}[Bijektive Abbildung]\mbox{}\\*
Eine Abbildung heißt bijektiv, wenn sie sowohl injektiv als
auch surjektiv ist.
\end{Definition}

\begin{Satz}
Sei $f\colon A\to B$ und $g\colon B\to C$. Es gilt:
\begin{align*}
1.\; & \text{Sind $f$ und $g$ injektiv, dann auch $g\circ f$}.\\
2.\; & \text{Sind $f$ und $g$ surjektiv, dann auch $g\circ f$}.\\
3.\; & \text{Sind $f$ und $g$ bijektiv, dann auch $g\circ f$}.
\end{align*}
\end{Satz}
\strong{Beweis.} Mühelos. Seien $f,g$ injektiv, dann gilt
\begin{gather*}
g(f(x_1)) = (g\circ f)(x_1) = (g\circ f)(x_2) = g(f(x_2))\\
\implies f(x_1) = f(x_2)\\
\implies x_1 = x_2.
\end{gather*}
Somit ist auch $g\circ f$ injektiv. Seien $f,g$ nun surjektiv,
dann ergibt sich
\[(g\circ f)(A) = g(f(A)) = g(B) = C\]
gemäß Satz \ref{img-comp}.
Somit ist auch $g\circ f$ surjektiv.\;\qedsymbol

\subsection{Allgemeines Produkt von Mengen}

Die folgende Begriffsverallgemeinerung des Produktes von Mengen
ist eigentlich erst in der Kardinalzahlarithmetik bedeutsam, rundet
allerdings als intuitiv deutbarer Hilfsbegriff das Verständnis ab.

Entsprechend dem Produkt von zwei Mengen ist das Produkt von
$n$ Mengen die Menge der $n$"=Tupel, das ist%
\begin{equation}
\prod_{k=1}^n A_k := \{(a_1,\ldots,a_n)\mid (\forall k)\;a_k\in A_k\}.
\end{equation}
Sei $K:=\{1,\ldots,n\}$. Die $n$-Tupel sind Funktionen
$f\colon K\to \bigcup_{k\in K} A_k$ mit $f(k)\in A_k$. Offenbar besteht
die Produktmenge aus allen solchen Funktionen. Die Definition lässt
sich demnach umformulieren zu
\begin{equation}
\prod_{k\in K} A_k := \{f\colon K\to\bigcup_{k\in K}A_k\mid
(\forall k\in K)\,f(k)\in A_k\}.
\end{equation}
So unschuldig die letzte Umformulierung auch daher kam, hält uns
nun nichts mehr davon ab, für $K$ eine beliebige Menge einzusetzen.

Die Elemente der Produktmenge nennt man Auswahlfunktionen.
Ist also $(A_k)_{k\in K}$ eine Familie von Mengen, wählt eine
Auswahlfunktion $f$ dazu für jeden »Index« $k\in K$ ein $f(k)\in A_k$
aus.

Die intuitiv klar erscheinende Überlegung
\begin{equation}
(\forall k\in K)(A_k\ne\emptyset) \implies \prod_{k\in K} A_k\ne\emptyset
\end{equation}
hat es in sich, sie wird als \emph{Auswahlaxiom} bezeichnet.
Man hat herausgefunden, dass dieses Axiom wahr oder auch falsch sein
darf, ohne dabei im Widerspruch zu den übrigen Axiomen der
ZFC"=Mengenlehre zu stehen. Der Spezialfall $K\subseteq\N_0$ wird
als \emph{abzählbares Auswahlaxiom} bezeichnet.

Für das Produkt einer konstanten Mengenfamilie gilt
\begin{equation}
A^K := \prod_{k\in K} A = \Abb(K,A).
\end{equation}

\newpage
\section{Relationen}
\subsection{Grundbegriffe}

\begin{Definition}[Relation]\mbox{}\\*
Seien $A,B$ zwei Mengen und sei $G\subseteq A\times B$.
Das Tripel $R=(G,A,B)$ heißt Relation zwischen $A$ und $B$.
Man schreibt
\[R(x,y) \defiff (x,y)\in G.\]
\end{Definition}
Eine Relation lässt sich natürlich als wahrheitswertige Funktion
interpretieren:
\[R\colon A\times B\to\{0,1\},\quad R(x,y):=((x,y)\in G).\]
Eine Relation ist somit auch ein Prädikat auf $A\times B$.

\subsection{Äquivalenzrelationen}
\begin{Definition}[Äquivalenzrelation]%
\index{Aequivalenzrelation@Äquivalenzrelation}\mbox{}\\*
Seien $A$ eine Menge und seien $x,y,z\in A$. Sei $R(x,y):=(x\sim y)$ eine
Relation. Man nennt $R$ Äquivalenzrelation, wenn gilt:
\[\begin{array}{ll}
x\sim x, &\text{(Reflexivität)}\\
x\sim y \implies y\sim x, & \text{(Symmetrie)}\\
x\sim y\land y\sim z\implies x\sim z.\quad & \text{(Transitivität)}
\end{array}\]
\end{Definition}

\begin{Definition}[Äquivalenzklasse]\mbox{}\\*
Sei $M$ eine Menge und $x\sim y$ eine Äquivalenzrelation für $x,y\in M$.
Die Menge%
\[[a] := \{x\in M\mid x\sim a\}\]
nennt man die Äquivalenzklasse zum Repräsentanten $a\in M$.
\end{Definition}

\begin{Satz}[Äquivalenzrelation induziert Zerlegung]\mbox{}\\*
Eine Menge wird durch eine Äquivalenzrelation in disjunkte
Äquivalenzklassen zerlegt, lat. partitioniert.
\end{Satz}
\strong{Beweis.} Sei $M$ die Menge und $x\sim y$ die Äquivalenzrelation.
Zu zeigen ist, dass kein Element von $M$ in mehr als einer
Äquivalenzklasse vorkommt. Seien $a,b,c\in M$, sei $c\in [a]$
und $c\in [b]$. Aufgrund von $c\sim a$ sowie $c\sim b$ und der
Transitivität gilt%
\[x\in [a]\iff x\sim a\iff x\sim c\iff x\sim b\iff x\in [b].\]
Man hat also
\[(\forall x\in M)(x\in [a]\Leftrightarrow x\in [b])\iff [a]=[b].\]
Wenn also $[a]\ne [b]$ ist, kann nicht gleichzeitig $c\in [a]$ und $c\in [b]$
sein.\;\qedsymbol

\begin{Satz}[Zerlegung induziert Äquivalenzrelation]\mbox{}\\*
Sei $M$ eine Menge. Die Familie $(A_k)$ von Mengen $A_k\subseteq M$
bilde eine Zerlegung von $M$, d.\,h. dass die Vereinigung aller
$A_k$ die Menge $M$ überdeckt und dass paarweise $A_i\cap A_j=\{\}$
für $i\ne j$ ist. Dann ist%
\[x\sim y\defiff (\exists k)(x\in A_k\land y\in A_k)\]
eine Äquivalenzrelation auf $M$.
\end{Satz}
\strong{Beweis.} Da die $A_k$ die Menge $M$ überdecken,
muss es für ein beliebiges $x\in M$ mindestens eine Menge $A_k$
geben, so dass $x\in A_k$. Daher gilt $x\sim x$.

Die Symmetrie ergibt sich trivial.

Zur Transitivität. Voraussetzung ist $x\sim y$ und $y\sim z$.
Es gibt also ein $i$ mit $x\in A_i$ und $y\in A_i$. Außerdem gibt
es ein $j$ mit $y\in A_j$ und $z\in A_j$. Somit gilt%
\[(\exists i)(\exists j)(x\in A_i\land y\in A_i\land y\in A_j\land z\in A_j).\]
Wegen
\[A_i\cap A_j = \{\} \iff (\forall y)(y\in A_i\land y\in A_j\iff 0)\]
für $i\ne j$ kann $y\in A_i\land y\in A_j$ aber nur erfüllt sein,
wenn $i=j$ ist. Daher ergibt sich%
\[(\exists i)(x\in A_i\land z\in A_i),\]
d.\,h. $x\sim z$.\;\qedsymbol

\begin{Definition}[Quotientenmenge]
\index{Quotientenmenge}\index{Faktormenge}\mbox{}\\*
Für eine gegebene Äquivalenzrelation wird die aus allen
Äquivalenzklassen bestehende Menge
\[M/{\sim} := \{[x]\mid x\in M\}\]
als Quotientenmenge oder Faktormenge bezeichnet.
\end{Definition}

\begin{Definition}[Quotientenabbildung]%
\index{Quotientenabbildung}\mbox{}\\*
Für eine gegebene Äquivalenzrelation ist die Projektion
\[\pi\colon M\to M/{\sim},\quad \pi(x):=[x]\]
surjektiv und wird Quotientenabbildung genannt.
\end{Definition}

\newpage
\begin{Definition}[Repräsentantensystem]%
\index{Repräsentantensystem}\mbox{}\\*
Für eine gegebene Äquivalenzrelation auf $M$ nennt man eine
Teilemenge $A\subseteq M$ ein vollständiges Repräsentantensystem,
wenn die Einschränkung $\pi|_A$ bijektiv ist, wobei mit $\pi$
die Quotientenabbildung gemeint ist.
\end{Definition}
Repräsentantensysteme ermöglichen die einfache Handhabung von
Äquivalenzklassen. Möchte man wissen, ob ein Element $x$ in der
Äquivalenklasse $[a]$ enthalten ist, dann braucht man bloß
zu überprüfen, ob $x\sim a$ ist. Außerdem besitzt die
Quotientenabbildung nun eine Darstellung $p\colon M\to A$,
dergestalt dass $\pi = \pi|_{A}\circ p$. Warum sollte das von
Bedeutung sein? Nun, Äquivalenzklassen fallen oft unendlich groß
aus. In der Kombinatorik treten zwar auch endliche Äquivalenzklassen auf,
diese werden trotzdem schnell unzugänglich groß. Die Äquivalenzklassen
und die Quotientenabbildung muss man also als abstrakte mathematische
Objekte betrachten. Abstrakte mathematische Objekte müssen wir erst
über eine Darstellung zugänglich machen, und genau dies ermöglicht
ein Repräsentantensystem.


\begin{Satz}[Charakterisierung von Äquivalenzklassen]\mbox{}\\*
Sei auf der Menge $M$ eine Äquivalenzrelation gegeben. Eine
Teilmenge $A\subseteq M$ ist genau dann eine Äquivalenzklasse,
wenn%
\begin{align*}
1.\;& A\ne\emptyset,\\
2.\;& x,y\in A\implies x\sim y,\\
3.\;& x\in A\land y\in M\land x\sim y\implies y\in A.
\end{align*}
\end{Satz}
\strong{Beweis.} Angenommen, $A$ ist eine Äquivalenzklasse.
Dann gibt es definitionsgemäß ein $a$ mit $A=[a]$. Daher ist
mindestens $a\in A$ und somit $A\ne\emptyset$. Mit $x,y\in A$ ergibt
sich $A=[x]=[y]$. Aufgrund von%
\[x\sim y \iff [a]=[b]\]
muss somit $x\sim y$ sein. Sei nun $x\in A$ und $y\in M$ mit
$x\sim y$. Es folgt $A=[x]=[y]$. Daher muss $y\in A$ sein.

Umgekehrt angenommen, die drei Eigenschaften sind erfüllt.
Zu zeigen ist, dass es ein $a$ gibt mit $A=[a]$. Da $A$ gemäß 1.
nichtleer ist, enthält es mindestens ein Element, dieses nennen wir
$a$. Für jedes weitere Element $x\in A$ ergibt sich
$x\sim a$, da sonst 2. verletzt sein würde. Schließlich muss man
noch wissen, ob $x\in A$, wenn $x\sim a$ und $x\in M$ ist.
Dies ist aber mit 3. gesichert. Es gibt also
tatsächlich ein $a$ mit $A=\{x\in M\mid x\sim a\}$.\;\qedsymbol

Eine große Fülle von Äquivalenzrelationen lässt sich auf die folgende
einfache Art konstruieren. Hat man eine beliebige Abbildung
$f\colon M\to N$, dann sind die Urbilder $f^{-1}(\{y_1\})$ und
$f^{-1}(\{y_2\})$ disjunkt, sofern $y_1\ne y_2$, denn%
\[f^{-1}(\{y_1\})\cap f^{-1}(\{y_2\}) = f^{-1}(\{y_1\}\cap\{y_2\})
= f^{-1}(\emptyset) = \emptyset.\]
Demnach ist gemäß
\[Z = M/{\sim} = \{f^{-1}(\{y\})\mid y\in f(M)\}\]
eine Zerlegung des Definitionsbereichs $M$ gegeben und somit auch eine
Äquivalenzrelation. Für $x_1,x_2\in M$ gilt%
\[x_1\sim x_2 \iff f(x_1) = f(x_2).\]
Ist $f$ zudem surjektiv, dann gehört zu jedem Element von $N$ genau eine
Äquivalenzklasse. Demnach definiert $f$ dann eine verallgemeinerte
Quotientenabbildung, da die Elemente von $N$ die Äquivalenzklassen
charakterisieren. Die Bijektion $\varphi\colon Z\to N$ hat dabei
die Eigenschaft $f = \varphi\circ\pi$. Sofern $N$ für uns zugänglich
ist, resultiert hieraus auch eine verallgemeinerte Darstellung der
Quotientenabbildung, denn
\[f = \varphi\circ\pi = \varphi\circ (\pi|_A\circ p)
= (\varphi\circ\pi|_A)\circ p.\]
Nun ist $\varphi\circ\pi|_A$ auch bijektiv, weil $\varphi$
und $\pi|_A$ es sind. Somit charakterisiert $N$ ein
vollständiges Repräsentantensystem.

Was bisher erläutert wurde mag recht abstrakt erscheinen. Wir haben
aber eigentlich ein recht intuitives Verständnis für diese
Begrifflichkeiten. Das typische Beispiel für eine Äquivalenzrelation
ist, wenn zwei Schüler in die gleiche Schulklasse gehen. Die
Äquivalenzklasse ist dann schlicht diese Schulklasse. Die Menge
der Schüler der Schule wird in disjunkte Schulklassen zerlegt.
Die Menge dieser Schulklassen bildet die Quotientenmenge. Ein
vollständiges Repräsentantensystem ist z.\,B. die Wahl eines
Klassensprechers in jeder Klasse.

Ein weiteres typisches Beispiel für eine Äquivalenzrelation ist die
Kongruenz modulo $m$, die elementar in der Zahlentheorie
und Gruppentheorie vorkommt. Die Äquivalenzklassen sind hier die
Restklassen. Die Reste bilden ein kanonisches vollständiges
Repräsentantensystem. Das Bilden des Restes zu einer Zahl ist
eine Darstellung der Quotientenabbildung.

Äquivalenzrelationen haben in der Mathematik eine fundamentale
Bedeutung, da sie den Begriff der Gleichheit abstrahieren und
verallgemeinern. Wir können nun umgekehrt den philosophischen
Standpunkt einnehmen, dass es Identität in der wirklichen Welt, was
damit auch immer gemeint sein soll, nirgendwo gibt, dass die Welt also
überall eine reichhaltige Tiefe besitzt mit welcher keine zwei Dinge
die selben sind. Ein Vergleich setzt dann von vornherein eine
Äquivalenzrelation voraus. Man könnte einwenden, in unserem Kosmos sei
eine in die Hand genommene Tasse die selbe Tasse. Dies ist aber wieder
bloß eine Relation zwischen zwei Objekten in der Raumzeit. Die Tasse
ist außerdem eine Ansammlung von Atomen, die sich in diesem Zeitraum
wahrscheinlich an irgendeiner Stelle verändert haben wird. Ein
neuerlicher Einwand wäre, dass eine Struktur in der Raumzeit identisch
zu sich selbst sein muss. Diese Struktur ist denkbar, aber für uns
niemals so zugänglich, als würden wir eine Tasse in die
Hand nehmen und betrachten.

Diesem Gedankengang liegt die Idee zugrunde, dass es zu jeder
Äquivalenzrelation weitere Äquivalenzrelationen gibt, welche
die Äquivalenzklassen wiederum in feinere Äquivalenzklassen zerlegen.
Die unendliche Fortsetzung von Verfeinerungen setzt voraus, dass
jede Äquivalenzklasse unendlich groß ist. In dieser Vorstellung einer
wirklichen Welt gibt es daher nichts was endlich wäre.

\subsection{Operationen auf Äquivalenzklassen}

Äquivalenzklassen werden später wichtig sein für die Formulierung von
Konstruktionen. Bei diesen Konstruktionen ist eine Abbildung
zwischen Quotientenmengen erforderlich. Weil die Äquivalenzklassen
dabei über Repräsentanten dargestellt sind, liegt es nahe, auch
die Abbildung über Repräsentanten zu definieren. Dies wirft die
Frage nach der \emph{Wohldefiniertheit} auf. Darunter versteht man,
dass die Abbildung auch tatsächlich unabhängig von den gewählten
Repräsentanten ist. Was das genau bedeutet, wird im folgenden
Abschnitt erklärt.

Gegeben seien zwei Quotientenmengen $M/\sim$ und $M'/\sim'$.
Eine vorhandene Abbildung $f\colon M\to M'$ induziert dann
eventuell gemäß%
\begin{equation}\label{eq:induzierte-Abbildung}
f\colon M/\sim\to M'/\sim',\; f([a]):=[f(a)]
\end{equation}
eine Abbildung zwischen den Quotientenmengen. Kommt es dabei nicht
zu einem Widerspruch, liegt also eine Abbildung vor, spricht man
von \emph{Wohldefiniertheit}. Hierfür darf der Funktionswert nicht
vom gewählten Repräsentant abhängen, d.\,h. die Bedingung%
\begin{equation}
\forall x\in [a]\colon f(x)\in [f(a)]
\end{equation}
muss erfüllt sein. Anders formuliert:
\begin{equation}
x\sim a \implies f(x)\sim' f(a).
\end{equation}
Für mehrstellige Abbildungen ist das Vorgehen analog. Eine
Abbildung $f\colon M^2\to M'$ induziert%
\begin{equation}
f\colon (M/\sim)^2\to M'/\sim',\; f([a],[b]):=[f(a,b)],
\end{equation}
sofern
\begin{equation}
x\sim a\land y\sim b\implies f(x,y)\sim' f(a,b).
\end{equation}
Bei den Konstruktionen kommen in der Regel zweistellige Abbildungen
(mit $M=M'$) vor, weil die Verknüpfungen von Elementen der algebraischen
Strukturen zweistellig sind.

