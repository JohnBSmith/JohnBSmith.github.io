<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8">
  <title>Blog</title>
  <link href="blog.css" rel="stylesheet">
</head>
<body>

<div id="content">
<header id="header">
<h1>Blog</h1>
<a href="../de.htm">Home</a><!--
--><a href="../Rest/Portal.htm">Portal</a>
</header>

<div id="main-aside">
<main id="main">

<h2>Inhaltsverzeichnis</h2>
<ul>
<li><span class="date">[2015-12-12]</span>
  <a href="#Passwoerter">Kryptische Passwörter</a>
<li><span class="date">[2017-02-22]</span>
  <a href="#Index">Index clientseitig durchsuchen</a>
<li><span class="date">[2017-03-19]</span>
  <a href="#Midi">Probleme mit Midi auf Linux</a>
<li><span class="date">[2017-05-09]</span>
  <a href="#Int">Ganzzahldatentypen</a>
<li><span class="date">[2017-10-26]</span>
  <a href="#Rust">Gedanken zu Rust</a>
</ul>

<h2 id="Passwoerter">Kryptische Passwörter</h2>
<div class="date">12. Dezember 2015</div>

<p>Ich las gerade einen Zeitungsartikel über Passwörter. Dort wurden
einem wie üblich Tipps genannt, um sich solche sicher zu erstellen.
Die Darstellung war simplifiziert und hob unwesentliche Dinge hervor.
Es wurde dann empfohlen, mindestens 12 Zeichen mit
Zufallskombinationen zu verwenden. Aber was soll das
<em>mindestens</em>? Warum nicht einfach
eine exakte Zahl von Zeichen? Viele Dienste wollen dann auch noch
unbedingt Sonderzeichen und große Buchstaben, andernfalls wird
das Passwort abgewiesen. Das ist natürlich ein ziemlicher Bullshit.
Ich will erklären warum.

<p>Gehen wir zunächst einmal von dem aus, was sicher ist. Man kann
durch theoretische Überlegungen leicht feststellen, dass ein
128bit-Passwort sicher ist. Falls Quantencomputer verwendet werden,
so soll man nach Meinung von Forschern die Passwortlänge verdoppeln,
also ein 256bit-Passwort verwenden.

<p>Nun kann man so ein Passwort zu einer bestimmten Basis
darstellen, wenn man es als Zahl im Stellenwertsystem auffasst.
Die Basis <code>B</code> ist dabei eine geordnete Menge von Ziffern.
Die Länge der Basis, d.&nbsp;h. die Anzahl der Ziffern, bezeichnen wir
mit <code>b</code>. Im Dezimalsystem hat man folgende Basis:

<pre>
  B = {0,1,2,3,4,5,6,7,8,9}
  b = |B| = 10
</pre>


<p>Eigentlich ist ein Passwort keine Zahl, sondern nur
ein Symbolwort. Man nennt die Basis dann
Symbolalphabet. Aber das sind abstraktere
Begriffe, die nur für Informatiker verständlich sind. Die
nötige Passwortlänge wollen wir nun mit <code>L</code> bezeichnen,
präziser mit <code>L(b)</code>, da es sich um eine von <code>b</code>
abhängige Funktion handelt.

<p>Für eine einzelne Ziffer gibt es nun <code>b</code> Möglichkeiten,
für zwei sind es <code>b*b</code> und für <code>L</code> Ziffern sind
es <code>b<sup>L</sup></code>. Die Zahl
<pre>
  S = b<sup>L</sup>
</pre>
<p>bezeichnet man als Schlüsselraumgröße.
Ein bit hat zwei Möglichkeiten. Dann hat ein
128bit Passwort also <code>2<sup>128</sup></code> Möglichkeiten.
Damit erhält man die Gleichung
<pre>
  b<sup>L</sup> = 2<sup>128</sup>.
</pre>
<p>Logarithmieren auf beiden Seiten und Umformung bringt
<pre>
  L = 128 lg(2)/lg(b).
</pre>
<p>Zur Sicherheit wollen wir Aufrunden. Somit erhält man
für die notwendige Passwortlänge die Formel
<pre>
  L = ceil(128 lg(2)/lg(b)).
</pre>
<p>Hier sind nun einige Basen bzw. Alphabete wie sie praktisch
verwendet werden.
<table class="bt">
<tr><th>b<th>Basis
<tr><td>10<td>dezimale Ziffern
<tr><td>16<td>hexadezimale Ziffern
<tr><td>26<td>kleine Buchstaben
<tr><td>36<td>Buchstaben und Ziffern
<tr><td>62<td>kleine und große Buchstaben sowie Ziffern
<tr><td>90<td>druckbare ASCII-Zeichen
</table>

<p>Nun eine Tabelle mit der notwendigen Passwortlänge:
<pre>
    b |   L
    2 | 128
    3 |  81
    4 |  64
    6 |  50
   10 |  39
   16 |  32
   26 |  28
   36 |  25
   62 |  22
   90 |  20
  100 |  20
  128 |  19
  256 |  16
  999 |  13
</pre>
<p>Man sieht, dass die notwendige Passwortlänge erst schnell und
dann immer langsamer abnimmt. Nur um fünf Zeichen zu sparen, muss
man aber nicht große Buchstaben und Sonderzeichen verwenden.
Selbst wenn man 1000 Hanzi verwenden würde, wäre die Passwortlänge
immer noch 13 Zeichen.

<p>Es ist nun am sichersten, (exakt gleichverteilte) zufällige Zeichen
zu benutzen. Diese ordnet man zur Lesbarkeit in Vierergruppen
an. Bei 24 kleinen Buchstaben und Ziffern sind das sechs Gruppen.
Ein Passwort sieht dann z.&nbsp;B. so aus:

<pre>
  b4ma 2kwq wmco piht ujx8 r37g
</pre>

<p>Leerzeichen sollten vom Eingabeparser
entfernt werden. Ich finde es sehr fehleranfällig, wenn
Eingabeparser so etwas nicht machen. 

<p>Das mit den nicht notwendigen Sonderzeichen lässt sich auch
so veranschaulichen: wenn man zwei hexadezimale Ziffern zu einem
Symbol zusammenfasst, hat man schon <code>b=256</code>.
Anstelle noch so kryptische Zeichen zu verwenden, kann man also auch
einfach die Passwortlänge verdoppeln und dabei nur hexadezimale
Ziffern benutzen.

<p>Für einen Account bei einem Server sollten sich
<code>2<sup>128</sup></code> Schlüssel aber nicht Brute-Force
durchprobieren lassen. So etwas wäre ja höchst auffällig. Angenommen,
jemand loggt sich maximal 100 mal am Tag ein und der Account
besteht maximal für 100 Jahre. Dann ist die maximale Anzahl der
Versuche 100*365*100. Man will nun eine Wahrscheinlichkeit von eins
zu einer Mio., dass jemand hierbei Zufällig den richtigen
Schlüssel findet. Man benötigt daher einen Schlüsselraum von
<pre>
  100*356*100*10<sup>6</sup> = 3.65*10<sup>12</sup>
  = 1.66*2<sup>41</sup>.
</pre>

<p>Bei <code>2<sup>42</sup></code> ergibt sich ein Passwort von
neun Buchstaben und Ziffern. Zur Sicherheit kann man 12 verwenden.
Ein Passwort wie
<pre>
  b4ma 2kwq wmco
</pre>
<p>sollte also ausreichend sicher sein. Ein Problem welches
sich jetzt ergibt, ist, dass von Passwörtern nur gesalzene
Hashwerte gespeichert werden sollten. Es kann möglich sein,
dass dabei zwei unterschiedliche Passwörter zum gleichen Hashwert
führen. Bei SHA-256-Hashwerten ist so etwas aber fast
ausgeschlossen.

<p>Und damit ist nun klar, dass man weder Sonderzeichen
noch Großbuchstaben verwenden muss. Verängstigte können
die Passwortlänge einfach von 12 auf 16 erhöhen,
das bringt mehr als noch so kryptische Sonderzeichen.
Warum? Weil <code>36<sup>16</sup></code> größer ist als
<code>90<sup>12</sup></code>.

<p>Um es mathematisch zu präzisieren: Wächst die Basis, so
ergibt sich für die Schlüsselraumgröße die Potenzfunktion
<code>S(x)=x<sup>L</sup></code>. Wächst jedoch die Schlüssellänge, so
ergibt sich für die Schlüsselraumgröße die Exponentialfunktion
<code>S(x)=b<sup>x</sup></code>. Exponentialfunktionen wachsen aber
wesentlich schneller als Potenzfunktionen.


<h2 id="Index">Index clientseitig durchsuchen</h2>
<div class="date">22. Februar 2017</div>

<p>Interessanterweise lässt sich unter Verwendung von clientseitigem
Javascript auch ein Index auf einem Server durchsuchen.
Das Problem ist zunächst, dass der Index irgendwann größer wird als
ca. vier MB. Als Lösung wird der Index nun jedoch als Baumstruktur
gespeichert, wobei die Knoten der ersten Ebenen in unterschiedlichen
Dateien stehen. Über <code>XMLHttpRequest</code> lassen sich die
Dateien dann per Lazy Evaluation lesen. Angenommen man hat einen
1&nbsp;GB großen Suchbaum. Bei zwei Ebenen mit je 26 Buchstaben lässt
sich der Index dann auf 1,5&nbsp;MB große Dateien verteilen.

<p>Ein weiteres Problem, welches sich dabei ergibt, ist nun aber
die Suche von Teilzeichenketten im Index. Dazu müsste der gesamte
Index geladen und durchsucht werden. Man könnte nun auf die Idee
kommen, aus dem Index einen Meta-Index zu erzeugen. Aber die
Teilzeichenketten sind im Normalfall über den gesamten Index verteilt,
sodass man doch wieder alle Dateien laden müsste.

<p>Stattdessen ist es vorteilhaft, gleich einen Index zu erzeugen,
der auch die Teilzeichenketten umfasst. Dieser wird dann wohl
etwas größer werden. Aber das ist nicht so schlimm, auch wenn der Index
so groß werden würde wie der gesamte Text der Website. Solange beim
Auswerten des Suchbaumes nur zwei bis drei kleine Dateien geladen
werden müssen, ist das kein Nachteil. Man beachte, dass das
Text-Daten sind, das ist eigentlich sehr wenig Festplattenplatz.

<p>Ich hätte gerne eine Volltextsuche für
<a href="https://de.wikipedia.org/wiki/Project_Gutenberg"
>Project Gutenberg</a>. Die Website verwendet seit einiger Zeit
schon TLS. Man muss aber einen https-Link verwenden.

<h2 id="Midi">Probleme mit Midi auf Linux</h2>
<div class="date">19. März 2017</div>
<p>Zurzeit gibt es noch einige Probleme mit Midi auf Linux
(Ubuntu 16.04 LTS). Linthesia in Version <code>0.4.3</code>
funktionierte, stürzte aber nach einiger Zeit ab. Nach Software-Updates
scheint es jetzt in (immer noch Version <code>0.4.3</code>) nicht mehr
abzustürzen, aber man hört nichts mehr, weil TiMidity irgendwie nicht
richtig angesprochen wird. TiMidity selbst funktioniert, jedoch war es
mir nicht möglich, alternative Soundfonts zu installieren.

<p>Musescore hat auch mal gesponnen, sodass man nichts hörte.
Es scheint jetzt aber wieder korrekt zu funktionieren. Das Verhalten
kann sich nach Software-Updates ja verändern, und ich verfolge nicht
alle Software-Updates. Musescore wandelt Midi in einigen Fällen
sogar in einigermaßen korrekte Partituren um und scheint sogar
Auftakte und Tonarten erkennen zu können.

<p>Das <code>fluidsynth</code>-Plugin für den VLC funktioniert,
das ist schön. Wenn man eine Midi-Datei im Firefox anklickt, dann
öffnet sich VLC und spielt die ab. Die Zukunftsvorstellung ist dabei
jetzt natürlich, dass sich gleich Linthesia öffnen könnte.
Jedenfalls braucht jemand in Zukunft nicht mehr unbedingt Noten
schreiben. Es geht wesentlich schneller, mit einem Keyboard eine
Midi-Datei aufzunehmen und die dann mit Linthesia abspielen zu lassen.

<h2 id="Int">Ganzzahldatentypen</h2>
<div class="date">9. Mai 2017</div>
<p>Wart ihr euch schon einmal unsicher, welchen der vielen
Ganzzahldatentypen ihr in C benutzen sollt? Meines Erachtens
können die eingebauten Datentypen von einem Compiler sinnvollerweise
so definiert werden:
<pre>
  unsigned char  == uint_fast8_t
  unsigned short == uint_fast16_t
  unsigned int   == uint_fast16_t
  unsigned long  == uint_fast32_t
</pre>
<p>Prinzipiell könnte ein Compiler auch so konfiguriert werden,
dass er möglichst viel Speicher spart (meistens nicht sinnvoll).
Zum Beispiel könnte man auch auf solches stoßen:
<pre>
  unsigned char  == uint_least8_t
  unsigned short == uint_least16_t
  unsigned int   == uint_fast16_t
  unsigned long  == uint_least32_t
</pre>
<p>Angenommen man will nun eine UTF-8- oder eine UTF-32-Zeichenkette
speichern. Man könnte jetzt auf die Idee kommen, dafür ein Feld von
<code>uint8_t</code> bzw. <code>uint32_t</code> zu verwenden.
Es kann aber auf seltenen Architekturen der Fall sein, dass das nicht
sinnvoll oder nicht möglich ist. Vielmehr möchte man für diesen Zweck
eigentlich <code>uint_least8_t</code> bzw. <code>uint_least32_t</code>
verwenden.

<p>Die Dinge fangen nun an kompliziert zu werden, wenn man ein
<code>uint32_t</code> als Feld von vier <code>uint8_t</code>
betrachten möchte:
<pre>
  uint32_t x = 0xcafebabe;
  uint8_t* p = (uint8_t*)&amp;x;
  printf("%02x %02x %02x %02x\n",p[3],p[2],p[1],p[0]);
</pre>
<p>Möchte man Daten aus einer Datei lesen oder in eine Datei
schreiben, so kommt dabei aber <code>uint8_t*</code> nicht vor.
Vielmehr stößt man auf <code>char*</code>, welcher zunächst in
<code>unsigned char*</code> umgecastet werden sollte. Es muss
jedoch nicht unbedingt <code>sizeof uint8_t == sizeof unsigned char</code>
sein. Das ist problematisch, wenn man z.&nbsp;B. eine
<code>uint_least32_t</code>-Zahl aus einer Datei auslesen möchte.
Die Zahl ist über ein Feld von vier <code>unsigned char</code>
verteilt. Der naive Ansatz wäre folgender:
<pre>
  unsigned char* Daten;
  uint8_t* pu8 = (unsigned char*)Daten; // Aua! (1)
  unsigned long x = *(uint32_t*)(pu8+POSITION);
</pre>
<p>Nicht weniger naiv ist folgender Ansatz:
<pre>
  unsigned char* Daten;
  unsigned char* p = Daten+POSITION;
  unsigned long x;
  x = *(unsigned long*)p; // Aua! (2)
  x = *(uint32_t*)p; // Aua! (3)
</pre>
<p>Wenn z.&nbsp;B. <code>sizeof unsinged char == sizeof unsigned
long</code> ist, dann geht alles schief. Das Feld schaut dann
folgendermaßen aus:
<pre>
  B X X X B X X X B X X X B X X X ...
  ^       ^       ^       ^
  p[0]    p[1]    p[2]    p[3]
</pre>
<p>wobei die <code>B</code> die Bytes der Zahl sind und <code>X</code>
beliebiger Datenmüll ist. Schauen wir uns an, was mit <code>pu8</code>
passiert:
<pre>
  B == pu8[0]
  X == pu8[1]
  X == pu8[2]
  X == pu8[3]
  B == pu8[4]
  X == pu8[5]
  usw.
</pre>
<p>Bei (3) schaut es so aus:
<pre>
  B X X X == *(uint32_t*)(p+POSITION)
</pre>

<p>Bei (2) nehmen wir an, dass <code>unsigned long == uint64_t</code>
gilt:
<pre>
  B X X X B X X X == *(unsigned long*)(p+POSITION)
</pre>
<p>Der Ausdruck (2) ist ausgesprochen schlimm, denn selbst
wenn <code>unsigned char</code> einem Byte entspräche, wäre
<pre>
  B B B B X X X X == *(unsigned long*)(p+POSITION)
</pre>
wo Datenmüll <code>XXXX</code> im Datum liegt. Das Problem ist hier,
dass das nicht portabel ist und Leute es eventuell erst bemerken,
wenn das Programm nach dem Portieren von <code>ILP32</code> auf
<code>LP64</code> an irgendeiner Stelle abstürzt oder sinnlose
Ergebnisse liefert.

<p>Dass alles nicht schon genug ist, ergibt sich außerdem noch
das Problem, dass die Daten in der Datei im Little-Endian-Format
gespeichert sind, die Computer-Architektur aber die
Big-Endian-Konvention verwenden könnte.

<p>Eine portable Lösung schaut wie folgt aus:
<pre>
  unsigned char* Daten;
  unsinged char* p = Daten+POSITION;
  unsigned long x;
  x = ((unsigned long)p[3] &amp; 0xff)&lt;&lt;24
    | ((unsigned long)p[2] &amp; 0xff)&lt;&lt;16
    | ((unsigned long)p[1] &amp; 0xff)&lt;&lt; 8
    | ((unsigned long)p[0] &amp; 0xff);
</pre>
<p>Zur Optimierung verwendet man ein Makro oder eine Inline-Funktion.
Die high-end-Compiler <code>gcc</code> und <code>clang</code>
beherrschen natürlich das Inlinen von Funktionen. Für billige
Compiler ist ein Makro aber besser.

<p>Falls <code>unsigned char</code>
mit <code>uint8_t</code> koinzidiert, kann <code>&amp; 0xff</code>
entfallen. Das ist eine ganz banale Optimierung. Wenn ein Compiler
das nicht wegoptimiert, solltet ihr den Compiler besser in den
Mülleimer werfen. Man darf diese Optimierung auch für
Embedded-Compiler erwarten, weil dort die Verwendung von
Bitarithmetik maßgeblich ist.

<p>Die Programmiersprache&nbsp;C kann als Mischung aus Hochsprache
und Assembler betrachtet werden. Programmierung in&nbsp;C sollte
zu Gunsten von typsicheren Programmiersprachen möglichst vermieden
werden. Als nächstes wird man sich also fragen, wie das Lesen von
Daten in den effizienten Programmiersprachen Ada, D, Rust und OCaml
ermöglicht wird.

<h2 id="Rust">Gedanken zu Rust</h2>
<div class="date">26. Oktober 2017</div>

<p>Standard ML ist eine strenge, typsichere und mathematisch
außerordentlich reine Programmiersprache.
In Standard ML wurden Theorembeweiser geschrieben.
An Robin Milner wurde 1991 für den Entwurf von Standard ML
der Turing-Award verliehen. Nur eines ist Standard ML nicht:
im Mainstream angekommen. Die Sprache konnte sich nicht
gegen die Effizienz von&nbsp;C behaupten. Verkettete Listen
erzeugen zu viele Speicherallokationen und rekursive Programmierung
ist langsamer als iterative. Solche Probleme lassen sich mit
Zusatzinformationen bis zu einem gewissen Grad wegoptimieren,
aber das kann außerordentlich schwierig werden. Zwar hatte
Standard ML auch Mittel zur iterativen Programmierung, aber diese
stand im Abseits.

<p>In Rust wurde nun das scharfe typtheoretische Modell von
Standard ML mit dem iterativen Programmierstil kombiniert.
So gibt es die algebraischen Typkonstruktionen Produkt
(<code>struct</code> wie <code>struct</code> in&nbsp;C,
<code>record</code> in Pascal) und Summe (<code>enum</code>
wie tagged <code>union</code> in&nbsp;C und Pascal). Wenn
die <code>union</code> entfällt, bleibt das Tag übrig, das ist
dann eine einfache <code>enum</code> wie in&nbsp;C. Die Summe
kann man sich als disjunkte Vereinigung von Typen vorstellen,
wenn man sich die Typen als Mengen von zulässigen Werten vorstellt.
Eigentlich sind bei Typen aber auch rekursive Typen möglich, was
zu einem Paradoxen wie der russelschen Antimonie führt. Deshalb
können Typen im Allgemeinen keine Mengen sein, sondern sind
viel mehr Klassen. Das kartesische Produkt von Mengen wird
zum kategorientheortischen Produkt verallgemeinert und
die disjunkte Vereinigung zum Koprodukt.

<p>Während das Produkt von Typen seinen Weg in die klassischen
Programmiersprachen gefunden hat, sind typsichere
Tagged Unions bei den meisten Sprachen leider nicht möglich.
Zur Verwendung von Tagged Unions ist es notwendig, diese
wieder typsicher in eine Fallunterscheidung aufzuspalten.
Dafür wird eine extra Kontrollstruktur benötigt, die es
nur in Algol 68, Rust und den funktionalen Sprachen gibt.
In Java sind aus Gründen der Typsicherheit nun Tagged Unions
nicht möglich &mdash; das Verhalten wird durch Laufzeitpolymorphie
simuliert, was zu außerordentlich vielen Speicherallokationen,
Cache-unfreundlichen Indirektionen und damit scheußlichem
Laufzeitverhalten führt. Man versucht, das Problem durch
Verwendung eines Garbage-Kollektors leicht zu mildern.

<p>Auch das System zur Ausnahmebehandlung arbeitet in Rust
mit Summentypen. Der Grundgedanke ist, dass im Falle eines
Fehlers von einer Funktion ein Fehlerwert zurückgegeben
wird, der außerhalb der Menge der normalen Werte liegt.
Um ein solches Vorgehen zuverlässig zu machen, wird wieder eine
disjunkte Vereinigung benutzt. Die dafür normalerweise
vorgesehenen Summentypen sind <code>Option&lt;T&gt;</code>
und <code>Result&lt;T,E&gt;</code>, man kann sich aber auch
eigene Summentypen definieren. Bei C++ weiß man nie so genau
was hinter <code>try-catch</code> stekt, welche Laufzeitkosten
entstehen, wie komplex das intern arbeitet, und welche Programmaufrufe
eine Ausnahme werfen könnten. Bei einer Systemprogrammiersprache mag
man solches eigentlich nicht. Aus diesem Grund ist der Ansatz mit
Summentypen sehr viel eleganter.

<p>Das System <i>Scope, Ownership, Lifetime, Borrowing, Mutability</i>
ist sehr ausgeklügelt, auch wenn die formalen Regeln des Borrow
Checkers noch nicht zu 100% ausgearbeitet worden sind. In den meisten
Fällen genügt das System tatsächlich. In einer speziellen Situation
reichten mir Lebenszeitangaben nicht aus, so dass ich einen
Arena-Allokator benötigt hätte. Die Referenzen auf dynamisch erzeugte
Daten die ein Arena-Objekt zurückgibt, haben die selbe Lebenszeit
wie das Arena-Objekt selbst. Leider ist es nicht möglich, den Datentyp
Arena in typsicherem Rust zu programmieren und in der Standardbibliothek
ist dieser Datentyp auch nicht vorhanden.

<p>Man kann sich aber auch in solchen problematischen Fällen
mit <code>Rc&lt;T&gt;</code>
(ggf. als <code>Rc&lt;RefCell&lt;T&gt;&gt;</code>)
behelfen. Das sind Referenz-zählende Smart-Pointer, die eine
minimalistische Garbage-Collection darstellen.
Das eleganteste bei der Speicherallokation in Rust ist
die automatische Deallokation und der automatische Aufruf
von Destruktoren am Ende der Lebenszeit von Objekten, ein System
das schon erfolgreich in C++ eingebaut wurde.
Die Lebenszeit von Objekten endet immer dann, wenn sie ihren Scope
verlassen und keine Ownership-Übertrag an eine andere Variable
stattgefunden hat. Das gilt auch für die Smart-Pointer: Die
Lebenszeit des Objektes, auf das die Pointer zeigen, endet genau
dann, wenn die Lebenszeit aller Pointer vorbei ist.

<p>Man muss sich mal vor Augen führen dass solche Referenz-zählenden
Zeiger eigentlich unheimlich performant sind. Zumal beim
bloßen Borrowing nicht am Referenz-Zähler herumgespielt werden
muss, es sei denn man benötigt verändliche Borrows, die durch
<code>RefCell&lt;T&gt;</code> modeliert werden. Selbst wenn das
Programm dann 1% langsamer wird oder 1% mehr
Energie verbraucht, ist das eigentlich nicht weiter schlimm.
Für große Objekte, aus denen eine Menge Inhalt ausgelsen werden
soll, sind die Referenz-Zähler eigentlich
zu vernachlässen. Performance-Einbußen treten erst bei Feldern von sehr
feinen kleinen Datenobjekten auf. In einem solchen Fall sollte man
sowieso möglichst mit Summentypen arbeiten um unnötige
Speicherallokationen zu vermeiden.

<p>Momentan gibt es in Rust ein kleineres Problem mit
<i>Code Bloat</i>, der bei generischen Algorithmen auftritt.
Zum Beispiel wird der Maschinencode beim Datentyp
<code>Vec&lt;T&gt;</code> für jeden Typ <code>T</code> neu erzeugt,
was als Monomorphisation oder automatische Spezialisierung
bezeichnet wird.
Tatsächlich ist es aber möglich, die internen Algorithmen polymorph
zu schreiben, indem sie nur den Speicher per Shallow Copy kopieren.
Nur das Interface wird generisch ausgelegt, was aber eine
Zero-Cost Abstraktion darstellt. Für die Laufzeit ist es
natürlich <i>etwas</i> günstiger, wenn die Algorithmen für
jeden Typ <code>T</code> extra spezialisiert
werden. Bei einem Optionstyp <code>Option&lt;T&gt;</code> mit
großen Inhalt muss z.&nbsp;B. nur das Tag kopiert werden, falls die
Option <code>None</code> ist.

<p>Auch <code>Vec&lt;Box&lt;T&gt;&gt;</code> für unterschiedliche
Typen <code>T</code> erzeugt momentan Code Bloat. Das ist natürlich
unschön, da der Maschinencode in diesem Fall identisch sein sollte.
Diese Idee lässt sich aber vernünftig und in mehr Ausdrucksstärke
als allgemeines Prinzip in Rust umsetzen. Die Konstruktion
dazu ist:
<pre class="code indent">
<b>trait</b> Item{}

<b>struct</b> A; <b>impl</b> Item <b>for</b> A{}
<b>struct</b> B; <b>impl</b> Item <b>for</b> B{}

<b>fn</b> main(){
  <b>let</b> vA: Vec&lt;Box&lt;Item&gt;&gt; = vec![Box::new(A), Box::new(A)];
  <b>let</b> vB: Vec&lt;Box&lt;Item&gt;&gt; = vec![Box::new(B), Box::new(B)];
}
</pre>
<p>Auf diese Art ist auch Laufzeit-Polymorphie möglich.
Wenn <code>Item</code> nämlich Methoden-Signaturen enthält
und die Strukturen diese implementieren, werden die
Variablen vom Typ <code>Box&lt;Item&gt;</code> automatisch zu
<i>Fat Pointern</i> die neben einem Zeiger auf die Daten noch
einen Zeiger auf die jeweilige Tabelle virtueller Methoden
enthalten. Für Variablen vom Typ <code>Item</code> entfallen alle
Indirektionen und die Methoden können direkt aufgerufen werden.
Die selben Methoden können somit nach belieben statisch an ein
Objekt oder dynamisch an einen Objekt-Zeiger gebunden werden.
Dieser Ansatz ist außerordentlich elegant und ausgeklügelt,
und ich würde sagen dass das der kanonische Ansatz für eine
performante Programmiersprache ist.

<p>Was Rust m.&nbsp;E. noch fehlt ist ein System zum
maschinengestützten Beweisen von sicher abstrahierten unsafe-Blöcken.
Damit lässt sich die Korrektheit von Alogrithmen, welche
unsafe-Blöcke enthalten, im Nachhinein sicherstellen. Mit
Korrektheit ist hier gemeint, dass es in keinem Fall zu einer
Speicherzugriffs-Verletzung und damit undefiniertem Verhalten
kommen kann. Jedes undefinierte Verhalten stellt nämlich eine
potentielle Sicherheitslücke dar.

<p>Zusammenfassend wurde ich überzeugt, dass Rust die Sprache
ist, die das Erbe von C/C++ antreten könnte. Falls es nicht
Rust selbst ist, ist es eine Sprache die Rust sehr ähnlich
ist und fast die gleichen Mechanismen besitzt.
</main>

<aside id="right-aside">
</aside>
</div>

</div>

</body>
</html>
